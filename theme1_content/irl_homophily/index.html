<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Source Themes Academic 4.6.3"><meta name=author content="Marian-Andrei Rizoiu"><meta name=description content="Our article from the [The Conversation](https://theconversation.com/some-reddit-users-just-love-to-disagree-new-ai-powered-troll-spotting-algorithm-finds-255879) from our paper presented at WWW'25."><link rel=alternate hreflang=en-us href=https://www.behavioral-ds.science/theme1_content/irl_homophily/><meta name=theme-color content="#2962ff"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin=anonymous><script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin=anonymous async></script><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap"><link rel=stylesheet href=/css/academic.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-983V3P8SQ2"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
function trackOutboundLink(url){gtag('event','click',{'event_category':'outbound','event_label':url,'transport_type':'beacon','event_callback':function(){document.location=url;}});console.debug("Outbound link clicked: "+url);}
function onClickCallback(event){if((event.target.tagName!=='A')||(event.target.host===window.location.host)){return;}
trackOutboundLink(event.target);}
gtag('js',new Date());gtag('config','G-983V3P8SQ2',{});document.addEventListener('click',onClickCallback,false);</script><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/img/icon-32.png><link rel=apple-touch-icon type=image/png href=/img/icon-192.png><link rel=canonical href=https://www.behavioral-ds.science/theme1_content/irl_homophily/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="Behavioral Data Science"><meta property="og:url" content="https://www.behavioral-ds.science/theme1_content/irl_homophily/"><meta property="og:title" content="Some Reddit users just love to disagree, new AI-powered troll-spotting algorithm finds | Behavioral Data Science"><meta property="og:description" content="Our article from the [The Conversation](https://theconversation.com/some-reddit-users-just-love-to-disagree-new-ai-powered-troll-spotting-algorithm-finds-255879) from our paper presented at WWW'25."><meta property="og:image" content="https://www.behavioral-ds.science/theme1_content/irl_homophily/featured.png"><meta property="twitter:image" content="https://www.behavioral-ds.science/theme1_content/irl_homophily/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2025-05-09T00:00:00+00:00"><meta property="article:modified_time" content="2025-05-09T00:00:00+00:00"><title>Some Reddit users just love to disagree, new AI-powered troll-spotting algorithm finds | Behavioral Data Science</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container style=max-width:93%><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/><img src=/img/logo.png alt="Behavioral Data Science"></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/><img src=/img/logo.png alt="Behavioral Data Science"></a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/people><span>People</span></a></li><li class=nav-item><a class=nav-link href=/publication><span>Publications</span></a></li><li class="nav-item dropdown"><a href=/research class=nav-link aria-haspopup=true><span>Research</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/research/#theme1><span>Information spread, influence and attention</span></a>
<a class=dropdown-item href=/research/#theme2><span>Disinformation and online problematic content</span></a>
<a class=dropdown-item href=/research/#theme3><span>The labour markets of tomorrow</span></a></div></li><li class=nav-item><a class=nav-link href=/news><span>News</span></a></li><li class=nav-item><a class=nav-link href=/reading><span>Reading</span></a></li><li class=nav-item><a class=nav-link href=/contact><span>Contact</span></a></li><li class=nav-item><a class=nav-link href=https://github.com/behavioral-ds target=_blank rel=noopener><span><i class="fab fa-github" style=color:#333;font-size:1rem></i></span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=#><i class="fas fa-search" aria-hidden=true></i></a></li></ul></div></nav><article class=article><div class="article-container pt-3"><h1>Some Reddit users just love to disagree, new AI-powered troll-spotting algorithm finds</h1><div class=article-metadata><div><span><a href=/authors/lanqin-yuan/>Lanqin (Frankie) Yuan</a></span></div><span class=article-date>May 9, 2025</span>
<span class=middot-divider></span><span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/categories/research/>Research</a>, <a href=/categories/blogpost/>blogpost</a></span></div></div><div class=article-container><div class=article-style><p>This is a repost of our article from <a href=https://theconversation.com/some-reddit-users-just-love-to-disagree-new-ai-powered-troll-spotting-algorithm-finds-255879>The Conversation</a>.</p><p><strong>Paper citation:</strong></p><pre><code>Lanqin Yuan, Philipp J. Schneider, and Marian-Andrei Rizoiu. 2025. Behavioral Homophily in Social Media via Inverse Reinforcement Learning: A Reddit Case Study. In Proceedings of the ACM on Web Conference 2025 (WWW '25). Association for Computing Machinery, New York, NY, USA, 576–589. https://doi.org/10.1145/3696410.3714618
</code></pre><p>(<em>see full paper here: <a href=https://dl.acm.org/doi/pdf/10.1145/3696410.3714618><a href=https://dl.acm.org/doi/pdf/10.1145/3696410.3714618>https://dl.acm.org/doi/pdf/10.1145/3696410.3714618</a></a></em>)</p><p>In today’s fractured online landscape, it is harder than ever to identify harmful actors such as trolls and misinformation spreaders.</p><p>Often, efforts to spot malicious accounts focus on analysing what they say. However, our latest research suggests we should be paying more attention to what they do – and how they do it.</p><p>We have developed a way to identify potentially harmful online actors based solely on their behavioural patterns – the way they interact with others – rather than the content they share. We presented our results at the recent ACM Web Conference, and were awarded Best Paper.
Beyond looking at what people say</p><p>Traditional approaches to spotting problematic online behaviour typically rely on two methods. One is to examine content (what people are saying). The other is to analyse network connections (who follows whom).</p><p>These methods have limitations.</p><p>Users can circumvent content analysis. They may code their language carefully, or share misleading information without using obvious trigger words.</p><h2 id=beyond-looking-at-what-people-say>Beyond looking at what people say</h2><p>Traditional approaches to spotting problematic online behaviour typically rely on two methods. One is to examine content (what people are saying). The other is to analyse network connections (who follows whom).</p><p>These methods have limitations.</p><p>Users can circumvent content analysis. They may code their language carefully, or share misleading information without using obvious trigger words.</p><p>Network analysis falls short on platforms such as Reddit. Here, connections between users aren’t explicit. Communities are organised around topics rather than social relationships.</p><p>We wanted to find a way to identify harmful actors that couldn’t be easily gamed. We realised we could, focusing on behaviour – how people interact, rather than what they say.</p><h2 id=teaching-ai-to-understand-human-behaviour-online>Teaching AI to understand human behaviour online</h2><p>Our approach uses a technique called inverse reinforcement learning. This is a method typically used to understand human decision-making in fields such as autonomous driving or game theory.</p><p>We adapted this technology to analyse how users behave on social media platforms.</p><p>The system works by observing a user’s actions, such as creating new threads, posting comments and replying to others. From those actions it infers the underlying strategy or “policy” that drives their behaviour.</p><p>In our Reddit case study, we analysed 5.9 million interactions over six years. We identified five distinct behavioural personas, including one particularly notable group – “disagreers”.</p><h2 id=meet-the-disagreers>Meet the ‘disagreers’</h2><p>Perhaps our most striking result was finding an entire class of Reddit users whose primary purpose seems to be to disagree with others. These users specifically seek out opportunities to post contradictory comments, especially in response to disagreement, and then move on without waiting for replies.</p><p>The “disagreers” were most common in politically-focused subreddits (forums focused on particular topics) such as r/news, r/worldnews, and r/politics. Interestingly, they were much less common in the now-banned pro-Trump forum r/The_Donald despite its political focus.</p><p>This pattern reveals how behavioural analysis can uncover dynamics that content analysis might miss. In r/The_Donald, users tended to agree with each other while directing hostility toward outside targets. This dynamic may explain why traditional content moderation has struggled to address problems in such communities.</p><h2 id=soccer-fans-and-gamers>Soccer fans and gamers</h2><p>Our research also revealed unexpected connections. Users discussing completely different topics sometimes displayed remarkably similar behavioural patterns.</p><p>We found striking similarities between users discussing soccer (on r/soccer) and e-sports (on r/leagueoflegends).</p><p>This similarity emerges from the fundamental nature of both communities. Soccer and e-sports fans engage in parallel ways: they passionately support specific teams, follow matches with intense interest, participate in heated discussions about strategies and player performances, celebrate victories, and dissect defeats.</p><p>Both communities foster strong tribal identities. Users defend their favoured teams while critiquing rivals.</p><p>Whether debating Premier League tactics or League of Legends champions, the underlying interaction patterns – the timing, sequence and emotional tone of responses – remain consistent across these topically distinct communities.</p><p>This challenges conventional wisdom about online polarisation. While echo chambers are often blamed for increasing division, our research suggests behavioural patterns can transcend topical boundaries. Users may be divided more by how they interact than what they discuss.</p><h2 id=beyond-troll-detection>Beyond troll detection</h2><p>The implications of this research extend well beyond academic interest. Platform moderators could use behavioural patterns to identify potentially problematic users before they’ve posted large volumes of harmful content.</p><p>Unlike content moderation, behavioural analysis does not depend on understanding language. It is hard to evade, since changing one’s behavioural patterns requires more effort than adjusting language.</p><p>The approach could also help design more effective strategies to counter misinformation. Rather than focusing solely on the content, we can design systems that encourage more constructive engagement patterns.</p><p>For social media users, this research offers a reminder that how we engage online – not just what we say – shapes our digital identity and influences others.</p><p>As online spaces continue to grapple with manipulation, harassment and polarisation, approaches that consider behavioural patterns alongside content analysis may offer more effective solutions for fostering healthier online communities.</p></div><div class=share-box aria-hidden=true><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://www.behavioral-ds.science/theme1_content/irl_homophily/&text=Some%20Reddit%20users%20just%20love%20to%20disagree,%20new%20AI-powered%20troll-spotting%20algorithm%20finds" target=_blank rel=noopener class=share-btn-twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://www.behavioral-ds.science/theme1_content/irl_homophily/&t=Some%20Reddit%20users%20just%20love%20to%20disagree,%20new%20AI-powered%20troll-spotting%20algorithm%20finds" target=_blank rel=noopener class=share-btn-facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Some%20Reddit%20users%20just%20love%20to%20disagree,%20new%20AI-powered%20troll-spotting%20algorithm%20finds&body=https://www.behavioral-ds.science/theme1_content/irl_homophily/" target=_blank rel=noopener class=share-btn-email><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://www.behavioral-ds.science/theme1_content/irl_homophily/&title=Some%20Reddit%20users%20just%20love%20to%20disagree,%20new%20AI-powered%20troll-spotting%20algorithm%20finds" target=_blank rel=noopener class=share-btn-linkedin><i class="fab fa-linkedin-in"></i></a></li><li><a href="https://web.whatsapp.com/send?text=Some%20Reddit%20users%20just%20love%20to%20disagree,%20new%20AI-powered%20troll-spotting%20algorithm%20finds%20https://www.behavioral-ds.science/theme1_content/irl_homophily/" target=_blank rel=noopener class=share-btn-whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https://www.behavioral-ds.science/theme1_content/irl_homophily/&title=Some%20Reddit%20users%20just%20love%20to%20disagree,%20new%20AI-powered%20troll-spotting%20algorithm%20finds" target=_blank rel=noopener class=share-btn-weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><img class="portrait mr-3" src=/authors/lanqin-yuan/avatar_hu6e24f508cb3f7310d5ff73b6d9f05549_266435_250x250_fill_q90_lanczos_center.jpg alt=Avatar><div class=media-body><h5 class=card-title><a href=/authors/lanqin-yuan/>Lanqin (Frankie) Yuan</a></h5><h6 class=card-subtitle>PhD student</h6><p class=card-text>I am a PhD candidate at the University of Technology Sydney under the supervision of Dr Marian-Andrei Rizoiu. My research is centered around the automatic detection of problematic content (hate speech, misinformation, and disinformation), modeling the spread of problematic content, and exploring ways to address the spread of problematic content in online platforms.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:lanqin.yuan@student.uts.edu.au><i class="fas fa-envelope"></i></a></li><li><a href=https://twitter.com/EMPaThy789 target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href="https://scholar.google.com/citations?user=TGm6jw8AAAAJ&hl=en" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li></ul></div></div></div></article><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin=anonymous></script><script>const code_highlighting=true;</script><script>const search_config={"indexURI":"/index.json","minLength":1,"threshold":0.3};const i18n={"no_results":"No results found","placeholder":"Search...","results":"results found"};const content_type={'post':"Posts",'project':"Projects",'publication':"Publications",'talk':"Talks"};</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script id=dsq-count-scr src=https://behavioral-ds.disqus.com/count.js async></script><script src=/js/academic.min.b3ed283fe092cc42617915d1b60d8923.js></script><script src=//yihui.org/js/math-code.js></script><script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script><div class=container><footer class=site-footer><p class=powered-by>2025 &#183;
Powered by the
<a href=https://sourcethemes.com/academic/ target=_blank rel=noopener>Academic theme</a> for
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a>.
<span class=float-right aria-hidden=true><a href=# class=back-to-top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i>Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i>Download</a><div id=modal-error></div></div></div></div></div></body></html>