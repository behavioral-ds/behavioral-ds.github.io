<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Behavioral Data Science</title><link>https://www.behavioral-ds.science/authors/rohit-ram/</link><atom:link href="https://www.behavioral-ds.science/authors/rohit-ram/index.xml" rel="self" type="application/rss+xml"/><description>Behavioral Data Science</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>2025</copyright><lastBuildDate>Thu, 02 Feb 2023 00:00:00 +0000</lastBuildDate><image><url>https://www.behavioral-ds.science/img/logo.png</url><title>Behavioral Data Science</title><link>https://www.behavioral-ds.science/authors/rohit-ram/</link></image><item><title>Detecting extreme ideologies in shifting landscapes</title><link>https://www.behavioral-ds.science/blogpost/ideology_detection/</link><pubDate>Thu, 02 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/blogpost/ideology_detection/</guid><description>
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/csWMgU7R52Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
&lt;/iframe>
&lt;p>Also check out &lt;a href="../authors/rohit-ram/">Rohit&lt;/a>’s and &lt;a href="../authors/ma-rizoiu/">Andrei&lt;/a>’s article that just appeared in The Conversation: &lt;a href="https://theconversation.com/can-ideology-detecting-algorithms-catch-online-extremism-before-it-takes-hold-200629">Can ideology-detecting algorithms catch online extremism before it takes hold?&lt;/a>&lt;/p>
&lt;p>In this &lt;a href="https://arxiv.org/pdf/2208.04097.pdf">our latest working paper&lt;/a>, we propose a completely automatic end-to-end ideology detection pipeline for the detection and psychosocial profiling of left-right political ideology, as well as far-right ideological users.
The pipeline fills a crucial gap by providing flexible methodology and tooling for understanding ideologies and building early warning systems for extreme ideology-motivated (and potentially violent) activity.&lt;/p>
&lt;p>&lt;strong>Paper citation:&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Ram, R. and Rizoiu, M.A., 2022. You are what you browse: A robust framework for uncovering political ideology.
arXiv preprint arXiv:2208.04097.&lt;/code>&lt;/pre>
&lt;p>(&lt;em>see full paper here: &lt;a href="https://arxiv.org/pdf/2208.04097.pdf">https://arxiv.org/pdf/2208.04097.pdf&lt;/a>&lt;/em>)&lt;/p>
&lt;div id="ideology-in-an-online-world" class="section level2">
&lt;h2>Ideology in an Online World&lt;/h2>
&lt;p>Ideology determines how we make sense of much of the world, our opinions, and our political actions.
It is not a new concept; throughout history, it served as the context for unrest.
However, ideological spread and radicalization have entered a new paradigm in our ever-connected world. The internet is a significant source of information and spreads opinions quickly through social platforms.
In particular, the anonymity and lack of accountability often associated with online communication set up a supportive environment for spreading far-right ideologies and radicalizing individuals into extremist groups.
Far-right extremism is a form of ideology that advocates for ultranationalism, racism, and opposition to immigration and multiculturalism.
These ideologies strongly correlate with violence and terrorism and threaten individual and collective security.&lt;/p>
&lt;p>The Australian Security Intelligence Organisation (ASIO) raised concerns about Australians being radicalized very young and the rise of extremist movements in Australia through online technologies &lt;span class="citation">(&lt;a href="#ref-asio" role="doc-biblioref">&lt;span>“Director-General’s Annual Threat Assessment”&lt;/span> 2021&lt;/a>)&lt;/span>.
ASIO claimed that during the COVID period, 30-40% of their caseload was devoted to far-right extremism, up from 10-15% in 2016 &lt;span class="citation">(&lt;a href="#ref-guardian1" role="doc-biblioref">Karp 2020&lt;/a>)&lt;/span>.&lt;/p>
&lt;p>Unfortunately, Ideologically Motivated Violent Extremism (IMVE) continues to be an issue in Australia.
On December 12th, 2022, two Queensland police officers were killed while performing routine duties &lt;span class="citation">(&lt;a href="#ref-guardian2" role="doc-biblioref">Gillespie and McGowan 2022&lt;/a>)&lt;/span>.
Later investigations would uncover that the three people, who killed the officers, were active online in producing deep-state and religious conspiratorial content.
Their content has since been removed from mainstream social platforms but continues to be shared on conspiratorial websites.
Such extreme-leaning content often serves as a lead indicator of violent extremism (as was the case in this incident and the Christchurch Mosque Shootings three years prior). However, the tools to identify and understand the psychosocial characteristics of these extreme individuals and communities are lacking.&lt;/p>
&lt;p>In this work, we build an end-to-end ideology detection pipeline and psychosocial profiles of ideological groups.
We find that right-leaning individuals tend to use moral-vice language more than left-leaning and that far-right individuals’ grievance language (violence, hate, paranoia, etc.) significantly differs from the moderates.&lt;/p>
&lt;/div>
&lt;div id="signals-of-ideology" class="section level2">
&lt;h2>Signals of Ideology&lt;/h2>
&lt;p>In online social settings, researchers face numerous barriers that prevent using traditional methods.
Directly asking users for their ideologies has dubious success, infringes on platform T&amp;amp;Cs, and does not scale to online populations.
Inferring users’ ideologies from their activity also does not scale as the data requires is prohibitively expensive and tedious to compile.&lt;/p>
&lt;p>Instead, to reduce expert labor to feasible levels, researchers infer ideologies from signals in user behavior – such as whether they use political hashtags, retweet politicians, or follow political parties.
We dub these signals &lt;em>ideological proxies&lt;/em>.&lt;/p>
&lt;p>Importantly, these &lt;em>ideological proxies&lt;/em> for online users can still require laborious labeling by context-specific experts.
For example, the hashtag &lt;em>#ScottyFromMarketing&lt;/em> requires an up-to-date expert in Australian politics to uncover that it expresses an anti-right-wing ideology.
For many researchers:
- access to contextual experts is difficult,
- labeling of signals is still laborious and expensive,
- and context switches require relabelling (exasperating the above problems).&lt;/p>
&lt;p>Unfortunately, such context switches are commonplace, as the context changes with time, country, or social platform.
Figure &lt;a href="#fig:teaser">1&lt;/a> showcases the problem: most commonly used &lt;em>ideological proxies&lt;/em> can only be transferred in narrow circumstances (represented by the green dotted regions).
For example, following political parties is country-dependent, politicians come and go with time, and hashtags are platform-dependent.
As such, we desire an &lt;em>ideological proxy&lt;/em> that is robust to changes in context, requires no expert labeling and is true to the gold standard.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:teaser">&lt;/span>
&lt;img src="teaser_v2.svg" alt="Schema showing that not all ideological proxies can context-switch." width="700px" />
&lt;p class="caption">
Figure 1: Schema showing that not all ideological proxies can context-switch.
&lt;/p>
&lt;/div>
&lt;!-- ![Not all ideological proxies can context-switch](teaser.png) -->
&lt;p>Furthermore, the &lt;em>ideological proxies&lt;/em> are often sparse among users; however, we would ideally like to detect influence amongst the entire population of users (as taking only active users could bias our inferences).
We further desire a method for inferring the ideology of (potentially inactive) users without direct &lt;em>ideological proxy&lt;/em> information.&lt;/p>
&lt;/div>
&lt;div id="our-solution-you-are-what-you-browse" class="section level2">
&lt;h2>Our Solution: You are what you browse&lt;/h2>
&lt;p>Our solution is a large-scale end-to-end ideology detection pipeline that can be used to profile entire populations of users.
The solution has two main components; the media proxy and the inference architecture.
The media proxy allows for labeling a subset of users, and the inference architecture allows for propagating these labels to the remaining users via socially-informed homophilic lenses.&lt;/p>
&lt;div id="the-media-proxy" class="section level3">
&lt;h3>The Media Proxy&lt;/h3>
&lt;p>For the first part of our work, we generate a proxy based on media-sharing behavior, which satisfies the desiderata.&lt;/p>
&lt;p>We generate the media proxy via two media slant datasets (although many are widely available).
The first is an extensive survey of media consumption behaviors conducted by Reuters &lt;span class="citation">(&lt;a href="#ref-newman2019reuters" role="doc-biblioref">Newman et al. 2019&lt;/a>)&lt;/span> in several countries in 2020 and 2021.
Participants reported the media publications they consume and their own political ideology.
We estimate the slant of a media source for each country and year as the average ideology of the participants who consume it.
The second dataset is the Allsides Media Bias Dataset &lt;span class="citation">(&lt;a href="#ref-sides2018media" role="doc-biblioref">Sides 2018&lt;/a>)&lt;/span>, which contains an expert-curated set of media publications.
The Allsides dataset contains mostly American-based media; conversely, Reuters covers the major media outlets in each country.
Given that each country and period will have a different conception of ideologies, we calibrate Reuter’s media slants to approximate the Allsides (minimizing the mean-squared error). Figure &lt;a href="#fig:slants">2&lt;/a> shows the slants for each media website within the Reuters dataset.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:slants">&lt;/span>
&lt;img src="url_slants.svg" alt="Plot showing the slants for various media websites." width="700px" />
&lt;p class="caption">
Figure 2: Plot showing the slants for various media websites.
&lt;/p>
&lt;/div>
&lt;!-- ![The slants for various media websites](./url_slants.png) -->
&lt;!-- We finally define the media slant of a media website, as its average over the country, year, and sources, and -->
&lt;p>Finally, we quantify a user’s ideology as the average ideology of their shared media.&lt;/p>
&lt;p>The media proxy resolves the issue of context switching; since it is applicable across many contexts and can be used widely in a fully automated fashion.
This allows us to create an end-to-end ideology detection pipeline.&lt;/p>
&lt;p>We further define methods to classify far-right users from their media-sharing behaviors, which we fully describe in the paper.&lt;/p>
&lt;/div>
&lt;div id="the-inference-architecture" class="section level3">
&lt;h3>The Inference Architecture&lt;/h3>
&lt;p>In the second part of our work, we define an inference architecture that allows inferring the ideological labels of the remaining users – e.g., users who do not share any URLs.
Our inference architecture relies on the sociological principle of homophily, where we hypothesize that similar users will share a similar ideology.
We measure homophily through three distinct lenses;&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;em>Lexical&lt;/em>: Users with similar language will have similar ideology&lt;/li>
&lt;li>&lt;em>Hashtag&lt;/em>: Users who participate in similar topics of discussion share a similar ideology&lt;/li>
&lt;li>&lt;em>Resharing&lt;/em>: Users who consume similar content (signaled via resharing of other users) will share a similar ideology&lt;/li>
&lt;/ol>
&lt;p>Through these lenses, we utilize an AutoML model, FLAML &lt;span class="citation">(&lt;a href="#ref-wang2021flaml" role="doc-biblioref">Wang et al. 2021&lt;/a>)&lt;/span> (with the LightGBM architecture), trained on users identified via an ideological proxy to propagate the labels to the remaining users and generate a complete ideological profile for a dataset.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="the-data" class="section level2">
&lt;h2>The Data&lt;/h2>
&lt;p>We utilize several large-scale datasets from various platforms to showcase the relative ease of applying our end-to-end pipeline.
The datasets’ characteristics are described in Table &lt;a href="#tab:datasets">1&lt;/a>.
&lt;!-- For evaluation purposes, we use \#QandA based on the popular ABC panel show. -->&lt;/p>
&lt;table>
&lt;caption>&lt;span id="tab:datasets">Table 1: &lt;/span>The datasets used through-out the analysis, with the number of users, posts, and affliated country.&lt;/caption>
&lt;thead>
&lt;tr class="header">
&lt;th align="left">Dataset&lt;/th>
&lt;th align="left">Users&lt;/th>
&lt;th align="left">Posts&lt;/th>
&lt;th align="left">Country&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="left">#Qanda&lt;/td>
&lt;td align="left">103,074&lt;/td>
&lt;td align="left">768,808&lt;/td>
&lt;td align="left">AUS&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">#Ausvotes&lt;/td>
&lt;td align="left">273,874&lt;/td>
&lt;td align="left">5,033,982&lt;/td>
&lt;td align="left">AUS&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">#SocialSense&lt;/td>
&lt;td align="left">49,442&lt;/td>
&lt;td align="left">358,292&lt;/td>
&lt;td align="left">AUS&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">Riot&lt;/td>
&lt;td align="left">574,281&lt;/td>
&lt;td align="left">1,067,794&lt;/td>
&lt;td align="left">US&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">Parler&lt;/td>
&lt;td align="left">120,048&lt;/td>
&lt;td align="left">603,820&lt;/td>
&lt;td align="left">US&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;!-- ![The datasets we apply our pipeline on](datasets.png) -->
&lt;div id="psychosocial-profiles-of-the-ideological-groups" class="section level3">
&lt;h3>Psychosocial profiles of the Ideological Groups&lt;/h3>
&lt;p>Large-scale profiling of entire online populations gives us significant insights into the characteristics of online populations.
We apply our inferred ideological labels of online users in two critical ways:&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>We derive a method for distinguishing the left and the right in terms of their moral language.&lt;/li>
&lt;li>We derive a method for distinguishing moderate and extreme ideologies in terms of their grievance language.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Distinguishing Left and Right&lt;/strong>:
We utilize the FrameAxis &lt;span class="citation">(&lt;a href="#ref-mokhberian2020moral" role="doc-biblioref">Mokhberian et al. 2020&lt;/a>)&lt;/span> methodology to metricize each user’s association with each of the five Moral Foundations &lt;span class="citation">(&lt;a href="#ref-graham2013moral" role="doc-biblioref">Graham et al. 2013&lt;/a>)&lt;/span> in terms of their vice and virtue axes.
Given the measures of the Moral Foundations in the user language, we can start to detect in what way the left and the right differ.
To do this, we find each ideological group’s mean vice and virtue scores and compare these to the neutral group.
Figure &lt;a href="#fig:mft">3&lt;/a> shows the outcome of this analysis on the SocialSense dataset.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:mft">&lt;/span>
&lt;img src="mft_diff_plot.svg" alt="Plot of the moral foundations of ideological groups in the SocialSense dataset, showing that the left prefer virtue and the right prefer vice language." width="700px" />
&lt;p class="caption">
Figure 3: Plot of the moral foundations of ideological groups in the SocialSense dataset, showing that the left prefer virtue and the right prefer vice language.
&lt;/p>
&lt;/div>
&lt;!-- ![Plot showing that the left prefer virtue and the right prefer vice language](mft_diff_plot.png) -->
&lt;p>We see that the left prefers the language of virtue, while the right prefers the language of vice.
This trend is largely consistent across all datasets.&lt;/p>
&lt;p>&lt;strong>Distinguishing Moderates and Extremes&lt;/strong>: We similarly generate measures via the Grievance Dictionary &lt;span class="citation">(&lt;a href="#ref-van2021grievance" role="doc-biblioref">Van der Vegt et al. 2021&lt;/a>)&lt;/span>, a threat assessment tool designed to highlight potential threats through their language.
Similar to the previous plot, we investigate the distribution of grievance scores for the ideological groups.
However, here we measure the difference between distributions with the Signed KL-divergence (a measure of the difference in the location and shape of distributions).
Figure &lt;a href="#fig:grievance">4&lt;/a> shows the results for the Ausvotes dataset.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:grievance">&lt;/span>
&lt;img src="grievance_diff_plot.svg" alt="Plot of the grievance categories of ideological groups in the #Ausvotes dataset, showing that the far-right is significantly different." width="700px" />
&lt;p class="caption">
Figure 4: Plot of the grievance categories of ideological groups in the #Ausvotes dataset, showing that the far-right is significantly different.
&lt;/p>
&lt;/div>
&lt;!-- ![Plot showing that the far-right use grievance language](grievance_diff_plot.png) -->
&lt;p>We observe that the far-right’s usage of grievance language is significantly different from the moderate ideological groups.
This adds evidence to the growing concern that members of the far-right may vent their frustration and participate in violent behavior.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="conclusion" class="section level2">
&lt;h2>Conclusion&lt;/h2>
&lt;p>In this work, we build a fully automatic end-to-end ideology detection pipeline for left-right and far-right detection.
Importantly, with the pipeline, we can show the differences between the left and right, and moderates and extremes in terms of psychosocial language, across a range of diverse datasets.&lt;/p>
&lt;div id="references" class="section level3 unnumbered">
&lt;h3>References&lt;/h3>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-asio" class="csl-entry">
&lt;span>“Director-General’s Annual Threat Assessment.”&lt;/span> 2021. &lt;em>ASIO&lt;/em>. &lt;a href="https://www.asio.gov.au/resources/speeches-and-statements/director-generals-annual-threat-assessment-2021">https://www.asio.gov.au/resources/speeches-and-statements/director-generals-annual-threat-assessment-2021&lt;/a>.
&lt;/div>
&lt;div id="ref-guardian2" class="csl-entry">
Gillespie, Eden, and Michael McGowan. 2022. &lt;span>“Queensland Shooting: Gareth and Stacey Train Published YouTube Video After Killing Police Officers.”&lt;/span> &lt;a href="https://www.theguardian.com/australia-news/2022/dec/16/queensland-shooting-gareth-and-stacey-train-youtube-video-published-after-killing-police" class="uri">https://www.theguardian.com/australia-news/2022/dec/16/queensland-shooting-gareth-and-stacey-train-youtube-video-published-after-killing-police&lt;/a>; The Guardian.
&lt;/div>
&lt;div id="ref-graham2013moral" class="csl-entry">
Graham, Jesse, Jonathan Haidt, Sena Koleva, Matt Motyl, Ravi Iyer, Sean P Wojcik, and Peter H Ditto. 2013. &lt;span>“Moral Foundations Theory: The Pragmatic Validity of Moral Pluralism.”&lt;/span> In &lt;em>Advances in Experimental Social Psychology&lt;/em>, 47:55–130. Elsevier.
&lt;/div>
&lt;div id="ref-guardian1" class="csl-entry">
Karp, Paul. 2020. &lt;span>“Asio Reveals up to 40% of Its Counter-Terrorism Cases Involve Far-Right Violent Extremism.”&lt;/span> &lt;a href="https://www.theguardian.com/australia-news/2020/sep/22/asio-reveals-up-to-40-of-its-counter-terrorism-cases-involve-far-right-violent-extremism" class="uri">https://www.theguardian.com/australia-news/2020/sep/22/asio-reveals-up-to-40-of-its-counter-terrorism-cases-involve-far-right-violent-extremism&lt;/a>; The Guardian.
&lt;/div>
&lt;div id="ref-mokhberian2020moral" class="csl-entry">
Mokhberian, Negar, Andrés Abeliuk, Patrick Cummings, and Kristina Lerman. 2020. &lt;span>“Moral Framing and Ideological Bias of News.”&lt;/span> In &lt;em>International Conference on Social Informatics&lt;/em>, 206–19. Springer.
&lt;/div>
&lt;div id="ref-newman2019reuters" class="csl-entry">
Newman, Nic, Richard Fletcher, Antonis Kalogeropoulos, DAL Levy, and Rasmus Kleis Nielsen. 2019. &lt;span>“Reuters Institute Digital News Report 2018. Reuters Institute for the Study of Journalism.”&lt;/span> Oxford.
&lt;/div>
&lt;div id="ref-sides2018media" class="csl-entry">
Sides, All. 2018. &lt;span>“Media Bias Ratings.”&lt;/span> &lt;em>Allsides. Com&lt;/em>. &lt;a href="https://www.allsides.com/media-bias/ratings">https://www.allsides.com/media-bias/ratings&lt;/a>.
&lt;/div>
&lt;div id="ref-van2021grievance" class="csl-entry">
Van der Vegt, Isabelle, Maximilian Mozes, Bennett Kleinberg, and Paul Gill. 2021. &lt;span>“The Grievance Dictionary: Understanding Threatening Language Use.”&lt;/span> &lt;em>Behavior Research Methods&lt;/em> 53 (5): 2105–19.
&lt;/div>
&lt;div id="ref-wang2021flaml" class="csl-entry">
Wang, Chi, Qingyun Wu, Markus Weimer, and Erkang Zhu. 2021. &lt;span>“FLAML: A Fast and Lightweight Automl Library.”&lt;/span> &lt;em>Proceedings of Machine Learning and Systems&lt;/em> 3: 434–47.
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Detecting extreme ideologies in shifting landscapes</title><link>https://www.behavioral-ds.science/theme1_content/ideology_detection/</link><pubDate>Thu, 02 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme1_content/ideology_detection/</guid><description>
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/csWMgU7R52Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
&lt;/iframe>
&lt;p>Also check out &lt;a href="../authors/rohit-ram/">Rohit&lt;/a>’s and &lt;a href="../authors/ma-rizoiu/">Andrei&lt;/a>’s article that just appeared in The Conversation: &lt;a href="https://theconversation.com/can-ideology-detecting-algorithms-catch-online-extremism-before-it-takes-hold-200629">Can ideology-detecting algorithms catch online extremism before it takes hold?&lt;/a>&lt;/p>
&lt;p>In this &lt;a href="https://arxiv.org/pdf/2208.04097.pdf">our latest working paper&lt;/a>, we propose a completely automatic end-to-end ideology detection pipeline for the detection and psychosocial profiling of left-right political ideology, as well as far-right ideological users.
The pipeline fills a crucial gap by providing flexible methodology and tooling for understanding ideologies and building early warning systems for extreme ideology-motivated (and potentially violent) activity.&lt;/p>
&lt;p>&lt;strong>Paper citation:&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Ram, R. and Rizoiu, M.A., 2022. You are what you browse: A robust framework for uncovering political ideology.
arXiv preprint arXiv:2208.04097.&lt;/code>&lt;/pre>
&lt;p>(&lt;em>see full paper here: &lt;a href="https://arxiv.org/pdf/2208.04097.pdf">https://arxiv.org/pdf/2208.04097.pdf&lt;/a>&lt;/em>)&lt;/p>
&lt;div id="ideology-in-an-online-world" class="section level2">
&lt;h2>Ideology in an Online World&lt;/h2>
&lt;p>Ideology determines how we make sense of much of the world, our opinions, and our political actions.
It is not a new concept; throughout history, it served as the context for unrest.
However, ideological spread and radicalization have entered a new paradigm in our ever-connected world. The internet is a significant source of information and spreads opinions quickly through social platforms.
In particular, the anonymity and lack of accountability often associated with online communication set up a supportive environment for spreading far-right ideologies and radicalizing individuals into extremist groups.
Far-right extremism is a form of ideology that advocates for ultranationalism, racism, and opposition to immigration and multiculturalism.
These ideologies strongly correlate with violence and terrorism and threaten individual and collective security.&lt;/p>
&lt;p>The Australian Security Intelligence Organisation (ASIO) raised concerns about Australians being radicalized very young and the rise of extremist movements in Australia through online technologies &lt;span class="citation">(&lt;a href="#ref-asio" role="doc-biblioref">&lt;span>“Director-General’s Annual Threat Assessment”&lt;/span> 2021&lt;/a>)&lt;/span>.
ASIO claimed that during the COVID period, 30-40% of their caseload was devoted to far-right extremism, up from 10-15% in 2016 &lt;span class="citation">(&lt;a href="#ref-guardian1" role="doc-biblioref">Karp 2020&lt;/a>)&lt;/span>.&lt;/p>
&lt;p>Unfortunately, Ideologically Motivated Violent Extremism (IMVE) continues to be an issue in Australia.
On December 12th, 2022, two Queensland police officers were killed while performing routine duties &lt;span class="citation">(&lt;a href="#ref-guardian2" role="doc-biblioref">Gillespie and McGowan 2022&lt;/a>)&lt;/span>.
Later investigations would uncover that the three people, who killed the officers, were active online in producing deep-state and religious conspiratorial content.
Their content has since been removed from mainstream social platforms but continues to be shared on conspiratorial websites.
Such extreme-leaning content often serves as a lead indicator of violent extremism (as was the case in this incident and the Christchurch Mosque Shootings three years prior). However, the tools to identify and understand the psychosocial characteristics of these extreme individuals and communities are lacking.&lt;/p>
&lt;p>In this work, we build an end-to-end ideology detection pipeline and psychosocial profiles of ideological groups.
We find that right-leaning individuals tend to use moral-vice language more than left-leaning and that far-right individuals’ grievance language (violence, hate, paranoia, etc.) significantly differs from the moderates.&lt;/p>
&lt;/div>
&lt;div id="signals-of-ideology" class="section level2">
&lt;h2>Signals of Ideology&lt;/h2>
&lt;p>In online social settings, researchers face numerous barriers that prevent using traditional methods.
Directly asking users for their ideologies has dubious success, infringes on platform T&amp;amp;Cs, and does not scale to online populations.
Inferring users’ ideologies from their activity also does not scale as the data requires is prohibitively expensive and tedious to compile.&lt;/p>
&lt;p>Instead, to reduce expert labor to feasible levels, researchers infer ideologies from signals in user behavior – such as whether they use political hashtags, retweet politicians, or follow political parties.
We dub these signals &lt;em>ideological proxies&lt;/em>.&lt;/p>
&lt;p>Importantly, these &lt;em>ideological proxies&lt;/em> for online users can still require laborious labeling by context-specific experts.
For example, the hashtag &lt;em>#ScottyFromMarketing&lt;/em> requires an up-to-date expert in Australian politics to uncover that it expresses an anti-right-wing ideology.
For many researchers:
- access to contextual experts is difficult,
- labeling of signals is still laborious and expensive,
- and context switches require relabelling (exasperating the above problems).&lt;/p>
&lt;p>Unfortunately, such context switches are commonplace, as the context changes with time, country, or social platform.
Figure &lt;a href="#fig:teaser">1&lt;/a> showcases the problem: most commonly used &lt;em>ideological proxies&lt;/em> can only be transferred in narrow circumstances (represented by the green dotted regions).
For example, following political parties is country-dependent, politicians come and go with time, and hashtags are platform-dependent.
As such, we desire an &lt;em>ideological proxy&lt;/em> that is robust to changes in context, requires no expert labeling and is true to the gold standard.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:teaser">&lt;/span>
&lt;img src="teaser_v2.svg" alt="Schema showing that not all ideological proxies can context-switch." width="700px" />
&lt;p class="caption">
Figure 1: Schema showing that not all ideological proxies can context-switch.
&lt;/p>
&lt;/div>
&lt;!-- ![Not all ideological proxies can context-switch](teaser.png) -->
&lt;p>Furthermore, the &lt;em>ideological proxies&lt;/em> are often sparse among users; however, we would ideally like to detect influence amongst the entire population of users (as taking only active users could bias our inferences).
We further desire a method for inferring the ideology of (potentially inactive) users without direct &lt;em>ideological proxy&lt;/em> information.&lt;/p>
&lt;/div>
&lt;div id="our-solution-you-are-what-you-browse" class="section level2">
&lt;h2>Our Solution: You are what you browse&lt;/h2>
&lt;p>Our solution is a large-scale end-to-end ideology detection pipeline that can be used to profile entire populations of users.
The solution has two main components; the media proxy and the inference architecture.
The media proxy allows for labeling a subset of users, and the inference architecture allows for propagating these labels to the remaining users via socially-informed homophilic lenses.&lt;/p>
&lt;div id="the-media-proxy" class="section level3">
&lt;h3>The Media Proxy&lt;/h3>
&lt;p>For the first part of our work, we generate a proxy based on media-sharing behavior, which satisfies the desiderata.&lt;/p>
&lt;p>We generate the media proxy via two media slant datasets (although many are widely available).
The first is an extensive survey of media consumption behaviors conducted by Reuters &lt;span class="citation">(&lt;a href="#ref-newman2019reuters" role="doc-biblioref">Newman et al. 2019&lt;/a>)&lt;/span> in several countries in 2020 and 2021.
Participants reported the media publications they consume and their own political ideology.
We estimate the slant of a media source for each country and year as the average ideology of the participants who consume it.
The second dataset is the Allsides Media Bias Dataset &lt;span class="citation">(&lt;a href="#ref-sides2018media" role="doc-biblioref">Sides 2018&lt;/a>)&lt;/span>, which contains an expert-curated set of media publications.
The Allsides dataset contains mostly American-based media; conversely, Reuters covers the major media outlets in each country.
Given that each country and period will have a different conception of ideologies, we calibrate Reuter’s media slants to approximate the Allsides (minimizing the mean-squared error). Figure &lt;a href="#fig:slants">2&lt;/a> shows the slants for each media website within the Reuters dataset.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:slants">&lt;/span>
&lt;img src="url_slants.svg" alt="Plot showing the slants for various media websites." width="700px" />
&lt;p class="caption">
Figure 2: Plot showing the slants for various media websites.
&lt;/p>
&lt;/div>
&lt;!-- ![The slants for various media websites](./url_slants.png) -->
&lt;!-- We finally define the media slant of a media website, as its average over the country, year, and sources, and -->
&lt;p>Finally, we quantify a user’s ideology as the average ideology of their shared media.&lt;/p>
&lt;p>The media proxy resolves the issue of context switching; since it is applicable across many contexts and can be used widely in a fully automated fashion.
This allows us to create an end-to-end ideology detection pipeline.&lt;/p>
&lt;p>We further define methods to classify far-right users from their media-sharing behaviors, which we fully describe in the paper.&lt;/p>
&lt;/div>
&lt;div id="the-inference-architecture" class="section level3">
&lt;h3>The Inference Architecture&lt;/h3>
&lt;p>In the second part of our work, we define an inference architecture that allows inferring the ideological labels of the remaining users – e.g., users who do not share any URLs.
Our inference architecture relies on the sociological principle of homophily, where we hypothesize that similar users will share a similar ideology.
We measure homophily through three distinct lenses;&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;em>Lexical&lt;/em>: Users with similar language will have similar ideology&lt;/li>
&lt;li>&lt;em>Hashtag&lt;/em>: Users who participate in similar topics of discussion share a similar ideology&lt;/li>
&lt;li>&lt;em>Resharing&lt;/em>: Users who consume similar content (signaled via resharing of other users) will share a similar ideology&lt;/li>
&lt;/ol>
&lt;p>Through these lenses, we utilize an AutoML model, FLAML &lt;span class="citation">(&lt;a href="#ref-wang2021flaml" role="doc-biblioref">Wang et al. 2021&lt;/a>)&lt;/span> (with the LightGBM architecture), trained on users identified via an ideological proxy to propagate the labels to the remaining users and generate a complete ideological profile for a dataset.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="the-data" class="section level2">
&lt;h2>The Data&lt;/h2>
&lt;p>We utilize several large-scale datasets from various platforms to showcase the relative ease of applying our end-to-end pipeline.
The datasets’ characteristics are described in Table &lt;a href="#tab:datasets">1&lt;/a>.
&lt;!-- For evaluation purposes, we use \#QandA based on the popular ABC panel show. -->&lt;/p>
&lt;table>
&lt;caption>&lt;span id="tab:datasets">Table 1: &lt;/span>The datasets used through-out the analysis, with the number of users, posts, and affliated country.&lt;/caption>
&lt;thead>
&lt;tr class="header">
&lt;th align="left">Dataset&lt;/th>
&lt;th align="left">Users&lt;/th>
&lt;th align="left">Posts&lt;/th>
&lt;th align="left">Country&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="left">#Qanda&lt;/td>
&lt;td align="left">103,074&lt;/td>
&lt;td align="left">768,808&lt;/td>
&lt;td align="left">AUS&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">#Ausvotes&lt;/td>
&lt;td align="left">273,874&lt;/td>
&lt;td align="left">5,033,982&lt;/td>
&lt;td align="left">AUS&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">#SocialSense&lt;/td>
&lt;td align="left">49,442&lt;/td>
&lt;td align="left">358,292&lt;/td>
&lt;td align="left">AUS&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">Riot&lt;/td>
&lt;td align="left">574,281&lt;/td>
&lt;td align="left">1,067,794&lt;/td>
&lt;td align="left">US&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">Parler&lt;/td>
&lt;td align="left">120,048&lt;/td>
&lt;td align="left">603,820&lt;/td>
&lt;td align="left">US&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;!-- ![The datasets we apply our pipeline on](datasets.png) -->
&lt;div id="psychosocial-profiles-of-the-ideological-groups" class="section level3">
&lt;h3>Psychosocial profiles of the Ideological Groups&lt;/h3>
&lt;p>Large-scale profiling of entire online populations gives us significant insights into the characteristics of online populations.
We apply our inferred ideological labels of online users in two critical ways:&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>We derive a method for distinguishing the left and the right in terms of their moral language.&lt;/li>
&lt;li>We derive a method for distinguishing moderate and extreme ideologies in terms of their grievance language.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Distinguishing Left and Right&lt;/strong>:
We utilize the FrameAxis &lt;span class="citation">(&lt;a href="#ref-mokhberian2020moral" role="doc-biblioref">Mokhberian et al. 2020&lt;/a>)&lt;/span> methodology to metricize each user’s association with each of the five Moral Foundations &lt;span class="citation">(&lt;a href="#ref-graham2013moral" role="doc-biblioref">Graham et al. 2013&lt;/a>)&lt;/span> in terms of their vice and virtue axes.
Given the measures of the Moral Foundations in the user language, we can start to detect in what way the left and the right differ.
To do this, we find each ideological group’s mean vice and virtue scores and compare these to the neutral group.
Figure &lt;a href="#fig:mft">3&lt;/a> shows the outcome of this analysis on the SocialSense dataset.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:mft">&lt;/span>
&lt;img src="mft_diff_plot.svg" alt="Plot of the moral foundations of ideological groups in the SocialSense dataset, showing that the left prefer virtue and the right prefer vice language." width="700px" />
&lt;p class="caption">
Figure 3: Plot of the moral foundations of ideological groups in the SocialSense dataset, showing that the left prefer virtue and the right prefer vice language.
&lt;/p>
&lt;/div>
&lt;!-- ![Plot showing that the left prefer virtue and the right prefer vice language](mft_diff_plot.png) -->
&lt;p>We see that the left prefers the language of virtue, while the right prefers the language of vice.
This trend is largely consistent across all datasets.&lt;/p>
&lt;p>&lt;strong>Distinguishing Moderates and Extremes&lt;/strong>: We similarly generate measures via the Grievance Dictionary &lt;span class="citation">(&lt;a href="#ref-van2021grievance" role="doc-biblioref">Van der Vegt et al. 2021&lt;/a>)&lt;/span>, a threat assessment tool designed to highlight potential threats through their language.
Similar to the previous plot, we investigate the distribution of grievance scores for the ideological groups.
However, here we measure the difference between distributions with the Signed KL-divergence (a measure of the difference in the location and shape of distributions).
Figure &lt;a href="#fig:grievance">4&lt;/a> shows the results for the Ausvotes dataset.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:grievance">&lt;/span>
&lt;img src="grievance_diff_plot.svg" alt="Plot of the grievance categories of ideological groups in the #Ausvotes dataset, showing that the far-right is significantly different." width="700px" />
&lt;p class="caption">
Figure 4: Plot of the grievance categories of ideological groups in the #Ausvotes dataset, showing that the far-right is significantly different.
&lt;/p>
&lt;/div>
&lt;!-- ![Plot showing that the far-right use grievance language](grievance_diff_plot.png) -->
&lt;p>We observe that the far-right’s usage of grievance language is significantly different from the moderate ideological groups.
This adds evidence to the growing concern that members of the far-right may vent their frustration and participate in violent behavior.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="conclusion" class="section level2">
&lt;h2>Conclusion&lt;/h2>
&lt;p>In this work, we build a fully automatic end-to-end ideology detection pipeline for left-right and far-right detection.
Importantly, with the pipeline, we can show the differences between the left and right, and moderates and extremes in terms of psychosocial language, across a range of diverse datasets.&lt;/p>
&lt;div id="references" class="section level3 unnumbered">
&lt;h3>References&lt;/h3>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-asio" class="csl-entry">
&lt;span>“Director-General’s Annual Threat Assessment.”&lt;/span> 2021. &lt;em>ASIO&lt;/em>. &lt;a href="https://www.asio.gov.au/resources/speeches-and-statements/director-generals-annual-threat-assessment-2021">https://www.asio.gov.au/resources/speeches-and-statements/director-generals-annual-threat-assessment-2021&lt;/a>.
&lt;/div>
&lt;div id="ref-guardian2" class="csl-entry">
Gillespie, Eden, and Michael McGowan. 2022. &lt;span>“Queensland Shooting: Gareth and Stacey Train Published YouTube Video After Killing Police Officers.”&lt;/span> &lt;a href="https://www.theguardian.com/australia-news/2022/dec/16/queensland-shooting-gareth-and-stacey-train-youtube-video-published-after-killing-police" class="uri">https://www.theguardian.com/australia-news/2022/dec/16/queensland-shooting-gareth-and-stacey-train-youtube-video-published-after-killing-police&lt;/a>; The Guardian.
&lt;/div>
&lt;div id="ref-graham2013moral" class="csl-entry">
Graham, Jesse, Jonathan Haidt, Sena Koleva, Matt Motyl, Ravi Iyer, Sean P Wojcik, and Peter H Ditto. 2013. &lt;span>“Moral Foundations Theory: The Pragmatic Validity of Moral Pluralism.”&lt;/span> In &lt;em>Advances in Experimental Social Psychology&lt;/em>, 47:55–130. Elsevier.
&lt;/div>
&lt;div id="ref-guardian1" class="csl-entry">
Karp, Paul. 2020. &lt;span>“Asio Reveals up to 40% of Its Counter-Terrorism Cases Involve Far-Right Violent Extremism.”&lt;/span> &lt;a href="https://www.theguardian.com/australia-news/2020/sep/22/asio-reveals-up-to-40-of-its-counter-terrorism-cases-involve-far-right-violent-extremism" class="uri">https://www.theguardian.com/australia-news/2020/sep/22/asio-reveals-up-to-40-of-its-counter-terrorism-cases-involve-far-right-violent-extremism&lt;/a>; The Guardian.
&lt;/div>
&lt;div id="ref-mokhberian2020moral" class="csl-entry">
Mokhberian, Negar, Andrés Abeliuk, Patrick Cummings, and Kristina Lerman. 2020. &lt;span>“Moral Framing and Ideological Bias of News.”&lt;/span> In &lt;em>International Conference on Social Informatics&lt;/em>, 206–19. Springer.
&lt;/div>
&lt;div id="ref-newman2019reuters" class="csl-entry">
Newman, Nic, Richard Fletcher, Antonis Kalogeropoulos, DAL Levy, and Rasmus Kleis Nielsen. 2019. &lt;span>“Reuters Institute Digital News Report 2018. Reuters Institute for the Study of Journalism.”&lt;/span> Oxford.
&lt;/div>
&lt;div id="ref-sides2018media" class="csl-entry">
Sides, All. 2018. &lt;span>“Media Bias Ratings.”&lt;/span> &lt;em>Allsides. Com&lt;/em>. &lt;a href="https://www.allsides.com/media-bias/ratings">https://www.allsides.com/media-bias/ratings&lt;/a>.
&lt;/div>
&lt;div id="ref-van2021grievance" class="csl-entry">
Van der Vegt, Isabelle, Maximilian Mozes, Bennett Kleinberg, and Paul Gill. 2021. &lt;span>“The Grievance Dictionary: Understanding Threatening Language Use.”&lt;/span> &lt;em>Behavior Research Methods&lt;/em> 53 (5): 2105–19.
&lt;/div>
&lt;div id="ref-wang2021flaml" class="csl-entry">
Wang, Chi, Qingyun Wu, Markus Weimer, and Erkang Zhu. 2021. &lt;span>“FLAML: A Fast and Lightweight Automl Library.”&lt;/span> &lt;em>Proceedings of Machine Learning and Systems&lt;/em> 3: 434–47.
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>birdspotter: A toolkit for analyzing and labelling Twitter users</title><link>https://www.behavioral-ds.science/theme2_content/birdspotter/</link><pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme2_content/birdspotter/</guid><description>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/52HwHAiK1rs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;!-- &lt;img src="https://www.behavioral-ds.science/img/birdspotter_logo.png" alt="Birdspotter Logo" width="200"/> -->
&lt;!-- Motivation -->
&lt;!-- Framing: Problem -> Solution -->
&lt;!-- Context -->
&lt;p>Social media platforms, although relatively new, host millions of users and billions of interactions daily. As tied as we are to these platforms, they profoundly impact our social institutions through phenomena such as disinformation, political polarization, and social bots.&lt;/p>
&lt;!-- Problem -->
&lt;p>Researchers are increasingly interested in trying to form an understanding of phenomena and their implications. Social scientists, political scientists, and data practitioners alike curate expansive datasets to combat these potentially adverse effects on our society; however, they lack the appropriate tooling.&lt;/p>
&lt;!-- Solution -->
&lt;p>&lt;code>birdspotter&lt;/code> is an &lt;strong>easy-to-use&lt;/strong> tool that models Twitter users&amp;rsquo; attributes and labels them. It comes prepackaged with a &lt;strong>state-of-the-art bot detector&lt;/strong> and an &lt;strong>influence quantification&lt;/strong> system based on tweet dynamics. &lt;code>birdspotter&lt;/code> features a generalized user labeler, which can be retrained easily with the engineered features to address a variety of use cases. Also, &lt;a href="http://birdspotter.ml/">birdspotter.ml&lt;/a> is a web application that can be utilized to explore datasets and derive a narrative around a dataset.&lt;/p>
&lt;p>In this post, I'll showcase the basic usage of &lt;code>birdspotter&lt;/code> and &lt;a href="http://birdspotter.ml/">birdspotter.ml&lt;/a>.&lt;/p>
&lt;h2 id="installation">Installation&lt;/h2>
&lt;p>The package can be installed in the canonical python way:&lt;/p>
&lt;pre>&lt;code class="language-{bash}">pip install birdspotter
&lt;/code>&lt;/pre>
&lt;h2 id="getting-a-dataset">Getting a dataset&lt;/h2>
&lt;p>The Twitter T&amp;amp;Cs restrict the sharing of tweet data directly online; however, they do allow the sharing of tweet-ids, which can be converted to full tweet data through a process called &lt;em>hydration&lt;/em>. Tools like &lt;a href="https://github.com/DocNow/twarc">twarc&lt;/a> can be used to hydrate a Tweet ID dataset. The resulting dataset will be in &lt;code>jsonl&lt;/code> (line delimited &lt;code>json&lt;/code>) format, which &lt;code>birdspotter&lt;/code> accepts directly.&lt;/p>
&lt;p>In the below examples, we use two datasets; a collection of COVID-19 related tweets from January 31st, 2020 [1], and a collection of tweets about politicians on Twitter [2].&lt;/p>
&lt;p>The politicians&amp;rsquo; dataset was acquired through the following process (and a similar process was taken for the COVID-19 dataset):&lt;/p>
&lt;pre>&lt;code class="language-{bash}">pip install twarc
wget http://twitterpoliticians.org./downloads/base/all_tweet_ids.csv
twarc hydrate all_tweet_ids.csv &amp;gt; tweets.jsonl
&lt;/code>&lt;/pre>
&lt;h2 id="basic-usage">Basic Usage&lt;/h2>
&lt;p>The code below imports the main class &lt;code>Birdspotter&lt;/code>, extracts the tweets from their standard format, labels the users with the default bot detector and influence, and reformats the retweet cascades into a tidier format.&lt;/p>
&lt;pre>&lt;code class="language-{python}">## Import birdspotter
from birdspotter import BirdSpotter
## Extracts the tweets from the raw jsonl [https://github.com/echen102/COVID-19-TweetIDs]
bs = BirdSpotter('covid19.jsonl')
## Uses the default bot labeller and influence quantification systems
bs.getLabeledUsers()
## Formats the retweet cascades, such that expected retweet structures can extracted
bs.getCascadesDataFrame()
## Access the botness labels and influence scores
bs.featureDataframe[['botness', 'influence']]
&lt;/code>&lt;/pre>
&lt;p>From here, the dataset is readily profile-able:&lt;/p>
&lt;pre>&lt;code class="language-{python}">botness_dist = sns.histplot(data=bs.featureDataframe, x=&amp;quot;botness&amp;quot;)
influence_eccdf = sns.ecdfplot(data=bs.featureDataframe, x=&amp;quot;influence&amp;quot;, complementary=True).set(xscale=&amp;quot;log&amp;quot;, yscale=&amp;quot;log&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://www.behavioral-ds.science/img/covid_profile.png" alt="COVID Dataset Profile: (Left) The distribution of bot scores of users; (Right) The ECCDF of influence scores of users, showing a long-tailed (rich-gets-richer) paradigm">&lt;/p>
&lt;h2 id="the-visualizer">The visualizer&lt;/h2>
&lt;p>An alternative way to profile a dataset is the use &lt;a href="http://birdspotter.ml">&lt;code>birdspotter.ml&lt;/code>&lt;/a>, which facilitates dataset exploration and narrative construction.&lt;/p>
&lt;p>&lt;img src="https://www.behavioral-ds.science/img/auspol_teaser.png" alt="birdspotter.ml visualizer: The various components shown include the scatterplot panel (Left), the user information panel (Top Right), and the retweet cascades panel (Bottom Right)">&lt;/p>
&lt;p>The visualizer features a scatterplot (on the left) of influence and botness for a sample of users and the population density. The colors represent the hashtags (a proxy for the topic) that the users most tweet about in the dataset. Users within the scatterplot are hoverable and selectable, and their information populates in the components on the right.&lt;/p>
&lt;p>The top right component shows information and metrics about the selected user and links the user's profile.&lt;/p>
&lt;p>The bottom right component shows the retweet cascades where a user has participated and highlights their participation. The points represent the follower counts (social capital) of users and their retweets/tweets&amp;rsquo; timing. The points are also hoverable and selectable.&lt;/p>
&lt;h2 id="customising-the-labeller">Customising the labeller&lt;/h2>
&lt;p>By default, the labeler is trained as a bot detection system, comparable to the state-of-the-art &lt;a href="https://botometer.osome.iu.edu/">&lt;code>botometer&lt;/code>&lt;/a>. Notable, &lt;code>birdspotter&lt;/code> is provided in an offline package and can be applied at scale, while &lt;code>botometer&lt;/code> is accessible only via an online API, which is often prohibitively rate-limited.&lt;/p>
&lt;p>&lt;code>birdspotter&lt;/code> is a versatile tool and can be utilized by practitioners for a variety of use-cases. For example, we could train the labeler to identify political leaning. This process is a bit involved, so we summarise it below;&lt;/p>
&lt;ol>
&lt;li>We hydrate some tweets from the Twitter Parlimentarian Database&lt;/li>
&lt;li>We filter the tweets to include only &lt;strong>Australian Politicians&lt;/strong>.&lt;/li>
&lt;li>We &lt;strong>label right-wing partied politicians positively&lt;/strong>, and others negatively (with &lt;code>bs_pol.getBotAnnotationTemplate&lt;/code> for example)&lt;/li>
&lt;li>We &lt;strong>retrain &lt;code>birdspotter&lt;/code>&lt;/strong> with these new labels and label all users (i.e., including users the politicians retweeted) using the new model&lt;/li>
&lt;/ol>
&lt;!-- ```{python class.source = 'fold-hide'} -->
&lt;!-- # This is the guts of the code; it does what is described above -->
&lt;!-- politicians = pd.read_csv('./full_member_info.csv', encoding='utf16') -->
&lt;!-- politicians_aus = politicians[politicians['country'] == 'Australia'] -->
&lt;!-- politicians_aus_available = politicians_aus[~politicians_aus['uid'].isnull()] -->
&lt;!-- def classify_party(party_id): -->
&lt;!-- mapping = { -->
&lt;!-- 464 : 1, # Liberal Party of Australia -->
&lt;!-- 465 : -1, # Australian Labor Party -->
&lt;!-- 467 : 1, # The Nationals -->
&lt;!-- 468 : 0, # Nick Xenophon Team -->
&lt;!-- 469 : -1, # Australian Greens -->
&lt;!-- 471 : np.nan, -->
&lt;!-- 475 : 1, # Katter's Australian Party -->
&lt;!-- } -->
&lt;!-- return mapping[party_id] -->
&lt;!-- politicians_aus_available['isright'] = politicians_aus_available['party_id'].apply(classify_party) -->
&lt;!-- politicians_aus_available['user_id'] = politicians_aus_available['uid'].astype(int).astype(str) -->
&lt;!-- politicians_aus_available = politicians_aus_available.set_index('user_id') -->
&lt;!-- with open('./tweets.jsonl', 'r') as rf, open('./aus_tweets.jsonl', 'w') as wf: -->
&lt;!-- for line in tqdm(rf): -->
&lt;!-- try: -->
&lt;!-- j = json.loads(line) -->
&lt;!-- if j['user']['id_str'] in politicians_aus_available['uid'].astype(int).astype(str).values: -->
&lt;!-- wf.write(json.dumps(j) + '\n') -->
&lt;!-- except Exception as e: -->
&lt;!-- print(j) -->
&lt;!-- print(e) -->
&lt;!-- break -->
&lt;!-- bs = BirdSpotter('aus_tweets.jsonl') -->
&lt;!-- bs.getLabeledUsers() -->
&lt;!-- bs.getCascadesDataFrame() -->
&lt;!-- with open('bs_aus_module.pk', 'wb') as wf: -->
&lt;!-- pk.dump(bs,wf, protocol=4) -->
&lt;!-- bs.featureDataframe['isright'] = politicians_aus_available['isright'] -->
&lt;!-- ground_truth = bs.featureDataframe[~bs.featureDataframe['isright'].isnull()][['isright']] -->
&lt;!-- ground_truth['isbot'] = ground_truth['isright'] == 1 -->
&lt;!-- ground_truth = ground_truth[~ground_truth.index.duplicated()] -->
&lt;!-- data = bs.featureDataframe.copy()[bs.featureDataframe.index.isin(ground_truth.index)] -->
&lt;!-- data = data[~data.index.duplicated()] -->
&lt;!-- del data['isright'] -->
&lt;!-- del data['botness'] -->
&lt;!-- del data['influence'] -->
&lt;!-- del data['cascade_membership'] -->
&lt;!-- data = data[list(data.columns[data.dtypes != 'object'])] -->
&lt;!-- data['isbot'] = ground_truth['isbot'].loc[data.index] -->
&lt;!-- with open('pol_training_data.pickle', 'wb') as wf: -->
&lt;!-- pk.dump(data,wf, protocol=4) -->
&lt;!-- from birdspotter import BirdSpotter -->
&lt;!-- import pickle as pk -->
&lt;!-- # bs_pol = BirdSpotter('aus_tweets.jsonl') -->
&lt;!-- with open('bs_aus_module.pk', 'rb') as rf: -->
&lt;!-- bs_pol = pk.load(rf) -->
&lt;!-- print("Loaded module") -->
&lt;!-- bs_pol.trainClassifierModel('pol_training_data.pickle') -->
&lt;!-- print("finished training") -->
&lt;!-- del bs_pol.featureDataframe['botness'] -->
&lt;!-- print("removed botness column") -->
&lt;!-- bs_pol.getBotness() -->
&lt;!-- bs_pol.getLabeledUsers() -->
&lt;!-- print("got labels") -->
&lt;!-- with open('pol_booster.pickle', 'wb') as wf: -->
&lt;!-- pk.dump(bs_pol.booster, wf, protocol=4) -->
&lt;!-- print("pickled booster") -->
&lt;!-- with open('aus_pol_bs_module.pickle', 'wb') as wf: -->
&lt;!-- pk.dump(bs_pol, wf, protocol=4) -->
&lt;!-- with open('pol_booster.pickle', 'wb') as wf: -->
&lt;!-- pk.dump(bs.booster, wf, protocol=4) -->
&lt;!-- ``` -->
&lt;!-- This is context: -->
&lt;!-- I want to start with the opportunity namely the analysis of large amounts of population data tranparently showing the interactions and discourse of people, allowing practictioners to model important applications in society. I also want to highlight the research issues which require investigation, namely social bots, misinformation, polarization, etc. -->
&lt;!-- This is content -->
&lt;!-- I then want to move into the problem, namely that there is a lack of tooling to analyse these huge swaths of data -->
&lt;pre>&lt;code class="language-{python}">bs_pol = BirdSpotter('aus_tweets.jsonl')
bs_pol.trainClassifierModel('pol_training_data.pickle')
bs_pol.getLabeledUsers()
&lt;/code>&lt;/pre>
&lt;p>On this limited of Australian politicians dataset, a 10-fold CV of &lt;code>birdspotter&lt;/code> garners an average AUC (Area under ROC) of 0.986.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>&lt;code>birdspotter&lt;/code> aims to democratize social analyzes that were once the domain of machine learning experts, generating insights and understanding of online phenomena and mitigating their potentially adverse effects on our society. This post shows how &lt;code>birdspotter&lt;/code> can be used in both a simple and advanced way to recover such insights.&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;p>[1] Chen, E. et al. 2020. Tracking social media discourse about the covid-19 pandemic: Development of a public coronavirus twitter data set. JMIR Public Health and Surveillance. 6, 2 (2020), e19273.&lt;/p>
&lt;p>[2] Vliet, L. van et al. 2020. The twitter parliamentarian database: Analyzing twitter politics across 26 countries. PloS one. 15, 9 (2020), e0237073.&lt;/p></description></item><item><title>Causal Inference: A basic taster</title><link>https://www.behavioral-ds.science/theme1_content/causal_inference_taster/</link><pubDate>Thu, 12 Nov 2020 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme1_content/causal_inference_taster/</guid><description>
&lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
&lt;link href="index_files/anchor-sections/anchor-sections.css" rel="stylesheet" />
&lt;script src="index_files/anchor-sections/anchor-sections.js">&lt;/script>
&lt;link rel="stylesheet" href="tufte.css" type="text/css" />
&lt;p>Most statistics students will be familiar with the phrase “correlation isn’t causation,” however, this doesn’t feature strongly in the remainder of their educations. To overcome this hurdle, the researchers’ best practice in experimental design is the randomized controlled trial. However, there are only specific experiments that we can perform. For example, to test the whether smoking causes cancer, we can’t force subjects to smoke. &lt;label for="tufte-mn-" class="margin-toggle">⊕&lt;/label>&lt;input type="checkbox" id="tufte-mn-" class="margin-toggle">&lt;span class="marginnote">In the 1950s the tobacco companies argued that there could be some confounding factor (a gene) which smokers and lung cancer patients shared.&lt;/span> In general, restricting ourselves to experimental studies to determine causation is incredibly limiting (especially for data scientists). We want to make the same causal conclusions from observational studies and those from experimental studies. We can do that by studying causal inference.&lt;/p>
&lt;div id="simpsons" class="section level2">
&lt;h2>Simpson’s Paradox&lt;/h2>
An example of the importance of understanding causal relationships is given by Simpson’s Paradox &lt;span class="citation">(&lt;a href="#ref-simpson1951interpretation" role="doc-biblioref">Simpson 1951&lt;/a>)&lt;/span>, which describes a peculiar phenomenon that can present in data sets, where a correlation between two variables is present in one direction but reverses in each stratum of the data. The paradox expressed best through an example:
&lt;label for="tufte-mn-" class="margin-toggle">⊕&lt;/label>&lt;input type="checkbox" id="tufte-mn-" class="margin-toggle">&lt;span class="marginnote">This appears to suggest that the more someone exercises, the higher their cholesterol is! This is absurd!&lt;/span>
&lt;div class="figure">&lt;span id="fig:simpsons-before">&lt;/span>
&lt;img src="./index_files/figure-html/simpsons-before-1.png" alt="The results of an experiment, where x-axis represents how much exercise an individual does in hours, and y-axis represents cholestral measurment for the same individual." width="672" />
&lt;p class="caption">
Figure 1: The results of an experiment, where x-axis represents how much exercise an individual does in hours, and y-axis represents cholestral measurment for the same individual.
&lt;/p>
&lt;/div>
Figure &lt;a href="#fig:simpsons-before">1&lt;/a> shows a positive correlation in an experiment that measures individuals’ exercise per week and cholesterol. At first glance, this seems absurd, but when we partition the data by another causal variable, this seems reasonable:
&lt;div class="figure">&lt;span id="fig:simpsons-after">&lt;/span>
&lt;img src="index_files/figure-html/simpsons-after-1.png" alt="The same results as the experiment above, partioned by age" width="672" />
&lt;p class="caption">
Figure 2: The same results as the experiment above, partioned by age
&lt;/p>
&lt;/div>
&lt;p>&lt;label for="tufte-mn-" class="margin-toggle">⊕&lt;/label>&lt;input type="checkbox" id="tufte-mn-" class="margin-toggle">&lt;span class="marginnote">(Also note, we have fabricated the data, although these relationships are quite plausible)&lt;/span>
Understanding the full causal story is essential. Without an entire causal narrative, we might recommend inappropriate interventions; for example, a doctor might prescribe less exercise to reduce cholesterol in the case above.&lt;/p>
&lt;p>To deduce such causal stories, we need to apply the methodology of causal inference.&lt;/p>
&lt;/div>
&lt;div id="structural-equation-models-and-causal-graphs" class="section level2">
&lt;h2>Structural Equation Models and Causal Graphs&lt;/h2>
&lt;p>A structural equation model (SEM) is a set of equations representing the relationship between variables. For example, the equations which generated the data from &lt;a href="#simpsons">the Simpson’s paradox example&lt;/a>, are given as:
&lt;span class="math display">\[
\begin{align*}
age &amp;amp;= U_1 \\
exercise &amp;amp;= \frac{1}{13}*age + U_2 \\
cholesteral &amp;amp;= -4*exercise + age + U_3
\end{align*}
\]&lt;/span>
We can think of &lt;span class="math inline">\(U_1\)&lt;/span>, &lt;span class="math inline">\(U_2\)&lt;/span>, and &lt;span class="math inline">\(U_3\)&lt;/span> as specific unobserved exogenous variables of an individual, which generate their endogenous variables (something like error terms).&lt;/p>
&lt;p>A causal graph is a DAG which describes the existence of relationships between variables in a model. An edge &lt;code>x -&amp;gt; y&lt;/code> represents the relationship &lt;code>x&lt;/code> directly causes &lt;code>y&lt;/code>. Consequently, causal graphs can represent SEMs:
&lt;img src="index_files/figure-html/unnamed-chunk-1-1.png" width="672" />&lt;/p>
&lt;p>Indeed this graph shows how age confounds the effect of exercise on cholesterol.&lt;/p>
&lt;/div>
&lt;div id="do-calculus" class="section level2">
&lt;h2>Do-calculus&lt;/h2>
&lt;p>&lt;span class="citation">&lt;a href="#ref-pearl1995causal" role="doc-biblioref">Pearl&lt;/a> (&lt;a href="#ref-pearl1995causal" role="doc-biblioref">1995&lt;/a>)&lt;/span> outline a method to remove this confounding (and other similar scenarios) using do-calculus. Outlining the specifics of do-calculus is beyond the scope of this blog post (but for interested readers, we suggest &lt;span class="citation">(&lt;a href="#ref-pearl2016causal" role="doc-biblioref">Pearl, Glymour, and Jewell 2016&lt;/a>)&lt;/span>). In brief, do-calculus introduces the &lt;span class="math inline">\(do()\)&lt;/span> operator, which acts as an intervention and fixes a variable to a particular constant. For example, consider a similar binary situation to &lt;a href="#simpsons">the Simpson’s paradox example&lt;/a>, where &lt;em>exer&lt;/em> is a binary variable true if the individual is active, &lt;em>chol&lt;/em> is a binary variable true if the individual has high cholesterol, and &lt;em>age&lt;/em> is a binary variable true if the individual is over 60.&lt;/p>
&lt;pre class="r">&lt;code>bin_simpsons_data &amp;lt;- simpsons_data %&amp;gt;%
mutate(age = age &amp;gt; 60) %&amp;gt;% # Binarize the age, so those over 60 are True, and under 60 are False
mutate(exer = exercise&amp;gt;mean(exercise)) %&amp;gt;% # Binarize the exercise level, so those above the average are True, and under are False
mutate(chol = cholesteral&amp;gt;mean(cholesteral)) # Binarize the cholesteral level, so those above the average are True, and under are False&lt;/code>&lt;/pre>
&lt;p>We ask the same experimental question; does exercise reduce cholesterol. A naive approach would be to compute the effect as &lt;span class="math inline">\(P(chol | exer = 1) - P(chol | exer = 0)=\)&lt;/span> 0.168, where &lt;span class="math inline">\(P(chol | exer)\)&lt;/span> is computed by filtering the data according to &lt;em>exer&lt;/em>. Taking this approach, we would erroneously observe that the effect was positive since those who exercise more are also old and more likely to have high cholesterol.&lt;/p>
&lt;p>The experimental best practice approach would be to perform a randomized controlled trial (RCT). A random selection of individuals are assigned to &lt;em>do&lt;/em> a high exercise regiment and the others &lt;em>do&lt;/em> a low exercise regiment (regardless of age). The RCT implicitly removes the natural tendency of exercise to vary with age and allows researchers to observe the causal effect of exercise on cholesterol. When using data generated in such a fashion, increases/decreases in the probability of having high cholesterol caused by exercise are given by &lt;span class="math inline">\(P_{RCT}(chol | exer = 1) - P_{RCT}(chol | exer = 0)\)&lt;/span>. This metric is known as the Average Causal Effect (ACE), sometimes called the Average Treatment Effect. Note that by conditioning on &lt;span class="math inline">\(exer=x\)&lt;/span>, with data generated by an RCT, researchers are essentially limiting the data used to estimate &lt;span class="math inline">\(P_{RCT}(chol | exer = x)\)&lt;/span>, to individuals who were &lt;strong>forced&lt;/strong> to &lt;em>do&lt;/em> an exercise regiment &lt;span class="math inline">\(x\)&lt;/span>. The &lt;em>do&lt;/em> here represents forcing individuals to take an intervention value, regardless of their natural tendency, and this is captured by the &lt;span class="math inline">\(do()\)&lt;/span> operator. In this case, &lt;span class="math inline">\(P(chol | do(exer = x)) = P_{RCT}(chol | exer = x)\)&lt;/span>, since the data was generated with an RCT. However, RCTs can be prohibitively expensive (both in time and money) and might not be necessary to tease out a causal effect.&lt;/p>
&lt;p>We would still like to estimate the ACE, &lt;span class="math inline">\(P(chol | do(exer = 1)) - P(chol | do(exer = 0))\)&lt;/span>, by using data that wasn’t generated from an RCT. By using the &lt;span class="math inline">\(do()\)&lt;/span> operator here, we aim to disassociate &lt;em>exer&lt;/em> from its natural tendency with &lt;em>age&lt;/em> and effectively perform a graph surgery:&lt;/p>
&lt;p>&lt;img src="index_files/figure-html/unnamed-chunk-4-1.png" width="672" />&lt;/p>
&lt;p>&lt;span class="citation">&lt;a href="#ref-pearl2016causal" role="doc-biblioref">Pearl, Glymour, and Jewell&lt;/a> (&lt;a href="#ref-pearl2016causal" role="doc-biblioref">2016&lt;/a>)&lt;/span> provide an adjustment formula for just this scenario:
&lt;span class="math display">\[
P(y|do(x)) = \sum_z \frac{P(X=x, Y=y, PA=z)}{P(X=x| PA=z)}
\]&lt;/span>
where &lt;span class="math inline">\(X\)&lt;/span> represents the variable we are acting on, &lt;span class="math inline">\(Y\)&lt;/span> the variable we measure results from, and &lt;span class="math inline">\(PA\)&lt;/span> the parents of &lt;span class="math inline">\(X\)&lt;/span> and &lt;span class="math inline">\(Y\)&lt;/span> or more generally any nodes that satisfy the back-door criterion (which we will introduce later). Note this allows us to derive the causal effect, as if we had generated data with an RCT, using only probabilities estimated from data not generated by an RCT.&lt;/p>
&lt;p>As such we compute our ACE for the binary scenario:&lt;/p>
&lt;pre class="r">&lt;code># The Joint Distribution P(age, exer, chol) i.e. P(x,y,z)
p_aec &amp;lt;- bin_simpsons_data %&amp;gt;%
count(age, exer, chol) %&amp;gt;%
mutate(freq = n/sum(n))
# The Marginal Distribution P(age) i.e. P(z)
p_a &amp;lt;- bin_simpsons_data %&amp;gt;%
count(age) %&amp;gt;%
mutate(freq = n/sum(n))
# The Marginal Distribution P(age, exer) i.e. P(x, z)
p_ea &amp;lt;- bin_simpsons_data %&amp;gt;%
count(age, exer) %&amp;gt;%
mutate(freq = n/sum(n))
# The Conditional Mariginal Distribution P(exer | age) i.e. P(x | z)
p_e_a &amp;lt;- p_a %&amp;gt;%
right_join(p_ea, by=&amp;quot;age&amp;quot;) %&amp;gt;%
mutate(freq = freq.y/freq.x) %&amp;gt;%
select(age, exer, freq)
# The Intervention Distribution P(chol | do(exer)) i.e. P(y | do(x))
probabilities &amp;lt;- data.table(p_aec %&amp;gt;%
left_join(p_e_a, by=c(&amp;quot;age&amp;quot;, &amp;quot;exer&amp;quot;)) %&amp;gt;%
mutate(freq = freq.x/freq.y) %&amp;gt;%
select(age, exer, chol, freq) %&amp;gt;%
filter(chol) # We are only concerned with what cause high cholestral
)
# The average causal effect of exer on chol
ACE &amp;lt;- sum(probabilities[exer==T, freq]) - sum(probabilities[exer==F, freq]) &lt;/code>&lt;/pre>
&lt;p>This procedure leads to a negative ACE of -0.175, which shows the causal effect of going from high to low exercise on the probability of getting high cholesterol.&lt;/p>
&lt;p>A natural question that follows from this example is, under what conditions can we use such adjustments to achieve an identifiable causal effect.&lt;/p>
&lt;/div>
&lt;div id="d-seperation" class="section level2">
&lt;h2>d-seperation&lt;/h2>
&lt;p>To understand common scenarios where the effect of variable &lt;span class="math inline">\(X\)&lt;/span> on &lt;span class="math inline">\(Y\)&lt;/span> is identifiable within a causal graph, we must first introduce the concept of d-separation, also known as blocking. A pair of variable &lt;span class="math inline">\(X\)&lt;/span> and &lt;span class="math inline">\(Y\)&lt;/span> are said to be blocked if they are conditionally independent, given a set of nodes &lt;span class="math inline">\(Z\)&lt;/span>. There are three graph types, which are essential for blocking:&lt;/p>
&lt;p>&lt;img src="index_files/figure-html/unnamed-chunk-7-1.png" width="672" />&lt;/p>
&lt;p>In the chain scenario, &lt;span class="math inline">\(X \sim Y\)&lt;/span> is blocked by conditioning on &lt;span class="math inline">\(Z={M}\)&lt;/span>. This is sometimes refered to as the mediation scenario, which we will address further in &lt;a href="#front-door">the front-door criterion&lt;/a>.&lt;/p>
&lt;p>&lt;img src="index_files/figure-html/unnamed-chunk-8-1.png" width="672" />&lt;/p>
&lt;p>In the fork scenario, &lt;span class="math inline">\(X \sim Y\)&lt;/span> is blocked by conditioning on &lt;span class="math inline">\(Z={Z}\)&lt;/span>. This is sometimes refered to as the confounder scenario, which is the situation in &lt;a href="#simpsons">the simpson’s paradox example&lt;/a>.&lt;/p>
&lt;p>&lt;img src="index_files/figure-html/unnamed-chunk-9-1.png" width="672" />&lt;/p>
&lt;p>Finally, in the collider scenario, &lt;span class="math inline">\(X \sim Y\)&lt;/span> is blocked by &lt;em>not&lt;/em> conditioning on &lt;span class="math inline">\(Z={M}\)&lt;/span>. The idea that &lt;span class="math inline">\(X\)&lt;/span> and &lt;span class="math inline">\(Y\)&lt;/span>, which are independent, to begin with, can become conditionally dependant is unintuitive. One way to think about this is that we are sharing information received from $ Y $ with $ X $ through $ M $ when we condition on $ M $. For a more thorough investigation into this phenomenon, refer to &lt;span class="citation">(&lt;a href="#ref-pearl2016causal" role="doc-biblioref">Pearl, Glymour, and Jewell 2016&lt;/a>)&lt;/span>.&lt;/p>
&lt;p>A path is said to be blocked by &lt;span class="math inline">\(Z\)&lt;/span> if it contains a chain or fork with its middle node in &lt;span class="math inline">\(Z\)&lt;/span> or a collider with its middle node not in &lt;span class="math inline">\(Z\)&lt;/span>.&lt;/p>
&lt;p>We are now ready to introduce the main criteria for which we can perform adjustments.&lt;/p>
&lt;/div>
&lt;div id="the-backdoor" class="section level2">
&lt;h2>The Backdoor&lt;/h2>
&lt;div class="definition">
&lt;span id="def:unnamed-chunk-10" class="definition">&lt;strong>Definition 1 (The Backdoor Criterion) &lt;/strong>&lt;/span>A set of nodes &lt;span class="math inline">\(Z\)&lt;/span>, given a DAG &lt;span class="math inline">\(G\)&lt;/span> and a pair of nodes &lt;span class="math inline">\((X,Y)\)&lt;/span>, is said to satisfy the backdoor criterion if no node in &lt;span class="math inline">\(Z\)&lt;/span> is a descendant of &lt;span class="math inline">\(X\)&lt;/span>, and &lt;span class="math inline">\(Z\)&lt;/span> blocks all paths between &lt;span class="math inline">\(X\)&lt;/span> and &lt;span class="math inline">\(Y\)&lt;/span>, which contain arrows into &lt;span class="math inline">\(X\)&lt;/span>.
&lt;/div>
&lt;p>If there exists are set of nodes why satisfy the backdoor criterion, then the effect of &lt;span class="math inline">\(X\)&lt;/span> on &lt;span class="math inline">\(Y\)&lt;/span> is identifiable and given by:
&lt;span class="math display">\[
P(y|do(x)) = \sum_z \frac{P(X=x, Y=y, Z=z)}{P(X=x| Z=z)}
\]&lt;/span>&lt;/p>
&lt;p>The backdoor criterion stops undue influence through the &lt;em>backdoor&lt;/em> paths; it leaves direct paths between &lt;span class="math inline">\(X\)&lt;/span> and &lt;span class="math inline">\(Y\)&lt;/span>, and it blocks spurious paths.&lt;/p>
&lt;p>It is clear that { &lt;em>age&lt;/em> } satisfies these conditions to be a backdoor adjustment set in the example above.&lt;/p>
&lt;p>&lt;img src="index_files/figure-html/unnamed-chunk-11-1.png" width="672" />&lt;/p>
&lt;/div>
&lt;div id="front-door" class="section level2">
&lt;h2>The Front-door&lt;/h2>
&lt;p>There are notably common scenarios where this doesn’t work. For example, consider a constructed causal mediation situation, as follows:
&lt;img src="index_files/figure-html/unnamed-chunk-12-1.png" width="672" />&lt;/p>
&lt;p>In this case we cannot use the backdoor criterion, to detect the effect of &lt;em>smoking&lt;/em> on &lt;em>cancer&lt;/em> because &lt;em>tar&lt;/em> is a descendant of &lt;em>smoking&lt;/em>, and there exists no direct link between &lt;em>smoking&lt;/em> and &lt;em>cancer&lt;/em>. We must use instead the frontdoor criterion:&lt;/p>
&lt;div class="definition">
&lt;span id="def:unnamed-chunk-13" class="definition">&lt;strong>Definition 2 (The Frontdoor Criterion) &lt;/strong>&lt;/span>A set of nodes &lt;span class="math inline">\(Z\)&lt;/span>, given a DAG &lt;span class="math inline">\(G\)&lt;/span> and a pair of nodes &lt;span class="math inline">\((X,Y)\)&lt;/span>, is said to satisfy the frontdoor criterion if; &lt;span class="math inline">\(Z\)&lt;/span> intercepts all direct paths from &lt;span class="math inline">\(X\)&lt;/span> to &lt;span class="math inline">\(Y\)&lt;/span>, all paths between &lt;span class="math inline">\(X\)&lt;/span> and &lt;span class="math inline">\(Z\)&lt;/span> are blocked, and all backdoor paths between &lt;span class="math inline">\(Y\)&lt;/span> and &lt;span class="math inline">\(Z\)&lt;/span> are blocked by &lt;span class="math inline">\(X\)&lt;/span>.
&lt;/div>
&lt;p>If there exists are set of nodes &lt;span class="math inline">\(Z\)&lt;/span> which satisfy the frontdoor criterion, and &lt;span class="math inline">\(P(x, z)&amp;gt;0\)&lt;/span>, then the effect of &lt;span class="math inline">\(X\)&lt;/span> on &lt;span class="math inline">\(Y\)&lt;/span> is identifiable and given by:
&lt;span class="math display">\[
P(y|do(x)) = \sum_z P(z|x) \sum_{x^\prime} P(y|x^\prime, z)P(x^\prime)
\]&lt;/span>
In our smoking scenario, we see that by adjusting for &lt;em>tar&lt;/em> , we can observe the effect of &lt;em>smoking&lt;/em> on &lt;em>cancer&lt;/em>.&lt;/p>
&lt;/div>
&lt;div id="conclusion" class="section level2">
&lt;h2>Conclusion&lt;/h2>
&lt;p>The above briefly outlines a core motivation for studying causal inference and causal stories. We summarise some of the underlying theory of causal inference and show practical methodology through the &lt;em>frontdoor&lt;/em> and &lt;em>backdoor&lt;/em> criterion for determining causal effects through entirely observational studies.&lt;/p>
&lt;p>There are notable aspects of causal inference we have omitted from this taster. The most gaping is the lack of an explanation for the powerful tool of counterfactuals. We have only presented binary examples here (aside from our motivating example); however, perhaps the most common and useful causal inference application is to continuous examples using regression with linear models. Ultimately, we decided this was beyond causal inference taster’s scope and were more deserving of their own articles. Again, for the interested reader, we recommend &lt;span class="citation">&lt;a href="#ref-pearl2016causal" role="doc-biblioref">Pearl, Glymour, and Jewell&lt;/a> (&lt;a href="#ref-pearl2016causal" role="doc-biblioref">2016&lt;/a>)&lt;/span>, which adds links to many other resources.&lt;/p>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-pearl1995causal" class="csl-entry">
Pearl, Judea. 1995. &lt;span>“Causal Diagrams for Empirical Research.”&lt;/span> &lt;em>Biometrika&lt;/em> 82 (4): 669–88.
&lt;/div>
&lt;div id="ref-pearl2016causal" class="csl-entry">
Pearl, Judea, Madelyn Glymour, and Nicholas P Jewell. 2016. &lt;em>Causal Inference in Statistics: A Primer&lt;/em>. John Wiley &amp;amp; Sons.
&lt;/div>
&lt;div id="ref-simpson1951interpretation" class="csl-entry">
Simpson, Edward H. 1951. &lt;span>“The Interpretation of Interaction in Contingency Tables.”&lt;/span> &lt;em>Journal of the Royal Statistical Society: Series B (Methodological)&lt;/em> 13 (2): 238–41.
&lt;/div>
&lt;/div>
&lt;/div></description></item></channel></rss>