<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Behavioral Data Science</title><link>https://www.behavioral-ds.science/authors/quyu-kong/</link><atom:link href="https://www.behavioral-ds.science/authors/quyu-kong/index.xml" rel="self" type="application/rss+xml"/><description>Behavioral Data Science</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>2025</copyright><lastBuildDate>Mon, 13 Dec 2021 00:00:00 +0000</lastBuildDate><image><url>https://www.behavioral-ds.science/img/logo.png</url><title>Behavioral Data Science</title><link>https://www.behavioral-ds.science/authors/quyu-kong/</link></image><item><title>Slipping to the Extreme: A Mixed-Method to Explain How Extreme Opinions Infiltrate Online Discussions</title><link>https://www.behavioral-ds.science/theme2_content/icwsm2022/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme2_content/icwsm2022/</guid><description>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/HwFq3ywanp4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;p>In our &lt;a href="https://arxiv.org/pdf/2109.00302.pdf">recent paper&lt;/a> accepted at &lt;a href="https://www.icwsm.org/2022/index.html/">ICWSM 2022&lt;/a>, we propose a complete solution to accelerate the qualitative analysis of problematic online speech — with a specific focus on opinions emerging from online communities — by leveraging machine learning algorithms.&lt;/p>
&lt;p>&lt;strong>Paper citation:&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Quyu Kong, Emily Booth, Francesco Bailo, Amelia Johns, and Marian-Andrei
Rizoiu. Slipping to the Extreme: A Mixed-Method to Explain How Extreme
Opinions Infiltrate Online Discussions. In: Proceedings of the 16TH AAAI
International Conference on Web and Social Media, 2022.
&lt;/code>&lt;/pre>
&lt;p>(see full paper here: &lt;a href="https://arxiv.org/pdf/2109.00302.pdf">https://arxiv.org/pdf/2109.00302.pdf&lt;/a>)&lt;/p>
&lt;h3 id="problematic-speech-a-modern-plague">Problematic Speech: A Modern Plague&lt;/h3>
&lt;p>Problematic speech is online interactions, speech, and artifacts that are inaccurate, misleading, inappropriately attributed, or altogether fabricated [1].
In 2020, the COVID-19 pandemic alerted the world to complex issues that arise from social media platforms circulating user-generated misinformation, hate speech, and conspiracy theories [2].
There are several primary types of quantitative methods for addressing problematic information, including large-scale monitoring of social media datasets [3], understanding platforms, users, and networks contributing to the &amp;ldquo;infodemic&amp;rdquo; [4], and predicting future pathways of information spreading [5].
These studies provide valuable insights into understanding how problematic information spreads and detecting which sources are reshared frequently and by which accounts.
However, these approaches often have less to say about why certain opinions and views gain traction with vulnerable groups and online communities.&lt;/p>
&lt;p>Qualitative research methods are well placed to address this gap.
They provide rich, contextual insights into online communities&amp;rsquo; social beliefs, values, and practices, which shape how information is shared and how opinions are formed [6].
Nevertheless, a common criticism of qualitative research is that the in-depth knowledge comes at the expense of generating insights of limited representativeness and weak robustness of the findings.
Therefore, there is a gap between the depth of insight gained from ethnographic and qualitative approaches and the breadth of knowledge gained from computational methods from data science.&lt;/p>
&lt;p>Our work fills this gap by proposing a mixed-method approach that combines qualitative insights, large-scale data collection, and human-in-the-loop machine learning approaches.
We apply our method to map in-depth and in-breadth the problematic information around four topics:
&lt;em>2019-20 Australian bushfire season&lt;/em>,
&lt;em>Climate change&lt;/em>,
&lt;em>COVID-19&lt;/em>, and
&lt;em>Vaccination&lt;/em>
on three social media platforms (Facebook, Twitter, and YouTube).&lt;/p>
&lt;h2 id="our-solution-mixing-digital-ethnography-with-advanced-machine-learning">Our Solution: Mixing Digital Ethnography with Advanced Machine Learning&lt;/h2>
&lt;p>&lt;img src="fig1.png" alt="The pipeline of machine learning accelerated qualitative research where the human-in-the-loop machine learning algorithms are employed for dataset augmentation.">&lt;/p>
&lt;p>We present a complete solution that bridges and facilitates qualitative and quantitative analysis to study problematic online speech.
The pipeline consists of three components which are detailed in this section.&lt;/p>
&lt;h3 id="deep-qualitative-study">Deep qualitative study&lt;/h3>
&lt;p>The first component is the qualitative study.
We build a platform based on an open-source tool, &lt;a href="https://wikiba.se/">&lt;em>Wikibase&lt;/em>&lt;/a>, where we conduct qualitative and quantitative analysis.
Through the quantitative study, we build an ontology of problematic online speech.
We label a large number of social media postings using their topics.
Simultaneously, we construct a vocabulary of 71 opinions that we also use to label postings.
Some example opinions include:&lt;/p>
&lt;ul>
&lt;li>Climate change crisis isn't real&lt;/li>
&lt;li>United Nations is corrupt&lt;/li>
&lt;li>Climate change is a UN hoax&lt;/li>
&lt;li>United Nations wants to be the global ruling government&lt;/li>
&lt;li>Vaccines cause Autism&lt;/li>
&lt;li>The World Health Organisation is corrupt&lt;/li>
&lt;/ul>
&lt;p>These opinions contain mistrust in the government and supra-national structures (e.g., UN, WHO) and typical misinformation about vaccines.&lt;/p>
&lt;h3 id="unlabeled-data-collection">Unlabeled data collection&lt;/h3>
&lt;p>Qualitative approaches analyze emerging content and construct the vocabulary simultaneously when labeling the data.
However, they lack representativeness as they tend to be overly concentrated on narrow areas of the narrative landscape.
For this reason, the second step in our methodology involves collecting data at scale.
We collect large-scale raw data using the uncovered vocabulary from the deep qualitative study.
We construct keywords (shown in the table) for each topic to crawl social media data from three platforms.
We obtain a total of &lt;strong>13,321,813&lt;/strong> postings — &lt;strong>11,437,009&lt;/strong> Facebook postings, &lt;strong>1,793,927&lt;/strong> tweets and &lt;strong>90,877&lt;/strong> YouTube comments.&lt;/p>
&lt;p>&lt;img src="table.png" alt="keywords">&lt;/p>
&lt;h3 id="dataset-augmentation">Dataset augmentation&lt;/h3>
&lt;p>The next step is to annotate all the postings in our dataset automatically.
We employ machine learning algorithms to augment the data labeling process with a human-in-the-loop setting.&lt;/p>
&lt;p>By adopting the state-of-the-art text classification algorithm, RoBERTa [7,8], we first train the classifiers to identify problematic speech on postings annotated by the qualitative researchers.
Next, we deploy three strategies to select unlabeled data.
The active learning [9] strategy selects the data for which the classifiers are most uncertain.
The top-confidence strategy selects data that classifiers are most certain about.
The third strategy — the random strategy — randomly samples from unlabeled data.
The qualitative researchers then label the sampled data, introduce the newly labeled data in the ontology, and repeat the procedure iteratively until the predictive performance converges.&lt;/p>
&lt;h2 id="humanintheloop-performance">Human-in-the-loop Performance&lt;/h2>
&lt;p>We discuss here the convergence of prediction performance over labeling iterations.&lt;/p>
&lt;p>The following plot depicts the prediction performance on the test set macro-averaged over topics (accuracy in the left panel and F1 score on the right panel) over iterations.
The solid lines show the performance indicators, together with the cross-validation generalization error.&lt;/p>
&lt;p>The cross-validation performance is stable across iterations.
This is expected as the classifiers learn from the same data on which the generalization is estimated — i.e., the classifiers are representative of the data they were trained on.
However, the difference between the test set performance and cross-validation performance is indicative of the representativity over the entire dataset.
The cross-validation accuracy is consistently lower than the test set accuracy because the test data is more imbalanced than labeled data.
The cross-validation F1 is more optimistic than the test set F1.
Finally, the difference between the two stabilizes for the later iterations, further suggesting the convergence.
&lt;img src="fig3.png" alt="Convergence of topic classifier performances over seven iterations.">&lt;/p>
&lt;h2 id="applying-the-qualitative-mapping">Applying the Qualitative Mapping&lt;/h2>
&lt;p>We employ the obtained augmented labeled set to analyze the dynamics of problematic opinions at scale.
We machine-label the opinions in a large set of postings spanning over a long time, allowing us to apply the qualitative-defined coding schema to a significantly larger sample of postings.
This reduces the unavoidable selection bias of the deep qualitative study.
It also offers a critical tool for analyzing co-occurring opinions, which helps identify central opinions.
It is common for postings to express multiple opinions.&lt;/p>
&lt;p>We explore central opinions by building an opinion co-occurrence network in the online conversation of the topic &lt;strong>2019-20 Australian bushfire season&lt;/strong>.
In the network, nodes are the opinions captured during the bushfire conversation, while edges are present when both opinions are detected in the same postings.
The node degree of a given opinion node represents the number of opinions that co-occurred with it.
The edges are weighted by the number of postings in which their connected node opinions co-occurred.&lt;/p>
&lt;p>The following plot presents each edge's daily proportions of weights among all edges between September 2019 and January 2020.
We show six edges (i.e., opinion pairs) to represent three types of temporal dynamics:&lt;/p>
&lt;ul>
&lt;li>A continuous and relatively strong association between prevalent opinions — &amp;ldquo;Climate change crisis isn't real&amp;rdquo; and &amp;ldquo;Climate change is a UN hoax,&amp;rdquo; which not notably is a conspiracy theory.&lt;/li>
&lt;li>Associations with declining relative frequencies — &amp;ldquo;Greta Thunberg should not have a platform or influence as a climate&amp;hellip;&amp;rdquo; and &amp;ldquo;Women and girls don't deserve a voice in the public sphere&amp;rdquo;.&lt;/li>
&lt;li>Rising associations such as &amp;ldquo;bushfires and climate change not related&amp;rdquo; and &amp;ldquo;bushfires were caused by random arsonists&amp;rdquo;; and also the conspiracy theory associations between &amp;ldquo;United Nations is corrupt&amp;rdquo; and &amp;ldquo;United Nations wants to be the global ruling government&amp;rdquo;.
&lt;img src="fig2.png" alt="Daily proportions of edge weights of six selected co-occurred opinions pairs.">&lt;/li>
&lt;/ul>
&lt;p>In the following plot, we map the co-occurrence network from posts published over 14 days in late September 2019, i.e., the period when the betweenness for conspiracy opinions is at peak.
This figure explains the ambivalent network role that conspiracy opinions can play: we first note a conspiracy opinion with relatively high degree and frequency — &amp;ldquo;Climate change is a UN hoax&amp;rdquo; —, while we also observe the presence of low degree but high betweenness conspiracy opinions at the periphery of the network — &amp;ldquo;Bushfires linked to secret elites&amp;rsquo; secret technology (chemtrails, HAARP, HSRN, geoengineering)&amp;quot;, &amp;ldquo;bushfires deliberately lit to promote a climate change agenda&amp;rdquo; and &amp;ldquo;Australia should not be a member of the United Nations&amp;rdquo;.&lt;/p>
&lt;p>&lt;img src="featured.png" alt="A visualization of the co-occurrence network in late September 2020 — node sizes and colors indicate the degrees and betweenness values">&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;p>[1] Jack, C. 2017. Lexicon of lies: Terms for problematic information. Data &amp;amp; Society.&lt;br>
[2] Posetti, J.; and Bontcheva, K. 2020. Disinfodemic: deciphering COVID-19 disinformation. Policy brief 1.&lt;br>
[3] Ram, R.; Kong, Q.; and Rizoiu, M.-A. 2021. Birdspotter: A Tool for Analyzing and Labeling Twitter Users. In WSDM. ACM.&lt;br>
[4] Smith, N.; and Graham, T. 2019. Mapping the anti-vaccination movement on Facebook. Information, Communication &amp;amp; Society.&lt;br>
[5] Molina, M. D.; Sundar, S. S.; Le, T.; and Lee, D. 2019. “Fake news” is not simply false information: a concept explication and taxonomy of online content. American behavioral scientist&lt;br>
[6] Glaeser, E. L.; and Sunstein, C. R. 2009. Extremism and social learning. Journal of Legal Analysis.&lt;br>
[7] Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; and Polosukhin, I. 2017. Attention is all you need. In NeurIPS.&lt;br>
[8] Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.; Levy, O.; Lewis, M.; Zettlemoyer, L.; and Stoyanov, V. 2019. Roberta: A robustly optimized BERT pretraining approach. arXiv.&lt;br>
[9] Settles, B. 2012. Active learning. Synthesis lectures on artificial intelligence and machine learning.&lt;/p></description></item><item><title>Epidemic Hawkes: an example project</title><link>https://www.behavioral-ds.science/researchproject/project1/</link><pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/researchproject/project1/</guid><description>&lt;p>This is an example project description&lt;/p></description></item><item><title>evently: simulation, fitting of Hawkes processes</title><link>https://www.behavioral-ds.science/softwaretool/evently/</link><pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/softwaretool/evently/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>This package is designed for simulating and fitting the Hawkes processes
and the HawkesN processes with several options of kernel functions.
Currently, it assumes univariate processes without background event
rates. Prior knowledge about the models is assumed in the following
tutorial and please refer to [1] and [2] for details about the
models.&lt;/p>
&lt;pre>&lt;code class="language-r">library(evently)
&lt;/code>&lt;/pre>
&lt;h2 id="installation-and-dependencies">Installation and dependencies&lt;/h2>
&lt;p>Several dependencies
(&lt;a href="https://cran.r-project.org/web/packages/poweRlaw/poweRlaw.pdf">poweRlaw&lt;/a>,
&lt;a href="https://ampl.com/">AMPL&lt;/a>,
&lt;a href="https://www.coin-or.org/Ipopt/documentation/">Ipopt&lt;/a>) are required for
running this package. These dependencies will be installed automatically
by R or by following instructions upon package load.&lt;/p>
&lt;p>Install the package by executing&lt;/p>
&lt;pre>&lt;code class="language-r">if (!require('devtools')) install.packages('devtools')
devtools::install_github('behavioral-ds/evently')
&lt;/code>&lt;/pre>
&lt;h2 id="simulating-cascades">Simulating cascades&lt;/h2>
&lt;p>Let’s first simulate 100 event cascades of the &lt;strong>Hawkes process with an
exponential kernel function&lt;/strong> (please refer to the &lt;a href="#available-models">Available
models&lt;/a> for models and their abbreviations in the
package) with a given parameter set, &lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%20%3D%200.9%2C%20%5Ctheta%20%3D%201" alt="\\kappa = 0.9, \\theta= 1" title="\kappa = 0.9, \theta = 1">. For each simulation, we only simulate
until 5 seconds. The resulted cascades are placed in a single &lt;code>list&lt;/code>
where each cascade is a &lt;code>data.frame&lt;/code>.&lt;/p>
&lt;pre>&lt;code class="language-r">set.seed(4)
sim_no &amp;lt;- 100
data &amp;lt;- generate_hawkes_event_series(par = c(K = 0.9, theta = 1), model_type = 'EXP', Tmax = 5, sim_no = sim_no)
# alternatively, `generate_hawkes_event_series` also accepts a model class object
# e.g.
# model &amp;lt;- new_hawkes_model(par = c(K = 0.9, theta = 1), model_type = 'EXP')
# generate_hawkes_event_series(model = model, Tmax = 5, sim_no = sim_no)
head(data[[1]])
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## magnitude time
## 1 1 0.0000000
## 2 1 0.5941959
## 3 1 1.4712411
## 4 1 1.6105430
## 5 1 1.7855535
## 6 1 1.8883869
&lt;/code>&lt;/pre>
&lt;p>A simulated process is represented by a &lt;code>data.frame&lt;/code> where each row is
an event. &lt;code>time&lt;/code> indicates the event happening time, while &lt;code>magnitude&lt;/code>
is the event mark information which is always 1 if &lt;code>model_type&lt;/code> is an
unmarked model. In the context of retweet diffusion cascades, the first
row is the original tweet and all following events are its retweets.
&lt;code>time&lt;/code> records the relative time (in second) of each retweet to the
original tweet and &lt;code>magnitude&lt;/code> is the follows’ count of the user who
retweeted.&lt;/p>
&lt;h2 id="fitting-a-model-on-data">Fitting a model on data&lt;/h2>
&lt;p>We can then fit on the cascades simulated in the previous section. After
providing the &lt;code>data&lt;/code> and &lt;code>model_type&lt;/code>, the fitting procedure will spawn
10 AMPL optimization procedures with different parameter
inistializations due to the non-convexity of some likelihood functions.
Among the 10 fitted model, the one giving the best likelihood value will
be returned. To make the fitting procedure faster, we can specify the
number of &lt;code>cores&lt;/code> to be used for fitting them in
parallel.&lt;/p>
&lt;pre>&lt;code class="language-r">fitted_model &amp;lt;- fit_series(data, model_type = 'EXP', observation_time = 5, cores = 10)
fitted_model
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Model: EXP
## No. of cascades: 100
## init_par
## K 7.92e+00; theta 1.32e+00
## par
## K 8.51e-01; theta 1.06e+00
## Neg Log Likelihood: 285.488
## lower_bound
## K 1.00e-100; theta 1.00e-100
## upper_bound
## K 1.00e+04; theta 3.00e+02
## convergence: 0
&lt;/code>&lt;/pre>
&lt;h2 id="available-models">Available models&lt;/h2>
&lt;p>There are 8 models available so far in this
package:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th align="center">Model&lt;/th>
&lt;th align="center">Abbreviation (model_type)&lt;/th>
&lt;th align="center">Intensity Function&lt;/th>
&lt;th align="center">Parameters&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td align="center">Hawkes process with an exponential kernel function&lt;/td>
&lt;td align="center">EXP&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} \\theta e^{-\\theta (t-t\_i)}" title="\kappa\sum_{t_i &amp;lt; t} \theta e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Hawkes process with a power-law kernel function&lt;/td>
&lt;td align="center">PL&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} (t-t\_i + c)^{-(1+\\theta)}" title="\kappa\sum_{t_i &amp;lt; t} (t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,c,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">HawkesN process with an exponential kernel function&lt;/td>
&lt;td align="center">EXPN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} \\theta e^{-\\theta (t-t\_i)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} \theta e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,theta,N&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">HawkesN process with a power-law kernel function&lt;/td>
&lt;td align="center">PLN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} (t-t\_i + c)^{-(1+\\theta)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} (t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,c,theta,N&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked Hawkes process with an exponential kernel function&lt;/td>
&lt;td align="center">mEXP&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20m_i%5E%7B%5Cbeta%7D%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} \\theta m\_i^{\\beta} e^{-\\theta (t-t\_i)}" title="\kappa\sum_{t_i &amp;lt; t} \theta m_i^{\beta} e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,beta,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked Hawkes process with a power-law kernel function&lt;/td>
&lt;td align="center">mPL&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20m_i%5E%7B%5Cbeta%7D%20%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} m\_i^{\\beta} (t-t\_i + c)^{-(1+\\theta)}" title="\kappa\sum_{t_i &amp;lt; t} m_i^{\beta} (t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,beta,c,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked HawkesN process with an exponential kernel function&lt;/td>
&lt;td align="center">mEXPN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20m_i%5E%7B%5Cbeta%7D%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} \\theta m\_i^{\\beta} e^{-\\theta (t-t\_i)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} \theta m_i^{\beta} e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,beta,theta,N&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked HawkesN process with a power-law kernel function&lt;/td>
&lt;td align="center">mPLN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20m_i%5E%7B%5Cbeta%7D%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} m\_i^{\\beta}(t-t\_i + c)^{-(1+\\theta)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} m_i^{\beta}(t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,beta,c,theta,N&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="acknowledgement">Acknowledgement&lt;/h2>
&lt;p>The development of this package is supported by the Green Policy grant
from the National Security College, Crawford School, ANU.&lt;/p>
&lt;h2 id="license">License&lt;/h2>
&lt;p>Both dataset and code are distributed under the &lt;a href="https://creativecommons.org/licenses/by-nc/4.0/">Creative Commons
Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)
license&lt;/a>. If you
require a different license, please contact us at &lt;a href="mailto:Quyu.Kong@anu.edu.au">Quyu.Kong@anu.edu.au&lt;/a>
or &lt;a href="mailto:Marian-Andrei@rizoiu.eu">Marian-Andrei@rizoiu.eu&lt;/a>.&lt;/p>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;p>[1] Rizoiu, M. A., Lee, Y., Mishra, S., &amp;amp; Xie, L. (2017, December). Hawkes processes for events in social media. In Frontiers of Multimedia Research (pp. 191-218). Association for Computing Machinery
and Morgan &amp;amp; Claypool.&lt;br>
[2] Rizoiu, M. A., Mishra, S., Kong, Q., Carman, M., &amp;amp; Xie, L.
(2018, April). SIR-Hawkes: Linking epidemic models and Hawkes processes to model diffusions in finite populations. In Proceedings of the 2018 World Wide Web Conference (pp. 419-428). International World Wide Web Conferences Steering Committee.&lt;br>
[3] Mishra, S., Rizoiu, M. A., &amp;amp; Xie, L. (2016, October). Feature
driven and point process approaches for popularity prediction. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management (pp. 1069-1078). ACM.&lt;br>
[4] Kong, Q., Rizoiu, M. A., &amp;amp; Xie, L. (2019). Modeling Information
Cascades with Self-exciting Processes via Generalized Epidemic Models. arXiv preprint arXiv:1910.05451.&lt;/p></description></item><item><title>evently: simulation, fitting of Hawkes processes</title><link>https://www.behavioral-ds.science/theme1_content/evently/</link><pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme1_content/evently/</guid><description>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/zSMHol0qsy4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>This package is designed for simulating and fitting the Hawkes processes
and the HawkesN processes with several options of kernel functions.
Currently, it assumes univariate processes without background event
rates. Prior knowledge about the models is assumed in the following
tutorial and please refer to [1] and [2] for details about the
models.&lt;/p>
&lt;pre>&lt;code class="language-r">library(evently)
&lt;/code>&lt;/pre>
&lt;h2 id="installation-and-dependencies">Installation and dependencies&lt;/h2>
&lt;p>Several dependencies
(&lt;a href="https://cran.r-project.org/web/packages/poweRlaw/poweRlaw.pdf">poweRlaw&lt;/a>,
&lt;a href="https://ampl.com/">AMPL&lt;/a>,
&lt;a href="https://www.coin-or.org/Ipopt/documentation/">Ipopt&lt;/a>) are required for
running this package. These dependencies will be installed automatically
by R or by following instructions upon package load.&lt;/p>
&lt;p>Install the package by executing&lt;/p>
&lt;pre>&lt;code class="language-r">if (!require('devtools')) install.packages('devtools')
devtools::install_github('behavioral-ds/evently')
&lt;/code>&lt;/pre>
&lt;h2 id="simulating-cascades">Simulating cascades&lt;/h2>
&lt;p>Let’s first simulate 100 event cascades of the &lt;strong>Hawkes process with an
exponential kernel function&lt;/strong> (please refer to the &lt;a href="#available-models">Available
models&lt;/a> for models and their abbreviations in the
package) with a given parameter set, &lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%20%3D%200.9%2C%20%5Ctheta%20%3D%201" alt="\\kappa = 0.9, \\theta= 1" title="\kappa = 0.9, \theta = 1">. For each simulation, we only simulate
until 5 seconds. The resulted cascades are placed in a single &lt;code>list&lt;/code>
where each cascade is a &lt;code>data.frame&lt;/code>.&lt;/p>
&lt;pre>&lt;code class="language-r">set.seed(4)
sim_no &amp;lt;- 100
data &amp;lt;- generate_hawkes_event_series(par = c(K = 0.9, theta = 1), model_type = 'EXP', Tmax = 5, sim_no = sim_no)
# alternatively, `generate_hawkes_event_series` also accepts a model class object
# e.g.
# model &amp;lt;- new_hawkes_model(par = c(K = 0.9, theta = 1), model_type = 'EXP')
# generate_hawkes_event_series(model = model, Tmax = 5, sim_no = sim_no)
head(data[[1]])
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## magnitude time
## 1 1 0.0000000
## 2 1 0.5941959
## 3 1 1.4712411
## 4 1 1.6105430
## 5 1 1.7855535
## 6 1 1.8883869
&lt;/code>&lt;/pre>
&lt;p>A simulated process is represented by a &lt;code>data.frame&lt;/code> where each row is
an event. &lt;code>time&lt;/code> indicates the event happening time, while &lt;code>magnitude&lt;/code>
is the event mark information which is always 1 if &lt;code>model_type&lt;/code> is an
unmarked model. In the context of retweet diffusion cascades, the first
row is the original tweet and all following events are its retweets.
&lt;code>time&lt;/code> records the relative time (in second) of each retweet to the
original tweet and &lt;code>magnitude&lt;/code> is the follows’ count of the user who
retweeted.&lt;/p>
&lt;h2 id="fitting-a-model-on-data">Fitting a model on data&lt;/h2>
&lt;p>We can then fit on the cascades simulated in the previous section. After
providing the &lt;code>data&lt;/code> and &lt;code>model_type&lt;/code>, the fitting procedure will spawn
10 AMPL optimization procedures with different parameter
inistializations due to the non-convexity of some likelihood functions.
Among the 10 fitted model, the one giving the best likelihood value will
be returned. To make the fitting procedure faster, we can specify the
number of &lt;code>cores&lt;/code> to be used for fitting them in
parallel.&lt;/p>
&lt;pre>&lt;code class="language-r">fitted_model &amp;lt;- fit_series(data, model_type = 'EXP', observation_time = 5, cores = 10)
fitted_model
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Model: EXP
## No. of cascades: 100
## init_par
## K 7.92e+00; theta 1.32e+00
## par
## K 8.51e-01; theta 1.06e+00
## Neg Log Likelihood: 285.488
## lower_bound
## K 1.00e-100; theta 1.00e-100
## upper_bound
## K 1.00e+04; theta 3.00e+02
## convergence: 0
&lt;/code>&lt;/pre>
&lt;h2 id="available-models">Available models&lt;/h2>
&lt;p>There are 8 models available so far in this
package:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th align="center">Model&lt;/th>
&lt;th align="center">Abbreviation (model_type)&lt;/th>
&lt;th align="center">Intensity Function&lt;/th>
&lt;th align="center">Parameters&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td align="center">Hawkes process with an exponential kernel function&lt;/td>
&lt;td align="center">EXP&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} \\theta e^{-\\theta (t-t\_i)}" title="\kappa\sum_{t_i &amp;lt; t} \theta e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Hawkes process with a power-law kernel function&lt;/td>
&lt;td align="center">PL&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} (t-t\_i + c)^{-(1+\\theta)}" title="\kappa\sum_{t_i &amp;lt; t} (t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,c,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">HawkesN process with an exponential kernel function&lt;/td>
&lt;td align="center">EXPN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} \\theta e^{-\\theta (t-t\_i)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} \theta e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,theta,N&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">HawkesN process with a power-law kernel function&lt;/td>
&lt;td align="center">PLN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} (t-t\_i + c)^{-(1+\\theta)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} (t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,c,theta,N&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked Hawkes process with an exponential kernel function&lt;/td>
&lt;td align="center">mEXP&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20m_i%5E%7B%5Cbeta%7D%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} \\theta m\_i^{\\beta} e^{-\\theta (t-t\_i)}" title="\kappa\sum_{t_i &amp;lt; t} \theta m_i^{\beta} e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,beta,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked Hawkes process with a power-law kernel function&lt;/td>
&lt;td align="center">mPL&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20m_i%5E%7B%5Cbeta%7D%20%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} m\_i^{\\beta} (t-t\_i + c)^{-(1+\\theta)}" title="\kappa\sum_{t_i &amp;lt; t} m_i^{\beta} (t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,beta,c,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked HawkesN process with an exponential kernel function&lt;/td>
&lt;td align="center">mEXPN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20m_i%5E%7B%5Cbeta%7D%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} \\theta m\_i^{\\beta} e^{-\\theta (t-t\_i)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} \theta m_i^{\beta} e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,beta,theta,N&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked HawkesN process with a power-law kernel function&lt;/td>
&lt;td align="center">mPLN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20m_i%5E%7B%5Cbeta%7D%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} m\_i^{\\beta}(t-t\_i + c)^{-(1+\\theta)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} m_i^{\beta}(t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,beta,c,theta,N&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="acknowledgement">Acknowledgement&lt;/h2>
&lt;p>The development of this package is supported by the Green Policy grant
from the National Security College, Crawford School, ANU.&lt;/p>
&lt;h2 id="license">License&lt;/h2>
&lt;p>Both dataset and code are distributed under the &lt;a href="https://creativecommons.org/licenses/by-nc/4.0/">Creative Commons
Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)
license&lt;/a>. If you
require a different license, please contact us at &lt;a href="mailto:Quyu.Kong@anu.edu.au">Quyu.Kong@anu.edu.au&lt;/a>
or &lt;a href="mailto:Marian-Andrei@rizoiu.eu">Marian-Andrei@rizoiu.eu&lt;/a>.&lt;/p>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;p>[1] Rizoiu, M. A., Lee, Y., Mishra, S., &amp;amp; Xie, L. (2017, December). Hawkes processes for events in social media. In Frontiers of Multimedia Research (pp. 191-218). Association for Computing Machinery
and Morgan &amp;amp; Claypool.&lt;br>
[2] Rizoiu, M. A., Mishra, S., Kong, Q., Carman, M., &amp;amp; Xie, L.
(2018, April). SIR-Hawkes: Linking epidemic models and Hawkes processes to model diffusions in finite populations. In Proceedings of the 2018 World Wide Web Conference (pp. 419-428). International World Wide Web Conferences Steering Committee.&lt;br>
[3] Mishra, S., Rizoiu, M. A., &amp;amp; Xie, L. (2016, October). Feature
driven and point process approaches for popularity prediction. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management (pp. 1069-1078). ACM.&lt;br>
[4] Kong, Q., Rizoiu, M. A., &amp;amp; Xie, L. (2019). Modeling Information
Cascades with Self-exciting Processes via Generalized Epidemic Models. arXiv preprint arXiv:1910.05451.&lt;/p></description></item></channel></rss>