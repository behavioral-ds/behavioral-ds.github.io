<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Behavioral Data Science</title><link>https://www.behavioral-ds.science/</link><atom:link href="https://www.behavioral-ds.science/index.xml" rel="self" type="application/rss+xml"/><description>Behavioral Data Science</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>2025</copyright><lastBuildDate>Fri, 09 May 2025 00:00:00 +0000</lastBuildDate><image><url>https://www.behavioral-ds.science/img/logo.png</url><title>Behavioral Data Science</title><link>https://www.behavioral-ds.science/</link></image><item><title>Some Reddit users just love to disagree, new AI-powered troll-spotting algorithm finds</title><link>https://www.behavioral-ds.science/blogpost/irl_homophily/</link><pubDate>Fri, 09 May 2025 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/blogpost/irl_homophily/</guid><description>&lt;p>This is a repost of our article from &lt;a href="https://theconversation.com/some-reddit-users-just-love-to-disagree-new-ai-powered-troll-spotting-algorithm-finds-255879">The Conversation&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Paper citation:&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Lanqin Yuan, Philipp J. Schneider, and Marian-Andrei Rizoiu. 2025. Behavioral Homophily in Social Media via Inverse Reinforcement Learning: A Reddit Case Study. In Proceedings of the ACM on Web Conference 2025 (WWW '25). Association for Computing Machinery, New York, NY, USA, 576–589. https://doi.org/10.1145/3696410.3714618
&lt;/code>&lt;/pre>
&lt;p>(&lt;em>see full paper here: &lt;a href="https://dl.acm.org/doi/pdf/10.1145/3696410.3714618">&lt;a href="https://dl.acm.org/doi/pdf/10.1145/3696410.3714618">https://dl.acm.org/doi/pdf/10.1145/3696410.3714618&lt;/a>&lt;/a>&lt;/em>)&lt;/p>
&lt;p>In today’s fractured online landscape, it is harder than ever to identify harmful actors such as trolls and misinformation spreaders.&lt;/p>
&lt;p>Often, efforts to spot malicious accounts focus on analysing what they say. However, our latest research suggests we should be paying more attention to what they do – and how they do it.&lt;/p>
&lt;p>We have developed a way to identify potentially harmful online actors based solely on their behavioural patterns – the way they interact with others – rather than the content they share. We presented our results at the recent ACM Web Conference, and were awarded Best Paper.
Beyond looking at what people say&lt;/p>
&lt;p>Traditional approaches to spotting problematic online behaviour typically rely on two methods. One is to examine content (what people are saying). The other is to analyse network connections (who follows whom).&lt;/p>
&lt;p>These methods have limitations.&lt;/p>
&lt;p>Users can circumvent content analysis. They may code their language carefully, or share misleading information without using obvious trigger words.&lt;/p>
&lt;h2 id="beyond-looking-at-what-people-say">Beyond looking at what people say&lt;/h2>
&lt;p>Traditional approaches to spotting problematic online behaviour typically rely on two methods. One is to examine content (what people are saying). The other is to analyse network connections (who follows whom).&lt;/p>
&lt;p>These methods have limitations.&lt;/p>
&lt;p>Users can circumvent content analysis. They may code their language carefully, or share misleading information without using obvious trigger words.&lt;/p>
&lt;p>Network analysis falls short on platforms such as Reddit. Here, connections between users aren’t explicit. Communities are organised around topics rather than social relationships.&lt;/p>
&lt;p>We wanted to find a way to identify harmful actors that couldn’t be easily gamed. We realised we could, focusing on behaviour – how people interact, rather than what they say.&lt;/p>
&lt;h2 id="teaching-ai-to-understand-human-behaviour-online">Teaching AI to understand human behaviour online&lt;/h2>
&lt;p>Our approach uses a technique called inverse reinforcement learning. This is a method typically used to understand human decision-making in fields such as autonomous driving or game theory.&lt;/p>
&lt;p>We adapted this technology to analyse how users behave on social media platforms.&lt;/p>
&lt;p>The system works by observing a user’s actions, such as creating new threads, posting comments and replying to others. From those actions it infers the underlying strategy or “policy” that drives their behaviour.&lt;/p>
&lt;p>In our Reddit case study, we analysed 5.9 million interactions over six years. We identified five distinct behavioural personas, including one particularly notable group – “disagreers”.&lt;/p>
&lt;h2 id="meet-the-disagreers">Meet the ‘disagreers’&lt;/h2>
&lt;p>Perhaps our most striking result was finding an entire class of Reddit users whose primary purpose seems to be to disagree with others. These users specifically seek out opportunities to post contradictory comments, especially in response to disagreement, and then move on without waiting for replies.&lt;/p>
&lt;p>The “disagreers” were most common in politically-focused subreddits (forums focused on particular topics) such as r/news, r/worldnews, and r/politics. Interestingly, they were much less common in the now-banned pro-Trump forum r/The_Donald despite its political focus.&lt;/p>
&lt;p>This pattern reveals how behavioural analysis can uncover dynamics that content analysis might miss. In r/The_Donald, users tended to agree with each other while directing hostility toward outside targets. This dynamic may explain why traditional content moderation has struggled to address problems in such communities.&lt;/p>
&lt;h2 id="soccer-fans-and-gamers">Soccer fans and gamers&lt;/h2>
&lt;p>Our research also revealed unexpected connections. Users discussing completely different topics sometimes displayed remarkably similar behavioural patterns.&lt;/p>
&lt;p>We found striking similarities between users discussing soccer (on r/soccer) and e-sports (on r/leagueoflegends).&lt;/p>
&lt;p>This similarity emerges from the fundamental nature of both communities. Soccer and e-sports fans engage in parallel ways: they passionately support specific teams, follow matches with intense interest, participate in heated discussions about strategies and player performances, celebrate victories, and dissect defeats.&lt;/p>
&lt;p>Both communities foster strong tribal identities. Users defend their favoured teams while critiquing rivals.&lt;/p>
&lt;p>Whether debating Premier League tactics or League of Legends champions, the underlying interaction patterns – the timing, sequence and emotional tone of responses – remain consistent across these topically distinct communities.&lt;/p>
&lt;p>This challenges conventional wisdom about online polarisation. While echo chambers are often blamed for increasing division, our research suggests behavioural patterns can transcend topical boundaries. Users may be divided more by how they interact than what they discuss.&lt;/p>
&lt;h2 id="beyond-troll-detection">Beyond troll detection&lt;/h2>
&lt;p>The implications of this research extend well beyond academic interest. Platform moderators could use behavioural patterns to identify potentially problematic users before they’ve posted large volumes of harmful content.&lt;/p>
&lt;p>Unlike content moderation, behavioural analysis does not depend on understanding language. It is hard to evade, since changing one’s behavioural patterns requires more effort than adjusting language.&lt;/p>
&lt;p>The approach could also help design more effective strategies to counter misinformation. Rather than focusing solely on the content, we can design systems that encourage more constructive engagement patterns.&lt;/p>
&lt;p>For social media users, this research offers a reminder that how we engage online – not just what we say – shapes our digital identity and influences others.&lt;/p>
&lt;p>As online spaces continue to grapple with manipulation, harassment and polarisation, approaches that consider behavioural patterns alongside content analysis may offer more effective solutions for fostering healthier online communities.&lt;/p></description></item><item><title>Opinion Market Model: Stemming Far-Right Opinion Spread using Positive Interventions</title><link>https://www.behavioral-ds.science/blogpost/omm/</link><pubDate>Fri, 13 Oct 2023 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/blogpost/omm/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>In our digital age, the surge of online extremism brings forth urgent concerns such as hate speech normalization, user radicalization, and societal division. Counteracting these issues calls for exploring mitigation strategies, be it through negative interventions, an example of which is the EU’s Digital Services Act seeking to regulate deletion of harmful content, or positive interventions strategically introduced into the opinion landscape to boost certain opinions. In our latest work (to be presented at ICWSM 2024), we introduce the Opinion Market Model (OMM) as a testbed to simulate and measure the impact of positive interventions on online opinion dynamics. Additionally, we show the OMM’s capability to detect possible backfiring of debunking.&lt;/p>
&lt;p>In this blog post, we delve into OMM's structure and demonstrate its ability to uncover cooperation-competition relations across online opinions about (a) Australian bushfires and (b) popular VEVO artists, and show how media coverage modulates the spread of far-right opinion.&lt;/p>
&lt;p>&lt;strong>Paper citation:&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Calderon, Pio, Rohit Ram, and Marian-Andrei Rizoiu. &amp;quot;Opinion Market Model:
Stemming Far-Right Opinion Spread using Positive Interventions.&amp;quot; In
International AAAI Conference on Web and Social Media (ICWSM) 2024.
&lt;/code>&lt;/pre>
&lt;p>(&lt;em>see full paper here: &lt;a href="https://arxiv.org/pdf/2208.06620.pdf">&lt;a href="https://arxiv.org/pdf/2208.06620.pdf">https://arxiv.org/pdf/2208.06620.pdf&lt;/a>&lt;/a>&lt;/em>)&lt;/p>
&lt;h2 id="interventions-in-the-online-opinion-ecosystem">Interventions in the Online Opinion Ecosystem&lt;/h2>
&lt;p>Online social media platforms are breeding grounds for discourse, fostering both cooperation and competition among opinions vying for limited public attention [1]. Two distinct intervention strategies have emerged to counter extremist views in the online landscape. Negative interventions operate by diverting attention away from certain opinions, employing measures such as fact-check alerts [2], shadow-banning [3], and outright banning of extremist content [4]. While these methods have proven effective [5], they are predominantly within the control of social media platforms that use them sparingly [6]. Conversely, positive interventions [7], including debunking misinformation [8] and amplifying media coverage [9], combat extremism by boosting certain opinions, often under the purview of governmental and media entities [10].&lt;/p>
&lt;p>Evaluating the feasibility and effectiveness of positive interventions requires the ability (1) to disentangle inter-opinion interactions from the reaction of opinions to interventions and (2) to test the sensitivity of the opinion ecosystem to interventions. We propose the Opinion Market Model handle these two issues effectively.&lt;/p>
&lt;h2 id="our-solution-the-opinion-market-model">Our Solution: The Opinion Market Model&lt;/h2>
&lt;p>The Opinion Market Model (OMM) models online opinion dynamics resulting from inter-opinion interactions and positive interventions&amp;rsquo; influence. Drawing an analogy from economic markets, the model views opinions as analogous to economic goods. Just as goods can compete or reinforce each other's market share, online opinions can engage in similar dynamics—competing for limited online attention or complementing each other. This analogy allows for applying market share attraction models [11], aiding in understanding opinion interactions and their competition for users&amp;rsquo; attention in the online realm.&lt;/p>
&lt;img src="./featured.png" width="60%">
&lt;p style="text-align: center;">&lt;em>Figure 1. The OMM as a two-tier model of the online opinion ecosystem.&lt;/em>&lt;/p>
&lt;p>OMM models the online opinion ecosystem across two tiers: online attention volumes and opinion market shares. Illustrated in Figure 1 is a simplified scenario with two opinions (labeled 0 and 1) on a social media platform. Each opinion is assumed to have two stances denoting far-right support (+) and moderate views (-).&lt;/p>
&lt;p>In terms of system inputs (top row of Figure 1), the OMM makes a distinction between exogenous signals \(S(t)\) (gray) and interventions \(X(t)\) (yellow) to influence online opinions. Exogenous signals modulate the dynamics of the opinions’ sizes and represent events like natural disasters or speeches. Interventions (such as increased media coverage) are designed to add attention to the opinion ecosystem, increasing the market share of certain opinions while suppressing others.&lt;/p>
&lt;p>The first tier (middle row of Figure 1) uses a discrete-time Hawkes process [12] to estimate opinion attention volumes (i.e. the daily number of postings featuring opinions) driven by both exogenous signals and the self-exciting nature of online popularity.
The second tier (bottom row of Figure 1) uses a market share attraction model to capture both inter-opinion interactions, either cooperative or competitive and driven by limited online user attention, and their response to positive interventions.&lt;/p>
&lt;h3 id="datasets">Datasets&lt;/h3>
&lt;p>We utilize two real-world datasets to showcase the predictive and interpretative capabilities of the OMM. Below, we give a short description of each.&lt;/p>
&lt;p>&lt;strong>Bushfire Opinions dataset.&lt;/strong> The Bushfire Opinions dataset contains 90 days of Twitter and Facebook discussions about bushfires and climate change between 1 November 2019 to 29 January 2020. We filter and label relevant Facebook and Twitter postings using the textual topic and opinion classifiers developed in [13] into six opinions:&lt;/p>
&lt;ol start="0">
&lt;li>Greens policies are the cause of the Australian bushfires.&lt;/li>
&lt;li>Mainstream media cannot be trusted.&lt;/li>
&lt;li>Climate change crisis is not real / is a UN hoax.&lt;/li>
&lt;li>Australian bushfires and climate change are not related.&lt;/li>
&lt;li>Australian bushfires were caused by random arsonists.&lt;/li>
&lt;li>Bushfires are a normal summer occurrence in Australia.&lt;/li>
&lt;/ol>
&lt;p>To distinguish between moderate (-) and far-right (+) opinions, we utilize the far-right stance detector in [14], which employs a measure of textual homophily to gauge the similarity between Twitter users and established far-right figures. Our set of opinions is denoted as \({(i−, i+)|i ∈ {0, &amp;hellip; , 5}}\). In total, we analyze data from two platforms, encompassing 74,461 tweets and 7,974 Facebook posts, all labeled with 12 distinct stanced opinions.&lt;/p>
&lt;p>The exogenous signal \(S(t)\) is defined as the 5-day rolling average of the Google Trends query &amp;ldquo;bushfire+climate change&amp;rdquo; in Australia, functioning as a representation of general interest and offline occurrences [15]. For positive interventions \({X_k(t)}\), we incorporate reputable (R) and controversial (C) news coverage from Australian and international sources. Reputable sources are drawn from the Reputable News Index (RNIX) [16], while controversial international sources are accessed through NELA-GT-2019 [17].&lt;/p>
&lt;p>&lt;strong>VEVO 2017 Top 10 dataset.&lt;/strong> We evaluate the OMM on a second dataset obtained by aligning artist-level time series of YouTube views and Twitter post counts for the top 10 VEVO-affiliated artists over a span of 100 days from 2 January 2017, to 11 April 2017. The YouTube data from the VEVO Music Graph dataset [18] encompasses daily view counts for music videos by verified VEVO artists across six English-speaking countries. Twitter post counts are collected through the Twitter API, using the artist's name as the input query. Unlike the Bushfire Opinions dataset, here we utilize distinct exogenous signals for each artist, referred to as \(S_i(t)\), derived from Google Trends. Our focus for the VEVO 2017 Top 10 dataset is uncovering intrinsic interactions among artists; hence, we leave out interventions \({X_k(t)}\).&lt;/p>
&lt;h3 id="predicting-opinion-volumes-and-market-shares">Predicting Opinion Volumes and Market Shares&lt;/h3>
&lt;p>Since OMM is a two-tier model, we can evaluate its predictive capabilities on two levels: (1) predicting opinion volumes and (2) predicting opinion shares. In the first task, we forecast the total volume of opinionated posts across each considered online platform during the prediction period after training on the training period. In the second task, we predict the market shares for each opinion on each platform during the prediction period.&lt;/p>
&lt;p>&lt;img src="./omm_2.png" alt="">&lt;/p>
&lt;p style="text-align: center;">&lt;em>Figure 2. Fitting and predicting with OMM on the Bushfire Opinions dataset.&lt;/em>&lt;/p>
&lt;p>Fig. 2(a) illustrates the alignment between observed (blue line) and modeled (orange line) opinion volumes in the bushfire dataset. Notably, we fit well within both training and prediction periods. In Fig. 2(b), the distribution of observed (left column) and fitted/predicted (right column) opinion market shares for the bushfire dataset are showcased. Again, OMM adeptly captures trends in opinion shares across both platforms. We also compare (see full text) the OMM to a multivariate linear regression baseline and state-of-the-art models in product share modeling (the Correlated Cascades model [19] and the Competing Products model [20]), and show superior performance.&lt;/p>
&lt;h3 id="uncovering-latent-opinion-interactions">Uncovering Latent Opinion Interactions&lt;/h3>
&lt;p>To understand the interactions of opinions with one another, we borrow the economic concept of elasticity and derive opinion share model elasticities from the OMM. These quantify the instantaneous competition-cooperation interactions across opinions, capturing both the direct effect of an opinion on another and the indirect effect of an opinion across other opinions. Elasticities are signed metrics: if positive we observe a cooperative relation, if negative a competitive relation.&lt;/p>
&lt;p>&lt;img src="./omm_3.png" alt="">&lt;/p>
&lt;p style="text-align: center;">&lt;em>Figure 3. (a) Inter-opinion OMM elasticities in the Bushfire Opinions dataset. (b) Youtube elasticities in the VEVO Top 10 dataset.&lt;/em>&lt;/p>
&lt;p>&lt;strong>Bushfire Opinions.&lt;/strong> Figure 3(a) shows the inter-opinion elasticities for the Bushfire Opinions dataset derived from the fitted OMM model. Within Twitter we observe substantial self-reinforcement among opinions, a sign of the echo chamber effect [21]. In addition, we see significant cross-reinforcement between far-right sympathizers and opponents, suggesting interactions or debates between opposing viewpoints. For Facebook, OMM identifies limited interaction between opinions due to Facebook far-right groups acting as a filter bubble.&lt;/p>
&lt;p>The results suggest that to suppress far-right opinions effectively we should avoid direct confrontation, which might unintentionally attract more attention to them. Instead, a more successful approach is to promote counter-arguments related to the far-right opinions. For example, on Twitter, to diminish the impact of the opinion &amp;ldquo;Australian bushfires were caused by random arsonists&amp;rdquo; (4+), the Opinion Market Model (OMM) suggests boosting opinions like &amp;ldquo;Climate change is real&amp;rdquo; (2-) and &amp;ldquo;Greens are not the cause of the bushfires&amp;rdquo; (0-). However, promoting the opposing view, such as &amp;ldquo;Australian bushfires were not caused by random arsonists&amp;rdquo; (4-), could actually backfire. Interestingly, the opinion &amp;ldquo;Bushfires are a normal summer occurrence in Australia&amp;rdquo; (5+) takes a different approach—it reinforces most moderate opinions and discourages far-right ones. Notably, this opinion (5+) seems to trigger &amp;ldquo;Climate change is real&amp;rdquo; (2-), possibly due to the stark contrast between these viewpoints. This effect is consistent across different platforms.&lt;/p>
&lt;p>&lt;strong>VEVO Artists.&lt;/strong> We show the fitted Youtube elasticities for the VEVO artists in Figure 3(b). We make three observations. Firstly, strong self-reinforcement exists for most artists, reflecting their dedicated fanbases. Secondly, the OMM captures significant artist interactions that align with real-world events and relationships. For example, it detects how Calvin Harris inhibits both Taylor Swift and Katy Perry, possibly linked to their past conflicts, while Harris&amp;rsquo; collaboration with Ariana Grande reinforces their positive relationship. Lastly, the unique relationships between artists (Katy Perry, Taylor Swift, and Ariana Grande) within the same genre (mainstream pop) highlight the intricate nature of fanbase dynamics, showing that similar artists can have diverse pairwise interactions rather than solely cooperating or competing for attention.&lt;/p>
&lt;h3 id="omm-as-a-testbed-for-interventions">OMM as a Testbed for Interventions&lt;/h3>
&lt;p>Positive interventions can have delayed impacts on the opinion ecosystem due to the interconnectedness of opinions. When an intervention boosts a particular opinion, it also indirectly boosts opinions that cooperate with it while inhibiting competitive opinions.&lt;/p>
&lt;p>We can leverage the OMM in a &amp;ldquo;what-if&amp;rdquo; scenario to understand long-term effects of media coverage in the bushfire case study. By synthetically varying intervention sizes, the OMM can serve as a testbed for prioritizing interventions and for designing A/B tests to determine causal impacts. The setup involves changing intervention volumes after a certain time, and then measuring the resulting percentage change in far-right opinions.&lt;/p>
&lt;p>&lt;img src="./omm_4.png" alt="">&lt;/p>
&lt;p style="text-align: center;">&lt;em>Figure 4. OMM-simulated percent changes in the far-right (+) opinion market shares on Facebook (left) and Twitter (right) by modulating the volume of reputable (R) and controversial (C) news for each opinion in the Bushfire Opinions dataset.&lt;/em>&lt;/p>
&lt;p>Figure 4 illustrates the average percentage changes in the market share of far-right opinions when manipulating the interventions \({R_i(t), C_i(t)}\) separately. For Facebook, reputable news generally suppresses far-right opinions and most controversial news reinforces them, except for certain topics like &amp;ldquo;Greens policies are the cause of the Australian bushfires&amp;rdquo; (\(R_0\)) and &amp;ldquo;Australian bushfires were caused by arsonists.&amp;rdquo; (\(R_4\)) On Twitter, both reputable and controversial news suppress far-right opinions, except for reputable news related to certain topics.&lt;/p>
&lt;p>The insights are twofold: firstly, Facebook's effect is moderate compared to Twitter due to Facebook's filter bubble nature. Secondly, indiscriminately increasing reputable news on Twitter can be ineffective and even counterproductive as it might attract more attention to far-right narratives and users (see \(R_3\) and \(R_4\)) [22].&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;p>[1] Wu, S.; Rizoiu, M.-A.; and Xie, L. 2019. Estimating Attention Flow in Online Video Networks. CSCW, 3: 1–25.&lt;br>
[2] Nekmat, E. 2020. Nudge effect of fact-check alerts: source influence and media skepticism on sharing of news misinformation in social media. Social Media+ Society, 6(1).&lt;br>
[3] Young, G. K. 2022. How much is too much: the difficulties of social media content moderation. Information &amp;amp; Communications Technology Law, 31(1): 1–16.&lt;br>
[4] Jackson, S. 2019. The double-edged sword of banning ex- tremists from social media.&lt;br>
[5] Clayton, K.; Blair, S.; Busam, J. A.; Forstner, S.; Glance, J.; Green, G.; Kawata, A.; Kovvuri, A.; Martin, J.; Morgan, E.; et al. 2020. Real solutions for fake news? Measuring the effectiveness of general warnings and fact-check tags in reducing belief in false stories on social media. Political Behavior, 42(4): 1073–1095.&lt;br>
[6] Porter, E.; and Wood, T. J. 2021. Fact checks actually work, even on Facebook. But not enough people see them. The Washington Post.&lt;br>
[7] GIFCT. 2021. Content-Sharing Algorithms, Processes, and Positive Interventions Working Group.&lt;br>
[8] Haciyakupoglu, G.; Hui, J. Y.; Suguna, V.; Leong, D.; and Rahman, M. F. B. A. 2018. Countering fake news: A survey of recent global initiatives.&lt;br>
[9] Horowitz, M.; Cushion, S.; Dragomir, M.; Gutierrez Manjo ́n, S.; and Pantti, M. 2022. A framework for assessing the role of public service media organizations in countering disinformation. Digital Journalism, 10(5).&lt;br>
[10] Radsch, C. 2016. Media Development and Countering Violent Extremism: An Uneasy Relationship, a Need for Dialogue. Center for International Media Assistance. (2016).&lt;br>
[11] Cooper, L. G. 1993. Chapter 6 Market-share models. In Marketing, volume 5, 259–314. Elsevier.&lt;br>
[12] Browning, R.; Sulem, D.; Mengersen, K.; Rivoirard, V.; and Rousseau, J. 2021. Simple discrete-time self-exciting models can describe complex dynamic processes: A case study of COVID-19. PLoS ONE, 16.&lt;br>
[13] Kong, Q.; Booth, E.; Bailo, F.; Johns, A.; and Rizoiu, M.-A. 2022. Slipping to the Extreme: A Mixed Method to Explain How Extreme Opinions Infiltrate Online Discussions. In AAAI ICWSM, volume 16, 524–535.&lt;br>
[14] Ram, R.; Thomas, E.; Kernot, D.; and Rizoiu, M.-A. 2022. Detecting Extreme Ideologies in Shifting Landscapes: an Automatic &amp;amp; Context-Agnostic Approach. arXiv:2208.04097.&lt;br>
[15] Sheshadri, K.; and Singh, M. P. 2019. The public and legislative impact of hyperconcentrated topic news. Science Advances, 5(8).&lt;br>
[16] Kong, Q.; Rizoiu, M.-A.; and Xie, L. 2020. Describing and predicting online items with reshare cascades via dual mixture self-exciting processes. In 29th ACM CIKM, 645–654.&lt;br>
[17] Gruppi, M.; Horne, B. D.; and Adalı, S. 2020. NELA-GT- 2019: A Large Multi-Labelled News Dataset for The Study of Misinformation in News Articles. arXiv:2003.08444.&lt;br>
[18] Wu, S.; Rizoiu, M.-A.; and Xie, L. 2019. Estimating Attention Flow in Online Video Networks. CSCW, 3: 1–25.&lt;br>
[19] Zarezade, A.; Khodadadi, A.; Farajtabar, M.; Rabiee, H. R.; and Zha, H. 2017. Correlated cascades: Compete or cooperate. AAAI 2017, 238–244.&lt;br>
[20] Valera, I.; and Gomez-Rodriguez, M. 2015. Modeling Adoption and Usage of Competing Products. In ICDM.&lt;br>
[21] Cinelli, M.; De Francisci Morales, G.; Galeazzi, A.; Quattrociocchi, W.; and Starnini, M. 2021. The echo chamber effect on social media. PNAS, 118(9).&lt;br>
[22] Peucker, M.; Fisher, T. J.; and Davey, J. 2022. Mainstream media use in far-right online ecosystems. Technical report.&lt;/p></description></item><item><title>Opinion Market Model: Stemming Far-Right Opinion Spread using Positive Interventions</title><link>https://www.behavioral-ds.science/theme2_content/omm/</link><pubDate>Fri, 13 Oct 2023 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme2_content/omm/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>In our digital age, the surge of online extremism brings forth urgent concerns such as hate speech normalization, user radicalization, and societal division. Counteracting these issues calls for exploring mitigation strategies, be it through negative interventions, an example of which is the EU’s Digital Services Act seeking to regulate deletion of harmful content, or positive interventions strategically introduced into the opinion landscape to boost certain opinions. In our latest work (to be presented at ICWSM 2024), we introduce the Opinion Market Model (OMM) as a testbed to simulate and measure the impact of positive interventions on online opinion dynamics. Additionally, we show the OMM’s capability to detect possible backfiring of debunking.&lt;/p>
&lt;p>In this blog post, we delve into OMM's structure and demonstrate its ability to uncover cooperation-competition relations across online opinions about (a) Australian bushfires and (b) popular VEVO artists, and show how media coverage modulates the spread of far-right opinion.&lt;/p>
&lt;p>&lt;strong>Paper citation:&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Calderon, Pio, Rohit Ram, and Marian-Andrei Rizoiu. &amp;quot;Opinion Market Model:
Stemming Far-Right Opinion Spread using Positive Interventions.&amp;quot; In
International AAAI Conference on Web and Social Media (ICWSM) 2024.
&lt;/code>&lt;/pre>
&lt;p>(&lt;em>see full paper here: &lt;a href="https://arxiv.org/pdf/2208.06620.pdf">&lt;a href="https://arxiv.org/pdf/2208.06620.pdf">https://arxiv.org/pdf/2208.06620.pdf&lt;/a>&lt;/a>&lt;/em>)&lt;/p>
&lt;h2 id="interventions-in-the-online-opinion-ecosystem">Interventions in the Online Opinion Ecosystem&lt;/h2>
&lt;p>Online social media platforms are breeding grounds for discourse, fostering both cooperation and competition among opinions vying for limited public attention [1]. Two distinct intervention strategies have emerged to counter extremist views in the online landscape. Negative interventions operate by diverting attention away from certain opinions, employing measures such as fact-check alerts [2], shadow-banning [3], and outright banning of extremist content [4]. While these methods have proven effective [5], they are predominantly within the control of social media platforms that use them sparingly [6]. Conversely, positive interventions [7], including debunking misinformation [8] and amplifying media coverage [9], combat extremism by boosting certain opinions, often under the purview of governmental and media entities [10].&lt;/p>
&lt;p>Evaluating the feasibility and effectiveness of positive interventions requires the ability (1) to disentangle inter-opinion interactions from the reaction of opinions to interventions and (2) to test the sensitivity of the opinion ecosystem to interventions. We propose the Opinion Market Model handle these two issues effectively.&lt;/p>
&lt;h2 id="our-solution-the-opinion-market-model">Our Solution: The Opinion Market Model&lt;/h2>
&lt;p>The Opinion Market Model (OMM) models online opinion dynamics resulting from inter-opinion interactions and positive interventions&amp;rsquo; influence. Drawing an analogy from economic markets, the model views opinions as analogous to economic goods. Just as goods can compete or reinforce each other's market share, online opinions can engage in similar dynamics—competing for limited online attention or complementing each other. This analogy allows for applying market share attraction models [11], aiding in understanding opinion interactions and their competition for users&amp;rsquo; attention in the online realm.&lt;/p>
&lt;img src="./featured.png" width="60%">
&lt;p style="text-align: center;">&lt;em>Figure 1. The OMM as a two-tier model of the online opinion ecosystem.&lt;/em>&lt;/p>
&lt;p>OMM models the online opinion ecosystem across two tiers: online attention volumes and opinion market shares. Illustrated in Figure 1 is a simplified scenario with two opinions (labeled 0 and 1) on a social media platform. Each opinion is assumed to have two stances denoting far-right support (+) and moderate views (-).&lt;/p>
&lt;p>In terms of system inputs (top row of Figure 1), the OMM makes a distinction between exogenous signals \(S(t)\) (gray) and interventions \(X(t)\) (yellow) to influence online opinions. Exogenous signals modulate the dynamics of the opinions’ sizes and represent events like natural disasters or speeches. Interventions (such as increased media coverage) are designed to add attention to the opinion ecosystem, increasing the market share of certain opinions while suppressing others.&lt;/p>
&lt;p>The first tier (middle row of Figure 1) uses a discrete-time Hawkes process [12] to estimate opinion attention volumes (i.e. the daily number of postings featuring opinions) driven by both exogenous signals and the self-exciting nature of online popularity.
The second tier (bottom row of Figure 1) uses a market share attraction model to capture both inter-opinion interactions, either cooperative or competitive and driven by limited online user attention, and their response to positive interventions.&lt;/p>
&lt;h3 id="datasets">Datasets&lt;/h3>
&lt;p>We utilize two real-world datasets to showcase the predictive and interpretative capabilities of the OMM. Below, we give a short description of each.&lt;/p>
&lt;p>&lt;strong>Bushfire Opinions dataset.&lt;/strong> The Bushfire Opinions dataset contains 90 days of Twitter and Facebook discussions about bushfires and climate change between 1 November 2019 to 29 January 2020. We filter and label relevant Facebook and Twitter postings using the textual topic and opinion classifiers developed in [13] into six opinions:&lt;/p>
&lt;ol start="0">
&lt;li>Greens policies are the cause of the Australian bushfires.&lt;/li>
&lt;li>Mainstream media cannot be trusted.&lt;/li>
&lt;li>Climate change crisis is not real / is a UN hoax.&lt;/li>
&lt;li>Australian bushfires and climate change are not related.&lt;/li>
&lt;li>Australian bushfires were caused by random arsonists.&lt;/li>
&lt;li>Bushfires are a normal summer occurrence in Australia.&lt;/li>
&lt;/ol>
&lt;p>To distinguish between moderate (-) and far-right (+) opinions, we utilize the far-right stance detector in [14], which employs a measure of textual homophily to gauge the similarity between Twitter users and established far-right figures. Our set of opinions is denoted as \({(i−, i+)|i ∈ {0, &amp;hellip; , 5}}\). In total, we analyze data from two platforms, encompassing 74,461 tweets and 7,974 Facebook posts, all labeled with 12 distinct stanced opinions.&lt;/p>
&lt;p>The exogenous signal \(S(t)\) is defined as the 5-day rolling average of the Google Trends query &amp;ldquo;bushfire+climate change&amp;rdquo; in Australia, functioning as a representation of general interest and offline occurrences [15]. For positive interventions \({X_k(t)}\), we incorporate reputable (R) and controversial (C) news coverage from Australian and international sources. Reputable sources are drawn from the Reputable News Index (RNIX) [16], while controversial international sources are accessed through NELA-GT-2019 [17].&lt;/p>
&lt;p>&lt;strong>VEVO 2017 Top 10 dataset.&lt;/strong> We evaluate the OMM on a second dataset obtained by aligning artist-level time series of YouTube views and Twitter post counts for the top 10 VEVO-affiliated artists over a span of 100 days from 2 January 2017, to 11 April 2017. The YouTube data from the VEVO Music Graph dataset [18] encompasses daily view counts for music videos by verified VEVO artists across six English-speaking countries. Twitter post counts are collected through the Twitter API, using the artist's name as the input query. Unlike the Bushfire Opinions dataset, here we utilize distinct exogenous signals for each artist, referred to as \(S_i(t)\), derived from Google Trends. Our focus for the VEVO 2017 Top 10 dataset is uncovering intrinsic interactions among artists; hence, we leave out interventions \({X_k(t)}\).&lt;/p>
&lt;h3 id="predicting-opinion-volumes-and-market-shares">Predicting Opinion Volumes and Market Shares&lt;/h3>
&lt;p>Since OMM is a two-tier model, we can evaluate its predictive capabilities on two levels: (1) predicting opinion volumes and (2) predicting opinion shares. In the first task, we forecast the total volume of opinionated posts across each considered online platform during the prediction period after training on the training period. In the second task, we predict the market shares for each opinion on each platform during the prediction period.&lt;/p>
&lt;p>&lt;img src="./omm_2.png" alt="">&lt;/p>
&lt;p style="text-align: center;">&lt;em>Figure 2. Fitting and predicting with OMM on the Bushfire Opinions dataset.&lt;/em>&lt;/p>
&lt;p>Fig. 2(a) illustrates the alignment between observed (blue line) and modeled (orange line) opinion volumes in the bushfire dataset. Notably, we fit well within both training and prediction periods. In Fig. 2(b), the distribution of observed (left column) and fitted/predicted (right column) opinion market shares for the bushfire dataset are showcased. Again, OMM adeptly captures trends in opinion shares across both platforms. We also compare (see full text) the OMM to a multivariate linear regression baseline and state-of-the-art models in product share modeling (the Correlated Cascades model [19] and the Competing Products model [20]), and show superior performance.&lt;/p>
&lt;h3 id="uncovering-latent-opinion-interactions">Uncovering Latent Opinion Interactions&lt;/h3>
&lt;p>To understand the interactions of opinions with one another, we borrow the economic concept of elasticity and derive opinion share model elasticities from the OMM. These quantify the instantaneous competition-cooperation interactions across opinions, capturing both the direct effect of an opinion on another and the indirect effect of an opinion across other opinions. Elasticities are signed metrics: if positive we observe a cooperative relation, if negative a competitive relation.&lt;/p>
&lt;p>&lt;img src="./omm_3.png" alt="">&lt;/p>
&lt;p style="text-align: center;">&lt;em>Figure 3. (a) Inter-opinion OMM elasticities in the Bushfire Opinions dataset. (b) Youtube elasticities in the VEVO Top 10 dataset.&lt;/em>&lt;/p>
&lt;p>&lt;strong>Bushfire Opinions.&lt;/strong> Figure 3(a) shows the inter-opinion elasticities for the Bushfire Opinions dataset derived from the fitted OMM model. Within Twitter we observe substantial self-reinforcement among opinions, a sign of the echo chamber effect [21]. In addition, we see significant cross-reinforcement between far-right sympathizers and opponents, suggesting interactions or debates between opposing viewpoints. For Facebook, OMM identifies limited interaction between opinions due to Facebook far-right groups acting as a filter bubble.&lt;/p>
&lt;p>The results suggest that to suppress far-right opinions effectively we should avoid direct confrontation, which might unintentionally attract more attention to them. Instead, a more successful approach is to promote counter-arguments related to the far-right opinions. For example, on Twitter, to diminish the impact of the opinion &amp;ldquo;Australian bushfires were caused by random arsonists&amp;rdquo; (4+), the Opinion Market Model (OMM) suggests boosting opinions like &amp;ldquo;Climate change is real&amp;rdquo; (2-) and &amp;ldquo;Greens are not the cause of the bushfires&amp;rdquo; (0-). However, promoting the opposing view, such as &amp;ldquo;Australian bushfires were not caused by random arsonists&amp;rdquo; (4-), could actually backfire. Interestingly, the opinion &amp;ldquo;Bushfires are a normal summer occurrence in Australia&amp;rdquo; (5+) takes a different approach—it reinforces most moderate opinions and discourages far-right ones. Notably, this opinion (5+) seems to trigger &amp;ldquo;Climate change is real&amp;rdquo; (2-), possibly due to the stark contrast between these viewpoints. This effect is consistent across different platforms.&lt;/p>
&lt;p>&lt;strong>VEVO Artists.&lt;/strong> We show the fitted Youtube elasticities for the VEVO artists in Figure 3(b). We make three observations. Firstly, strong self-reinforcement exists for most artists, reflecting their dedicated fanbases. Secondly, the OMM captures significant artist interactions that align with real-world events and relationships. For example, it detects how Calvin Harris inhibits both Taylor Swift and Katy Perry, possibly linked to their past conflicts, while Harris&amp;rsquo; collaboration with Ariana Grande reinforces their positive relationship. Lastly, the unique relationships between artists (Katy Perry, Taylor Swift, and Ariana Grande) within the same genre (mainstream pop) highlight the intricate nature of fanbase dynamics, showing that similar artists can have diverse pairwise interactions rather than solely cooperating or competing for attention.&lt;/p>
&lt;h3 id="omm-as-a-testbed-for-interventions">OMM as a Testbed for Interventions&lt;/h3>
&lt;p>Positive interventions can have delayed impacts on the opinion ecosystem due to the interconnectedness of opinions. When an intervention boosts a particular opinion, it also indirectly boosts opinions that cooperate with it while inhibiting competitive opinions.&lt;/p>
&lt;p>We can leverage the OMM in a &amp;ldquo;what-if&amp;rdquo; scenario to understand long-term effects of media coverage in the bushfire case study. By synthetically varying intervention sizes, the OMM can serve as a testbed for prioritizing interventions and for designing A/B tests to determine causal impacts. The setup involves changing intervention volumes after a certain time, and then measuring the resulting percentage change in far-right opinions.&lt;/p>
&lt;p>&lt;img src="./omm_4.png" alt="">&lt;/p>
&lt;p style="text-align: center;">&lt;em>Figure 4. OMM-simulated percent changes in the far-right (+) opinion market shares on Facebook (left) and Twitter (right) by modulating the volume of reputable (R) and controversial (C) news for each opinion in the Bushfire Opinions dataset.&lt;/em>&lt;/p>
&lt;p>Figure 4 illustrates the average percentage changes in the market share of far-right opinions when manipulating the interventions \({R_i(t), C_i(t)}\) separately. For Facebook, reputable news generally suppresses far-right opinions and most controversial news reinforces them, except for certain topics like &amp;ldquo;Greens policies are the cause of the Australian bushfires&amp;rdquo; (\(R_0\)) and &amp;ldquo;Australian bushfires were caused by arsonists.&amp;rdquo; (\(R_4\)) On Twitter, both reputable and controversial news suppress far-right opinions, except for reputable news related to certain topics.&lt;/p>
&lt;p>The insights are twofold: firstly, Facebook's effect is moderate compared to Twitter due to Facebook's filter bubble nature. Secondly, indiscriminately increasing reputable news on Twitter can be ineffective and even counterproductive as it might attract more attention to far-right narratives and users (see \(R_3\) and \(R_4\)) [22].&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;p>[1] Wu, S.; Rizoiu, M.-A.; and Xie, L. 2019. Estimating Attention Flow in Online Video Networks. CSCW, 3: 1–25.&lt;br>
[2] Nekmat, E. 2020. Nudge effect of fact-check alerts: source influence and media skepticism on sharing of news misinformation in social media. Social Media+ Society, 6(1).&lt;br>
[3] Young, G. K. 2022. How much is too much: the difficulties of social media content moderation. Information &amp;amp; Communications Technology Law, 31(1): 1–16.&lt;br>
[4] Jackson, S. 2019. The double-edged sword of banning ex- tremists from social media.&lt;br>
[5] Clayton, K.; Blair, S.; Busam, J. A.; Forstner, S.; Glance, J.; Green, G.; Kawata, A.; Kovvuri, A.; Martin, J.; Morgan, E.; et al. 2020. Real solutions for fake news? Measuring the effectiveness of general warnings and fact-check tags in reducing belief in false stories on social media. Political Behavior, 42(4): 1073–1095.&lt;br>
[6] Porter, E.; and Wood, T. J. 2021. Fact checks actually work, even on Facebook. But not enough people see them. The Washington Post.&lt;br>
[7] GIFCT. 2021. Content-Sharing Algorithms, Processes, and Positive Interventions Working Group.&lt;br>
[8] Haciyakupoglu, G.; Hui, J. Y.; Suguna, V.; Leong, D.; and Rahman, M. F. B. A. 2018. Countering fake news: A survey of recent global initiatives.&lt;br>
[9] Horowitz, M.; Cushion, S.; Dragomir, M.; Gutierrez Manjo ́n, S.; and Pantti, M. 2022. A framework for assessing the role of public service media organizations in countering disinformation. Digital Journalism, 10(5).&lt;br>
[10] Radsch, C. 2016. Media Development and Countering Violent Extremism: An Uneasy Relationship, a Need for Dialogue. Center for International Media Assistance. (2016).&lt;br>
[11] Cooper, L. G. 1993. Chapter 6 Market-share models. In Marketing, volume 5, 259–314. Elsevier.&lt;br>
[12] Browning, R.; Sulem, D.; Mengersen, K.; Rivoirard, V.; and Rousseau, J. 2021. Simple discrete-time self-exciting models can describe complex dynamic processes: A case study of COVID-19. PLoS ONE, 16.&lt;br>
[13] Kong, Q.; Booth, E.; Bailo, F.; Johns, A.; and Rizoiu, M.-A. 2022. Slipping to the Extreme: A Mixed Method to Explain How Extreme Opinions Infiltrate Online Discussions. In AAAI ICWSM, volume 16, 524–535.&lt;br>
[14] Ram, R.; Thomas, E.; Kernot, D.; and Rizoiu, M.-A. 2022. Detecting Extreme Ideologies in Shifting Landscapes: an Automatic &amp;amp; Context-Agnostic Approach. arXiv:2208.04097.&lt;br>
[15] Sheshadri, K.; and Singh, M. P. 2019. The public and legislative impact of hyperconcentrated topic news. Science Advances, 5(8).&lt;br>
[16] Kong, Q.; Rizoiu, M.-A.; and Xie, L. 2020. Describing and predicting online items with reshare cascades via dual mixture self-exciting processes. In 29th ACM CIKM, 645–654.&lt;br>
[17] Gruppi, M.; Horne, B. D.; and Adalı, S. 2020. NELA-GT- 2019: A Large Multi-Labelled News Dataset for The Study of Misinformation in News Articles. arXiv:2003.08444.&lt;br>
[18] Wu, S.; Rizoiu, M.-A.; and Xie, L. 2019. Estimating Attention Flow in Online Video Networks. CSCW, 3: 1–25.&lt;br>
[19] Zarezade, A.; Khodadadi, A.; Farajtabar, M.; Rabiee, H. R.; and Zha, H. 2017. Correlated cascades: Compete or cooperate. AAAI 2017, 238–244.&lt;br>
[20] Valera, I.; and Gomez-Rodriguez, M. 2015. Modeling Adoption and Usage of Competing Products. In ICDM.&lt;br>
[21] Cinelli, M.; De Francisci Morales, G.; Galeazzi, A.; Quattrociocchi, W.; and Starnini, M. 2021. The echo chamber effect on social media. PNAS, 118(9).&lt;br>
[22] Peucker, M.; Fisher, T. J.; and Davey, J. 2022. Mainstream media use in far-right online ecosystems. Technical report.&lt;/p></description></item><item><title>Detecting extreme ideologies in shifting landscapes</title><link>https://www.behavioral-ds.science/blogpost/ideology_detection/</link><pubDate>Thu, 02 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/blogpost/ideology_detection/</guid><description>
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/csWMgU7R52Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
&lt;/iframe>
&lt;p>Also check out &lt;a href="../authors/rohit-ram/">Rohit&lt;/a>’s and &lt;a href="../authors/ma-rizoiu/">Andrei&lt;/a>’s article that just appeared in The Conversation: &lt;a href="https://theconversation.com/can-ideology-detecting-algorithms-catch-online-extremism-before-it-takes-hold-200629">Can ideology-detecting algorithms catch online extremism before it takes hold?&lt;/a>&lt;/p>
&lt;p>In this &lt;a href="https://arxiv.org/pdf/2208.04097.pdf">our latest working paper&lt;/a>, we propose a completely automatic end-to-end ideology detection pipeline for the detection and psychosocial profiling of left-right political ideology, as well as far-right ideological users.
The pipeline fills a crucial gap by providing flexible methodology and tooling for understanding ideologies and building early warning systems for extreme ideology-motivated (and potentially violent) activity.&lt;/p>
&lt;p>&lt;strong>Paper citation:&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Ram, R. and Rizoiu, M.A., 2022. You are what you browse: A robust framework for uncovering political ideology.
arXiv preprint arXiv:2208.04097.&lt;/code>&lt;/pre>
&lt;p>(&lt;em>see full paper here: &lt;a href="https://arxiv.org/pdf/2208.04097.pdf">https://arxiv.org/pdf/2208.04097.pdf&lt;/a>&lt;/em>)&lt;/p>
&lt;div id="ideology-in-an-online-world" class="section level2">
&lt;h2>Ideology in an Online World&lt;/h2>
&lt;p>Ideology determines how we make sense of much of the world, our opinions, and our political actions.
It is not a new concept; throughout history, it served as the context for unrest.
However, ideological spread and radicalization have entered a new paradigm in our ever-connected world. The internet is a significant source of information and spreads opinions quickly through social platforms.
In particular, the anonymity and lack of accountability often associated with online communication set up a supportive environment for spreading far-right ideologies and radicalizing individuals into extremist groups.
Far-right extremism is a form of ideology that advocates for ultranationalism, racism, and opposition to immigration and multiculturalism.
These ideologies strongly correlate with violence and terrorism and threaten individual and collective security.&lt;/p>
&lt;p>The Australian Security Intelligence Organisation (ASIO) raised concerns about Australians being radicalized very young and the rise of extremist movements in Australia through online technologies &lt;span class="citation">(&lt;a href="#ref-asio" role="doc-biblioref">&lt;span>“Director-General’s Annual Threat Assessment”&lt;/span> 2021&lt;/a>)&lt;/span>.
ASIO claimed that during the COVID period, 30-40% of their caseload was devoted to far-right extremism, up from 10-15% in 2016 &lt;span class="citation">(&lt;a href="#ref-guardian1" role="doc-biblioref">Karp 2020&lt;/a>)&lt;/span>.&lt;/p>
&lt;p>Unfortunately, Ideologically Motivated Violent Extremism (IMVE) continues to be an issue in Australia.
On December 12th, 2022, two Queensland police officers were killed while performing routine duties &lt;span class="citation">(&lt;a href="#ref-guardian2" role="doc-biblioref">Gillespie and McGowan 2022&lt;/a>)&lt;/span>.
Later investigations would uncover that the three people, who killed the officers, were active online in producing deep-state and religious conspiratorial content.
Their content has since been removed from mainstream social platforms but continues to be shared on conspiratorial websites.
Such extreme-leaning content often serves as a lead indicator of violent extremism (as was the case in this incident and the Christchurch Mosque Shootings three years prior). However, the tools to identify and understand the psychosocial characteristics of these extreme individuals and communities are lacking.&lt;/p>
&lt;p>In this work, we build an end-to-end ideology detection pipeline and psychosocial profiles of ideological groups.
We find that right-leaning individuals tend to use moral-vice language more than left-leaning and that far-right individuals’ grievance language (violence, hate, paranoia, etc.) significantly differs from the moderates.&lt;/p>
&lt;/div>
&lt;div id="signals-of-ideology" class="section level2">
&lt;h2>Signals of Ideology&lt;/h2>
&lt;p>In online social settings, researchers face numerous barriers that prevent using traditional methods.
Directly asking users for their ideologies has dubious success, infringes on platform T&amp;amp;Cs, and does not scale to online populations.
Inferring users’ ideologies from their activity also does not scale as the data requires is prohibitively expensive and tedious to compile.&lt;/p>
&lt;p>Instead, to reduce expert labor to feasible levels, researchers infer ideologies from signals in user behavior – such as whether they use political hashtags, retweet politicians, or follow political parties.
We dub these signals &lt;em>ideological proxies&lt;/em>.&lt;/p>
&lt;p>Importantly, these &lt;em>ideological proxies&lt;/em> for online users can still require laborious labeling by context-specific experts.
For example, the hashtag &lt;em>#ScottyFromMarketing&lt;/em> requires an up-to-date expert in Australian politics to uncover that it expresses an anti-right-wing ideology.
For many researchers:
- access to contextual experts is difficult,
- labeling of signals is still laborious and expensive,
- and context switches require relabelling (exasperating the above problems).&lt;/p>
&lt;p>Unfortunately, such context switches are commonplace, as the context changes with time, country, or social platform.
Figure &lt;a href="#fig:teaser">1&lt;/a> showcases the problem: most commonly used &lt;em>ideological proxies&lt;/em> can only be transferred in narrow circumstances (represented by the green dotted regions).
For example, following political parties is country-dependent, politicians come and go with time, and hashtags are platform-dependent.
As such, we desire an &lt;em>ideological proxy&lt;/em> that is robust to changes in context, requires no expert labeling and is true to the gold standard.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:teaser">&lt;/span>
&lt;img src="teaser_v2.svg" alt="Schema showing that not all ideological proxies can context-switch." width="700px" />
&lt;p class="caption">
Figure 1: Schema showing that not all ideological proxies can context-switch.
&lt;/p>
&lt;/div>
&lt;!-- ![Not all ideological proxies can context-switch](teaser.png) -->
&lt;p>Furthermore, the &lt;em>ideological proxies&lt;/em> are often sparse among users; however, we would ideally like to detect influence amongst the entire population of users (as taking only active users could bias our inferences).
We further desire a method for inferring the ideology of (potentially inactive) users without direct &lt;em>ideological proxy&lt;/em> information.&lt;/p>
&lt;/div>
&lt;div id="our-solution-you-are-what-you-browse" class="section level2">
&lt;h2>Our Solution: You are what you browse&lt;/h2>
&lt;p>Our solution is a large-scale end-to-end ideology detection pipeline that can be used to profile entire populations of users.
The solution has two main components; the media proxy and the inference architecture.
The media proxy allows for labeling a subset of users, and the inference architecture allows for propagating these labels to the remaining users via socially-informed homophilic lenses.&lt;/p>
&lt;div id="the-media-proxy" class="section level3">
&lt;h3>The Media Proxy&lt;/h3>
&lt;p>For the first part of our work, we generate a proxy based on media-sharing behavior, which satisfies the desiderata.&lt;/p>
&lt;p>We generate the media proxy via two media slant datasets (although many are widely available).
The first is an extensive survey of media consumption behaviors conducted by Reuters &lt;span class="citation">(&lt;a href="#ref-newman2019reuters" role="doc-biblioref">Newman et al. 2019&lt;/a>)&lt;/span> in several countries in 2020 and 2021.
Participants reported the media publications they consume and their own political ideology.
We estimate the slant of a media source for each country and year as the average ideology of the participants who consume it.
The second dataset is the Allsides Media Bias Dataset &lt;span class="citation">(&lt;a href="#ref-sides2018media" role="doc-biblioref">Sides 2018&lt;/a>)&lt;/span>, which contains an expert-curated set of media publications.
The Allsides dataset contains mostly American-based media; conversely, Reuters covers the major media outlets in each country.
Given that each country and period will have a different conception of ideologies, we calibrate Reuter’s media slants to approximate the Allsides (minimizing the mean-squared error). Figure &lt;a href="#fig:slants">2&lt;/a> shows the slants for each media website within the Reuters dataset.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:slants">&lt;/span>
&lt;img src="url_slants.svg" alt="Plot showing the slants for various media websites." width="700px" />
&lt;p class="caption">
Figure 2: Plot showing the slants for various media websites.
&lt;/p>
&lt;/div>
&lt;!-- ![The slants for various media websites](./url_slants.png) -->
&lt;!-- We finally define the media slant of a media website, as its average over the country, year, and sources, and -->
&lt;p>Finally, we quantify a user’s ideology as the average ideology of their shared media.&lt;/p>
&lt;p>The media proxy resolves the issue of context switching; since it is applicable across many contexts and can be used widely in a fully automated fashion.
This allows us to create an end-to-end ideology detection pipeline.&lt;/p>
&lt;p>We further define methods to classify far-right users from their media-sharing behaviors, which we fully describe in the paper.&lt;/p>
&lt;/div>
&lt;div id="the-inference-architecture" class="section level3">
&lt;h3>The Inference Architecture&lt;/h3>
&lt;p>In the second part of our work, we define an inference architecture that allows inferring the ideological labels of the remaining users – e.g., users who do not share any URLs.
Our inference architecture relies on the sociological principle of homophily, where we hypothesize that similar users will share a similar ideology.
We measure homophily through three distinct lenses;&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;em>Lexical&lt;/em>: Users with similar language will have similar ideology&lt;/li>
&lt;li>&lt;em>Hashtag&lt;/em>: Users who participate in similar topics of discussion share a similar ideology&lt;/li>
&lt;li>&lt;em>Resharing&lt;/em>: Users who consume similar content (signaled via resharing of other users) will share a similar ideology&lt;/li>
&lt;/ol>
&lt;p>Through these lenses, we utilize an AutoML model, FLAML &lt;span class="citation">(&lt;a href="#ref-wang2021flaml" role="doc-biblioref">Wang et al. 2021&lt;/a>)&lt;/span> (with the LightGBM architecture), trained on users identified via an ideological proxy to propagate the labels to the remaining users and generate a complete ideological profile for a dataset.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="the-data" class="section level2">
&lt;h2>The Data&lt;/h2>
&lt;p>We utilize several large-scale datasets from various platforms to showcase the relative ease of applying our end-to-end pipeline.
The datasets’ characteristics are described in Table &lt;a href="#tab:datasets">1&lt;/a>.
&lt;!-- For evaluation purposes, we use \#QandA based on the popular ABC panel show. -->&lt;/p>
&lt;table>
&lt;caption>&lt;span id="tab:datasets">Table 1: &lt;/span>The datasets used through-out the analysis, with the number of users, posts, and affliated country.&lt;/caption>
&lt;thead>
&lt;tr class="header">
&lt;th align="left">Dataset&lt;/th>
&lt;th align="left">Users&lt;/th>
&lt;th align="left">Posts&lt;/th>
&lt;th align="left">Country&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="left">#Qanda&lt;/td>
&lt;td align="left">103,074&lt;/td>
&lt;td align="left">768,808&lt;/td>
&lt;td align="left">AUS&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">#Ausvotes&lt;/td>
&lt;td align="left">273,874&lt;/td>
&lt;td align="left">5,033,982&lt;/td>
&lt;td align="left">AUS&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">#SocialSense&lt;/td>
&lt;td align="left">49,442&lt;/td>
&lt;td align="left">358,292&lt;/td>
&lt;td align="left">AUS&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">Riot&lt;/td>
&lt;td align="left">574,281&lt;/td>
&lt;td align="left">1,067,794&lt;/td>
&lt;td align="left">US&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">Parler&lt;/td>
&lt;td align="left">120,048&lt;/td>
&lt;td align="left">603,820&lt;/td>
&lt;td align="left">US&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;!-- ![The datasets we apply our pipeline on](datasets.png) -->
&lt;div id="psychosocial-profiles-of-the-ideological-groups" class="section level3">
&lt;h3>Psychosocial profiles of the Ideological Groups&lt;/h3>
&lt;p>Large-scale profiling of entire online populations gives us significant insights into the characteristics of online populations.
We apply our inferred ideological labels of online users in two critical ways:&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>We derive a method for distinguishing the left and the right in terms of their moral language.&lt;/li>
&lt;li>We derive a method for distinguishing moderate and extreme ideologies in terms of their grievance language.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Distinguishing Left and Right&lt;/strong>:
We utilize the FrameAxis &lt;span class="citation">(&lt;a href="#ref-mokhberian2020moral" role="doc-biblioref">Mokhberian et al. 2020&lt;/a>)&lt;/span> methodology to metricize each user’s association with each of the five Moral Foundations &lt;span class="citation">(&lt;a href="#ref-graham2013moral" role="doc-biblioref">Graham et al. 2013&lt;/a>)&lt;/span> in terms of their vice and virtue axes.
Given the measures of the Moral Foundations in the user language, we can start to detect in what way the left and the right differ.
To do this, we find each ideological group’s mean vice and virtue scores and compare these to the neutral group.
Figure &lt;a href="#fig:mft">3&lt;/a> shows the outcome of this analysis on the SocialSense dataset.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:mft">&lt;/span>
&lt;img src="mft_diff_plot.svg" alt="Plot of the moral foundations of ideological groups in the SocialSense dataset, showing that the left prefer virtue and the right prefer vice language." width="700px" />
&lt;p class="caption">
Figure 3: Plot of the moral foundations of ideological groups in the SocialSense dataset, showing that the left prefer virtue and the right prefer vice language.
&lt;/p>
&lt;/div>
&lt;!-- ![Plot showing that the left prefer virtue and the right prefer vice language](mft_diff_plot.png) -->
&lt;p>We see that the left prefers the language of virtue, while the right prefers the language of vice.
This trend is largely consistent across all datasets.&lt;/p>
&lt;p>&lt;strong>Distinguishing Moderates and Extremes&lt;/strong>: We similarly generate measures via the Grievance Dictionary &lt;span class="citation">(&lt;a href="#ref-van2021grievance" role="doc-biblioref">Van der Vegt et al. 2021&lt;/a>)&lt;/span>, a threat assessment tool designed to highlight potential threats through their language.
Similar to the previous plot, we investigate the distribution of grievance scores for the ideological groups.
However, here we measure the difference between distributions with the Signed KL-divergence (a measure of the difference in the location and shape of distributions).
Figure &lt;a href="#fig:grievance">4&lt;/a> shows the results for the Ausvotes dataset.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:grievance">&lt;/span>
&lt;img src="grievance_diff_plot.svg" alt="Plot of the grievance categories of ideological groups in the #Ausvotes dataset, showing that the far-right is significantly different." width="700px" />
&lt;p class="caption">
Figure 4: Plot of the grievance categories of ideological groups in the #Ausvotes dataset, showing that the far-right is significantly different.
&lt;/p>
&lt;/div>
&lt;!-- ![Plot showing that the far-right use grievance language](grievance_diff_plot.png) -->
&lt;p>We observe that the far-right’s usage of grievance language is significantly different from the moderate ideological groups.
This adds evidence to the growing concern that members of the far-right may vent their frustration and participate in violent behavior.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="conclusion" class="section level2">
&lt;h2>Conclusion&lt;/h2>
&lt;p>In this work, we build a fully automatic end-to-end ideology detection pipeline for left-right and far-right detection.
Importantly, with the pipeline, we can show the differences between the left and right, and moderates and extremes in terms of psychosocial language, across a range of diverse datasets.&lt;/p>
&lt;div id="references" class="section level3 unnumbered">
&lt;h3>References&lt;/h3>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-asio" class="csl-entry">
&lt;span>“Director-General’s Annual Threat Assessment.”&lt;/span> 2021. &lt;em>ASIO&lt;/em>. &lt;a href="https://www.asio.gov.au/resources/speeches-and-statements/director-generals-annual-threat-assessment-2021">https://www.asio.gov.au/resources/speeches-and-statements/director-generals-annual-threat-assessment-2021&lt;/a>.
&lt;/div>
&lt;div id="ref-guardian2" class="csl-entry">
Gillespie, Eden, and Michael McGowan. 2022. &lt;span>“Queensland Shooting: Gareth and Stacey Train Published YouTube Video After Killing Police Officers.”&lt;/span> &lt;a href="https://www.theguardian.com/australia-news/2022/dec/16/queensland-shooting-gareth-and-stacey-train-youtube-video-published-after-killing-police" class="uri">https://www.theguardian.com/australia-news/2022/dec/16/queensland-shooting-gareth-and-stacey-train-youtube-video-published-after-killing-police&lt;/a>; The Guardian.
&lt;/div>
&lt;div id="ref-graham2013moral" class="csl-entry">
Graham, Jesse, Jonathan Haidt, Sena Koleva, Matt Motyl, Ravi Iyer, Sean P Wojcik, and Peter H Ditto. 2013. &lt;span>“Moral Foundations Theory: The Pragmatic Validity of Moral Pluralism.”&lt;/span> In &lt;em>Advances in Experimental Social Psychology&lt;/em>, 47:55–130. Elsevier.
&lt;/div>
&lt;div id="ref-guardian1" class="csl-entry">
Karp, Paul. 2020. &lt;span>“Asio Reveals up to 40% of Its Counter-Terrorism Cases Involve Far-Right Violent Extremism.”&lt;/span> &lt;a href="https://www.theguardian.com/australia-news/2020/sep/22/asio-reveals-up-to-40-of-its-counter-terrorism-cases-involve-far-right-violent-extremism" class="uri">https://www.theguardian.com/australia-news/2020/sep/22/asio-reveals-up-to-40-of-its-counter-terrorism-cases-involve-far-right-violent-extremism&lt;/a>; The Guardian.
&lt;/div>
&lt;div id="ref-mokhberian2020moral" class="csl-entry">
Mokhberian, Negar, Andrés Abeliuk, Patrick Cummings, and Kristina Lerman. 2020. &lt;span>“Moral Framing and Ideological Bias of News.”&lt;/span> In &lt;em>International Conference on Social Informatics&lt;/em>, 206–19. Springer.
&lt;/div>
&lt;div id="ref-newman2019reuters" class="csl-entry">
Newman, Nic, Richard Fletcher, Antonis Kalogeropoulos, DAL Levy, and Rasmus Kleis Nielsen. 2019. &lt;span>“Reuters Institute Digital News Report 2018. Reuters Institute for the Study of Journalism.”&lt;/span> Oxford.
&lt;/div>
&lt;div id="ref-sides2018media" class="csl-entry">
Sides, All. 2018. &lt;span>“Media Bias Ratings.”&lt;/span> &lt;em>Allsides. Com&lt;/em>. &lt;a href="https://www.allsides.com/media-bias/ratings">https://www.allsides.com/media-bias/ratings&lt;/a>.
&lt;/div>
&lt;div id="ref-van2021grievance" class="csl-entry">
Van der Vegt, Isabelle, Maximilian Mozes, Bennett Kleinberg, and Paul Gill. 2021. &lt;span>“The Grievance Dictionary: Understanding Threatening Language Use.”&lt;/span> &lt;em>Behavior Research Methods&lt;/em> 53 (5): 2105–19.
&lt;/div>
&lt;div id="ref-wang2021flaml" class="csl-entry">
Wang, Chi, Qingyun Wu, Markus Weimer, and Erkang Zhu. 2021. &lt;span>“FLAML: A Fast and Lightweight Automl Library.”&lt;/span> &lt;em>Proceedings of Machine Learning and Systems&lt;/em> 3: 434–47.
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Detecting extreme ideologies in shifting landscapes</title><link>https://www.behavioral-ds.science/theme1_content/ideology_detection/</link><pubDate>Thu, 02 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme1_content/ideology_detection/</guid><description>
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/csWMgU7R52Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
&lt;/iframe>
&lt;p>Also check out &lt;a href="../authors/rohit-ram/">Rohit&lt;/a>’s and &lt;a href="../authors/ma-rizoiu/">Andrei&lt;/a>’s article that just appeared in The Conversation: &lt;a href="https://theconversation.com/can-ideology-detecting-algorithms-catch-online-extremism-before-it-takes-hold-200629">Can ideology-detecting algorithms catch online extremism before it takes hold?&lt;/a>&lt;/p>
&lt;p>In this &lt;a href="https://arxiv.org/pdf/2208.04097.pdf">our latest working paper&lt;/a>, we propose a completely automatic end-to-end ideology detection pipeline for the detection and psychosocial profiling of left-right political ideology, as well as far-right ideological users.
The pipeline fills a crucial gap by providing flexible methodology and tooling for understanding ideologies and building early warning systems for extreme ideology-motivated (and potentially violent) activity.&lt;/p>
&lt;p>&lt;strong>Paper citation:&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Ram, R. and Rizoiu, M.A., 2022. You are what you browse: A robust framework for uncovering political ideology.
arXiv preprint arXiv:2208.04097.&lt;/code>&lt;/pre>
&lt;p>(&lt;em>see full paper here: &lt;a href="https://arxiv.org/pdf/2208.04097.pdf">https://arxiv.org/pdf/2208.04097.pdf&lt;/a>&lt;/em>)&lt;/p>
&lt;div id="ideology-in-an-online-world" class="section level2">
&lt;h2>Ideology in an Online World&lt;/h2>
&lt;p>Ideology determines how we make sense of much of the world, our opinions, and our political actions.
It is not a new concept; throughout history, it served as the context for unrest.
However, ideological spread and radicalization have entered a new paradigm in our ever-connected world. The internet is a significant source of information and spreads opinions quickly through social platforms.
In particular, the anonymity and lack of accountability often associated with online communication set up a supportive environment for spreading far-right ideologies and radicalizing individuals into extremist groups.
Far-right extremism is a form of ideology that advocates for ultranationalism, racism, and opposition to immigration and multiculturalism.
These ideologies strongly correlate with violence and terrorism and threaten individual and collective security.&lt;/p>
&lt;p>The Australian Security Intelligence Organisation (ASIO) raised concerns about Australians being radicalized very young and the rise of extremist movements in Australia through online technologies &lt;span class="citation">(&lt;a href="#ref-asio" role="doc-biblioref">&lt;span>“Director-General’s Annual Threat Assessment”&lt;/span> 2021&lt;/a>)&lt;/span>.
ASIO claimed that during the COVID period, 30-40% of their caseload was devoted to far-right extremism, up from 10-15% in 2016 &lt;span class="citation">(&lt;a href="#ref-guardian1" role="doc-biblioref">Karp 2020&lt;/a>)&lt;/span>.&lt;/p>
&lt;p>Unfortunately, Ideologically Motivated Violent Extremism (IMVE) continues to be an issue in Australia.
On December 12th, 2022, two Queensland police officers were killed while performing routine duties &lt;span class="citation">(&lt;a href="#ref-guardian2" role="doc-biblioref">Gillespie and McGowan 2022&lt;/a>)&lt;/span>.
Later investigations would uncover that the three people, who killed the officers, were active online in producing deep-state and religious conspiratorial content.
Their content has since been removed from mainstream social platforms but continues to be shared on conspiratorial websites.
Such extreme-leaning content often serves as a lead indicator of violent extremism (as was the case in this incident and the Christchurch Mosque Shootings three years prior). However, the tools to identify and understand the psychosocial characteristics of these extreme individuals and communities are lacking.&lt;/p>
&lt;p>In this work, we build an end-to-end ideology detection pipeline and psychosocial profiles of ideological groups.
We find that right-leaning individuals tend to use moral-vice language more than left-leaning and that far-right individuals’ grievance language (violence, hate, paranoia, etc.) significantly differs from the moderates.&lt;/p>
&lt;/div>
&lt;div id="signals-of-ideology" class="section level2">
&lt;h2>Signals of Ideology&lt;/h2>
&lt;p>In online social settings, researchers face numerous barriers that prevent using traditional methods.
Directly asking users for their ideologies has dubious success, infringes on platform T&amp;amp;Cs, and does not scale to online populations.
Inferring users’ ideologies from their activity also does not scale as the data requires is prohibitively expensive and tedious to compile.&lt;/p>
&lt;p>Instead, to reduce expert labor to feasible levels, researchers infer ideologies from signals in user behavior – such as whether they use political hashtags, retweet politicians, or follow political parties.
We dub these signals &lt;em>ideological proxies&lt;/em>.&lt;/p>
&lt;p>Importantly, these &lt;em>ideological proxies&lt;/em> for online users can still require laborious labeling by context-specific experts.
For example, the hashtag &lt;em>#ScottyFromMarketing&lt;/em> requires an up-to-date expert in Australian politics to uncover that it expresses an anti-right-wing ideology.
For many researchers:
- access to contextual experts is difficult,
- labeling of signals is still laborious and expensive,
- and context switches require relabelling (exasperating the above problems).&lt;/p>
&lt;p>Unfortunately, such context switches are commonplace, as the context changes with time, country, or social platform.
Figure &lt;a href="#fig:teaser">1&lt;/a> showcases the problem: most commonly used &lt;em>ideological proxies&lt;/em> can only be transferred in narrow circumstances (represented by the green dotted regions).
For example, following political parties is country-dependent, politicians come and go with time, and hashtags are platform-dependent.
As such, we desire an &lt;em>ideological proxy&lt;/em> that is robust to changes in context, requires no expert labeling and is true to the gold standard.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:teaser">&lt;/span>
&lt;img src="teaser_v2.svg" alt="Schema showing that not all ideological proxies can context-switch." width="700px" />
&lt;p class="caption">
Figure 1: Schema showing that not all ideological proxies can context-switch.
&lt;/p>
&lt;/div>
&lt;!-- ![Not all ideological proxies can context-switch](teaser.png) -->
&lt;p>Furthermore, the &lt;em>ideological proxies&lt;/em> are often sparse among users; however, we would ideally like to detect influence amongst the entire population of users (as taking only active users could bias our inferences).
We further desire a method for inferring the ideology of (potentially inactive) users without direct &lt;em>ideological proxy&lt;/em> information.&lt;/p>
&lt;/div>
&lt;div id="our-solution-you-are-what-you-browse" class="section level2">
&lt;h2>Our Solution: You are what you browse&lt;/h2>
&lt;p>Our solution is a large-scale end-to-end ideology detection pipeline that can be used to profile entire populations of users.
The solution has two main components; the media proxy and the inference architecture.
The media proxy allows for labeling a subset of users, and the inference architecture allows for propagating these labels to the remaining users via socially-informed homophilic lenses.&lt;/p>
&lt;div id="the-media-proxy" class="section level3">
&lt;h3>The Media Proxy&lt;/h3>
&lt;p>For the first part of our work, we generate a proxy based on media-sharing behavior, which satisfies the desiderata.&lt;/p>
&lt;p>We generate the media proxy via two media slant datasets (although many are widely available).
The first is an extensive survey of media consumption behaviors conducted by Reuters &lt;span class="citation">(&lt;a href="#ref-newman2019reuters" role="doc-biblioref">Newman et al. 2019&lt;/a>)&lt;/span> in several countries in 2020 and 2021.
Participants reported the media publications they consume and their own political ideology.
We estimate the slant of a media source for each country and year as the average ideology of the participants who consume it.
The second dataset is the Allsides Media Bias Dataset &lt;span class="citation">(&lt;a href="#ref-sides2018media" role="doc-biblioref">Sides 2018&lt;/a>)&lt;/span>, which contains an expert-curated set of media publications.
The Allsides dataset contains mostly American-based media; conversely, Reuters covers the major media outlets in each country.
Given that each country and period will have a different conception of ideologies, we calibrate Reuter’s media slants to approximate the Allsides (minimizing the mean-squared error). Figure &lt;a href="#fig:slants">2&lt;/a> shows the slants for each media website within the Reuters dataset.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:slants">&lt;/span>
&lt;img src="url_slants.svg" alt="Plot showing the slants for various media websites." width="700px" />
&lt;p class="caption">
Figure 2: Plot showing the slants for various media websites.
&lt;/p>
&lt;/div>
&lt;!-- ![The slants for various media websites](./url_slants.png) -->
&lt;!-- We finally define the media slant of a media website, as its average over the country, year, and sources, and -->
&lt;p>Finally, we quantify a user’s ideology as the average ideology of their shared media.&lt;/p>
&lt;p>The media proxy resolves the issue of context switching; since it is applicable across many contexts and can be used widely in a fully automated fashion.
This allows us to create an end-to-end ideology detection pipeline.&lt;/p>
&lt;p>We further define methods to classify far-right users from their media-sharing behaviors, which we fully describe in the paper.&lt;/p>
&lt;/div>
&lt;div id="the-inference-architecture" class="section level3">
&lt;h3>The Inference Architecture&lt;/h3>
&lt;p>In the second part of our work, we define an inference architecture that allows inferring the ideological labels of the remaining users – e.g., users who do not share any URLs.
Our inference architecture relies on the sociological principle of homophily, where we hypothesize that similar users will share a similar ideology.
We measure homophily through three distinct lenses;&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;em>Lexical&lt;/em>: Users with similar language will have similar ideology&lt;/li>
&lt;li>&lt;em>Hashtag&lt;/em>: Users who participate in similar topics of discussion share a similar ideology&lt;/li>
&lt;li>&lt;em>Resharing&lt;/em>: Users who consume similar content (signaled via resharing of other users) will share a similar ideology&lt;/li>
&lt;/ol>
&lt;p>Through these lenses, we utilize an AutoML model, FLAML &lt;span class="citation">(&lt;a href="#ref-wang2021flaml" role="doc-biblioref">Wang et al. 2021&lt;/a>)&lt;/span> (with the LightGBM architecture), trained on users identified via an ideological proxy to propagate the labels to the remaining users and generate a complete ideological profile for a dataset.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="the-data" class="section level2">
&lt;h2>The Data&lt;/h2>
&lt;p>We utilize several large-scale datasets from various platforms to showcase the relative ease of applying our end-to-end pipeline.
The datasets’ characteristics are described in Table &lt;a href="#tab:datasets">1&lt;/a>.
&lt;!-- For evaluation purposes, we use \#QandA based on the popular ABC panel show. -->&lt;/p>
&lt;table>
&lt;caption>&lt;span id="tab:datasets">Table 1: &lt;/span>The datasets used through-out the analysis, with the number of users, posts, and affliated country.&lt;/caption>
&lt;thead>
&lt;tr class="header">
&lt;th align="left">Dataset&lt;/th>
&lt;th align="left">Users&lt;/th>
&lt;th align="left">Posts&lt;/th>
&lt;th align="left">Country&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr class="odd">
&lt;td align="left">#Qanda&lt;/td>
&lt;td align="left">103,074&lt;/td>
&lt;td align="left">768,808&lt;/td>
&lt;td align="left">AUS&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">#Ausvotes&lt;/td>
&lt;td align="left">273,874&lt;/td>
&lt;td align="left">5,033,982&lt;/td>
&lt;td align="left">AUS&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">#SocialSense&lt;/td>
&lt;td align="left">49,442&lt;/td>
&lt;td align="left">358,292&lt;/td>
&lt;td align="left">AUS&lt;/td>
&lt;/tr>
&lt;tr class="even">
&lt;td align="left">Riot&lt;/td>
&lt;td align="left">574,281&lt;/td>
&lt;td align="left">1,067,794&lt;/td>
&lt;td align="left">US&lt;/td>
&lt;/tr>
&lt;tr class="odd">
&lt;td align="left">Parler&lt;/td>
&lt;td align="left">120,048&lt;/td>
&lt;td align="left">603,820&lt;/td>
&lt;td align="left">US&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;!-- ![The datasets we apply our pipeline on](datasets.png) -->
&lt;div id="psychosocial-profiles-of-the-ideological-groups" class="section level3">
&lt;h3>Psychosocial profiles of the Ideological Groups&lt;/h3>
&lt;p>Large-scale profiling of entire online populations gives us significant insights into the characteristics of online populations.
We apply our inferred ideological labels of online users in two critical ways:&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>We derive a method for distinguishing the left and the right in terms of their moral language.&lt;/li>
&lt;li>We derive a method for distinguishing moderate and extreme ideologies in terms of their grievance language.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Distinguishing Left and Right&lt;/strong>:
We utilize the FrameAxis &lt;span class="citation">(&lt;a href="#ref-mokhberian2020moral" role="doc-biblioref">Mokhberian et al. 2020&lt;/a>)&lt;/span> methodology to metricize each user’s association with each of the five Moral Foundations &lt;span class="citation">(&lt;a href="#ref-graham2013moral" role="doc-biblioref">Graham et al. 2013&lt;/a>)&lt;/span> in terms of their vice and virtue axes.
Given the measures of the Moral Foundations in the user language, we can start to detect in what way the left and the right differ.
To do this, we find each ideological group’s mean vice and virtue scores and compare these to the neutral group.
Figure &lt;a href="#fig:mft">3&lt;/a> shows the outcome of this analysis on the SocialSense dataset.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:mft">&lt;/span>
&lt;img src="mft_diff_plot.svg" alt="Plot of the moral foundations of ideological groups in the SocialSense dataset, showing that the left prefer virtue and the right prefer vice language." width="700px" />
&lt;p class="caption">
Figure 3: Plot of the moral foundations of ideological groups in the SocialSense dataset, showing that the left prefer virtue and the right prefer vice language.
&lt;/p>
&lt;/div>
&lt;!-- ![Plot showing that the left prefer virtue and the right prefer vice language](mft_diff_plot.png) -->
&lt;p>We see that the left prefers the language of virtue, while the right prefers the language of vice.
This trend is largely consistent across all datasets.&lt;/p>
&lt;p>&lt;strong>Distinguishing Moderates and Extremes&lt;/strong>: We similarly generate measures via the Grievance Dictionary &lt;span class="citation">(&lt;a href="#ref-van2021grievance" role="doc-biblioref">Van der Vegt et al. 2021&lt;/a>)&lt;/span>, a threat assessment tool designed to highlight potential threats through their language.
Similar to the previous plot, we investigate the distribution of grievance scores for the ideological groups.
However, here we measure the difference between distributions with the Signed KL-divergence (a measure of the difference in the location and shape of distributions).
Figure &lt;a href="#fig:grievance">4&lt;/a> shows the results for the Ausvotes dataset.&lt;/p>
&lt;div class="figure">&lt;span style="display:block;" id="fig:grievance">&lt;/span>
&lt;img src="grievance_diff_plot.svg" alt="Plot of the grievance categories of ideological groups in the #Ausvotes dataset, showing that the far-right is significantly different." width="700px" />
&lt;p class="caption">
Figure 4: Plot of the grievance categories of ideological groups in the #Ausvotes dataset, showing that the far-right is significantly different.
&lt;/p>
&lt;/div>
&lt;!-- ![Plot showing that the far-right use grievance language](grievance_diff_plot.png) -->
&lt;p>We observe that the far-right’s usage of grievance language is significantly different from the moderate ideological groups.
This adds evidence to the growing concern that members of the far-right may vent their frustration and participate in violent behavior.&lt;/p>
&lt;/div>
&lt;/div>
&lt;div id="conclusion" class="section level2">
&lt;h2>Conclusion&lt;/h2>
&lt;p>In this work, we build a fully automatic end-to-end ideology detection pipeline for left-right and far-right detection.
Importantly, with the pipeline, we can show the differences between the left and right, and moderates and extremes in terms of psychosocial language, across a range of diverse datasets.&lt;/p>
&lt;div id="references" class="section level3 unnumbered">
&lt;h3>References&lt;/h3>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-asio" class="csl-entry">
&lt;span>“Director-General’s Annual Threat Assessment.”&lt;/span> 2021. &lt;em>ASIO&lt;/em>. &lt;a href="https://www.asio.gov.au/resources/speeches-and-statements/director-generals-annual-threat-assessment-2021">https://www.asio.gov.au/resources/speeches-and-statements/director-generals-annual-threat-assessment-2021&lt;/a>.
&lt;/div>
&lt;div id="ref-guardian2" class="csl-entry">
Gillespie, Eden, and Michael McGowan. 2022. &lt;span>“Queensland Shooting: Gareth and Stacey Train Published YouTube Video After Killing Police Officers.”&lt;/span> &lt;a href="https://www.theguardian.com/australia-news/2022/dec/16/queensland-shooting-gareth-and-stacey-train-youtube-video-published-after-killing-police" class="uri">https://www.theguardian.com/australia-news/2022/dec/16/queensland-shooting-gareth-and-stacey-train-youtube-video-published-after-killing-police&lt;/a>; The Guardian.
&lt;/div>
&lt;div id="ref-graham2013moral" class="csl-entry">
Graham, Jesse, Jonathan Haidt, Sena Koleva, Matt Motyl, Ravi Iyer, Sean P Wojcik, and Peter H Ditto. 2013. &lt;span>“Moral Foundations Theory: The Pragmatic Validity of Moral Pluralism.”&lt;/span> In &lt;em>Advances in Experimental Social Psychology&lt;/em>, 47:55–130. Elsevier.
&lt;/div>
&lt;div id="ref-guardian1" class="csl-entry">
Karp, Paul. 2020. &lt;span>“Asio Reveals up to 40% of Its Counter-Terrorism Cases Involve Far-Right Violent Extremism.”&lt;/span> &lt;a href="https://www.theguardian.com/australia-news/2020/sep/22/asio-reveals-up-to-40-of-its-counter-terrorism-cases-involve-far-right-violent-extremism" class="uri">https://www.theguardian.com/australia-news/2020/sep/22/asio-reveals-up-to-40-of-its-counter-terrorism-cases-involve-far-right-violent-extremism&lt;/a>; The Guardian.
&lt;/div>
&lt;div id="ref-mokhberian2020moral" class="csl-entry">
Mokhberian, Negar, Andrés Abeliuk, Patrick Cummings, and Kristina Lerman. 2020. &lt;span>“Moral Framing and Ideological Bias of News.”&lt;/span> In &lt;em>International Conference on Social Informatics&lt;/em>, 206–19. Springer.
&lt;/div>
&lt;div id="ref-newman2019reuters" class="csl-entry">
Newman, Nic, Richard Fletcher, Antonis Kalogeropoulos, DAL Levy, and Rasmus Kleis Nielsen. 2019. &lt;span>“Reuters Institute Digital News Report 2018. Reuters Institute for the Study of Journalism.”&lt;/span> Oxford.
&lt;/div>
&lt;div id="ref-sides2018media" class="csl-entry">
Sides, All. 2018. &lt;span>“Media Bias Ratings.”&lt;/span> &lt;em>Allsides. Com&lt;/em>. &lt;a href="https://www.allsides.com/media-bias/ratings">https://www.allsides.com/media-bias/ratings&lt;/a>.
&lt;/div>
&lt;div id="ref-van2021grievance" class="csl-entry">
Van der Vegt, Isabelle, Maximilian Mozes, Bennett Kleinberg, and Paul Gill. 2021. &lt;span>“The Grievance Dictionary: Understanding Threatening Language Use.”&lt;/span> &lt;em>Behavior Research Methods&lt;/em> 53 (5): 2105–19.
&lt;/div>
&lt;div id="ref-wang2021flaml" class="csl-entry">
Wang, Chi, Qingyun Wu, Markus Weimer, and Erkang Zhu. 2021. &lt;span>“FLAML: A Fast and Lightweight Automl Library.”&lt;/span> &lt;em>Proceedings of Machine Learning and Systems&lt;/em> 3: 434–47.
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Acquaintances beat close friends for job connections, huge LinkedIn study shows</title><link>https://www.behavioral-ds.science/blogpost/linkedin_experiment/</link><pubDate>Mon, 19 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/blogpost/linkedin_experiment/</guid><description>&lt;h2 id="radio-adelaide-breakfast-interview">Radio Adelaide Breakfast interview:&lt;/h2>
&lt;p>&lt;audio
controls
src="RadioAdelaideBreakfast.mp3">
Your browser does not support the
&lt;code>audio&lt;/code> element.
&lt;/audio>&lt;/p>
&lt;p>Say you are looking for a new job. You head to LinkedIn to spruce up your profile and look around your social network.&lt;/p>
&lt;p>But who should you reach out to for an introduction to a potential new employer? A &lt;a href="https://www.science.org/doi/10.1126/science.abl4476">new study&lt;/a> of more than 20 million people, published in Science, shows that your close friends (on LinkedIn) are not your best bet: instead you should look to acquaintances you don't know well enough to share a personal connection with.&lt;/p>
&lt;h2 id="the-strength-of-weak-ties">The strength of weak ties&lt;/h2>
&lt;p>In 1973, the American sociologist &lt;a href="https://sociology.stanford.edu/people/mark-granovetter">Mark Granovetter&lt;/a> coined the phrase &amp;ldquo;&lt;a href="https://doi.org/10.1086%2F225469">the strength of weak ties&lt;/a>&amp;rdquo; in the context of social networks. He argued that the stronger the ties between two individuals, the more their friendship networks will overlap.&lt;/p>
&lt;p>Simply put, you are most likely to know all the friends of a close friend, but few of the friends of an acquaintance.&lt;/p>
&lt;p>So if you are searching for a job, you probably already know everything your immediate neighbourhood has to offer. Intuitively, it is the weak ties – your acquaintances – that offer the most opportunities for new discoveries.&lt;/p>
&lt;h2 id="weak-ties-and-jobs">Weak ties and jobs&lt;/h2>
&lt;p>Granovetter's theory feels right, but is it? A team of researchers from LinkedIn, Harvard Business School, Stanford and MIT set out to gather some empirical evidence on how weak ties affect job mobility.&lt;/p>
&lt;p>Their research piggy-backed on the efforts of engineers at LinkedIn to test and improve the platform's &amp;ldquo;People You May Know&amp;rdquo; recommendation algorithm. LinkedIn regularly updates this algorithm, which recommends new people to add to your network.&lt;/p>
&lt;p>One of these updates tested the effects of encouraging the formation of strong ties (recommending adding your close friends) versus weak ties (recommending acquaintances and friends of friends). The researchers then followed the users that participated in this &amp;ldquo;A/B testing&amp;rdquo; to see if the difference impacted their employment outcomes.&lt;/p>
&lt;p>More than 20 million LinkedIn users worldwide were randomly assigned to well-defined treatment groups. Users in each group were shown slightly different new contact recommendations, which led users in some groups to form more strong ties and users in other groups to form more weak ties.&lt;/p>
&lt;p>Next, the team measured how many jobs users in each group applied for, and how many &amp;ldquo;job transmissions&amp;rdquo; occurred. Job transmissions are of particular interest, as they are defined as getting a job in the same company as the new contact. A job transmission suggests the new contact helped land the job.&lt;/p>
&lt;h2 id="moderately-weak-ties-are-best">Moderately weak ties are best&lt;/h2>
&lt;p>The study uses causal analysis to go beyond simple correlations and connect link formation with employment. There are three important findings.&lt;/p>
&lt;p>First, the recommender engine significantly shapes link formation. Users who were recommended more weak links formed significantly more weak links, and users who were recommended more strong links formed more strong links.&lt;/p>
&lt;p>Second, the experiment provides causal evidence that moderately weak ties are more than twice as effective as strong ties in helping a job-seeker join a new employer. What's a &amp;ldquo;moderately&amp;rdquo; weak tie? The study found job transmission is most likely from acquaintances with whom you share about 10 mutual friends and rarely interact.&lt;/p>
&lt;p>Third, the strength of weak ties varied by industry. Whereas weak ties increased job mobility in more digital industries, strong ties increased job mobility in less digital industries.&lt;/p>
&lt;h2 id="better-recommendations">Better recommendations&lt;/h2>
&lt;p>This LinkedIn study is first to causally prove Granovetter's theory in the employment market. The causal analysis is key here, as large-scale studies of correlations between strength of ties and job transmission have shown strong ties are more beneficial, in what was considered until now a paradox.&lt;/p>
&lt;p>This study resolves the paradox and again proves the limitations of correlation studies, which do a poor job at disentangling confounding factors and sometimes lead to the wrong conclusions.&lt;/p>
&lt;p>From a practical point of view, the study outlines the best parameters for suggesting new links. It revealed that the connections most helpful in landing a job are your acquaintances, people you meet in professional settings, or friends of friends, rather than your closest friends – people with whom you share about 10 mutual contacts and with whom one is less likely to interact regularly.&lt;/p>
&lt;p>These can be translated into algorithmic recommendations, which can make the recommendation engines of professional networks such as LinkedIn even more proficient at helping job-seekers land jobs.&lt;/p>
&lt;h2 id="the-power-of-black-boxes">The power of black boxes&lt;/h2>
&lt;p>The public is often wary when large social media companies perform experiments on their users (see &lt;a href="https://www.bbc.com/news/technology-28051930">Facebook's infamous emotion experiment of 2014&lt;/a>).&lt;/p>
&lt;p>So, could LinkedIn's experiment have harmed its users? In theory, the users in the &amp;ldquo;strong link&amp;rdquo; treatment group might have missed the weak links that could have brought their next job.&lt;/p>
&lt;p>However, all groups had some degree of job mobility – some just a bit more than others. Moreover, since the researchers were observing an engineering experiment, the study itself seems to raise few ethical concerns.&lt;/p>
&lt;p>Nonetheless, it is a reminder to ask how much our most intimate professional decisions – such as selecting a new career or workplace – are determined by black-box artificial intelligence algorithms whose workings we cannot see.&lt;/p></description></item><item><title>Acquaintances beat close friends for job connections, huge LinkedIn study shows</title><link>https://www.behavioral-ds.science/theme3_content/linkedin_experiment/</link><pubDate>Mon, 19 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme3_content/linkedin_experiment/</guid><description>&lt;h2 id="radio-adelaide-breakfast-interview">Radio Adelaide Breakfast interview:&lt;/h2>
&lt;p>&lt;audio
controls
src="RadioAdelaideBreakfast.mp3">
Your browser does not support the
&lt;code>audio&lt;/code> element.
&lt;/audio>&lt;/p>
&lt;p>Say you are looking for a new job. You head to LinkedIn to spruce up your profile and look around your social network.&lt;/p>
&lt;p>But who should you reach out to for an introduction to a potential new employer? A &lt;a href="https://www.science.org/doi/10.1126/science.abl4476">new study&lt;/a> of more than 20 million people, published in Science, shows that your close friends (on LinkedIn) are not your best bet: instead you should look to acquaintances you don't know well enough to share a personal connection with.&lt;/p>
&lt;h2 id="the-strength-of-weak-ties">The strength of weak ties&lt;/h2>
&lt;p>In 1973, the American sociologist &lt;a href="https://sociology.stanford.edu/people/mark-granovetter">Mark Granovetter&lt;/a> coined the phrase &amp;ldquo;&lt;a href="https://doi.org/10.1086%2F225469">the strength of weak ties&lt;/a>&amp;rdquo; in the context of social networks. He argued that the stronger the ties between two individuals, the more their friendship networks will overlap.&lt;/p>
&lt;p>Simply put, you are most likely to know all the friends of a close friend, but few of the friends of an acquaintance.&lt;/p>
&lt;p>So if you are searching for a job, you probably already know everything your immediate neighbourhood has to offer. Intuitively, it is the weak ties – your acquaintances – that offer the most opportunities for new discoveries.&lt;/p>
&lt;h2 id="weak-ties-and-jobs">Weak ties and jobs&lt;/h2>
&lt;p>Granovetter's theory feels right, but is it? A team of researchers from LinkedIn, Harvard Business School, Stanford and MIT set out to gather some empirical evidence on how weak ties affect job mobility.&lt;/p>
&lt;p>Their research piggy-backed on the efforts of engineers at LinkedIn to test and improve the platform's &amp;ldquo;People You May Know&amp;rdquo; recommendation algorithm. LinkedIn regularly updates this algorithm, which recommends new people to add to your network.&lt;/p>
&lt;p>One of these updates tested the effects of encouraging the formation of strong ties (recommending adding your close friends) versus weak ties (recommending acquaintances and friends of friends). The researchers then followed the users that participated in this &amp;ldquo;A/B testing&amp;rdquo; to see if the difference impacted their employment outcomes.&lt;/p>
&lt;p>More than 20 million LinkedIn users worldwide were randomly assigned to well-defined treatment groups. Users in each group were shown slightly different new contact recommendations, which led users in some groups to form more strong ties and users in other groups to form more weak ties.&lt;/p>
&lt;p>Next, the team measured how many jobs users in each group applied for, and how many &amp;ldquo;job transmissions&amp;rdquo; occurred. Job transmissions are of particular interest, as they are defined as getting a job in the same company as the new contact. A job transmission suggests the new contact helped land the job.&lt;/p>
&lt;h2 id="moderately-weak-ties-are-best">Moderately weak ties are best&lt;/h2>
&lt;p>The study uses causal analysis to go beyond simple correlations and connect link formation with employment. There are three important findings.&lt;/p>
&lt;p>First, the recommender engine significantly shapes link formation. Users who were recommended more weak links formed significantly more weak links, and users who were recommended more strong links formed more strong links.&lt;/p>
&lt;p>Second, the experiment provides causal evidence that moderately weak ties are more than twice as effective as strong ties in helping a job-seeker join a new employer. What's a &amp;ldquo;moderately&amp;rdquo; weak tie? The study found job transmission is most likely from acquaintances with whom you share about 10 mutual friends and rarely interact.&lt;/p>
&lt;p>Third, the strength of weak ties varied by industry. Whereas weak ties increased job mobility in more digital industries, strong ties increased job mobility in less digital industries.&lt;/p>
&lt;h2 id="better-recommendations">Better recommendations&lt;/h2>
&lt;p>This LinkedIn study is first to causally prove Granovetter's theory in the employment market. The causal analysis is key here, as large-scale studies of correlations between strength of ties and job transmission have shown strong ties are more beneficial, in what was considered until now a paradox.&lt;/p>
&lt;p>This study resolves the paradox and again proves the limitations of correlation studies, which do a poor job at disentangling confounding factors and sometimes lead to the wrong conclusions.&lt;/p>
&lt;p>From a practical point of view, the study outlines the best parameters for suggesting new links. It revealed that the connections most helpful in landing a job are your acquaintances, people you meet in professional settings, or friends of friends, rather than your closest friends – people with whom you share about 10 mutual contacts and with whom one is less likely to interact regularly.&lt;/p>
&lt;p>These can be translated into algorithmic recommendations, which can make the recommendation engines of professional networks such as LinkedIn even more proficient at helping job-seekers land jobs.&lt;/p>
&lt;h2 id="the-power-of-black-boxes">The power of black boxes&lt;/h2>
&lt;p>The public is often wary when large social media companies perform experiments on their users (see &lt;a href="https://www.bbc.com/news/technology-28051930">Facebook's infamous emotion experiment of 2014&lt;/a>).&lt;/p>
&lt;p>So, could LinkedIn's experiment have harmed its users? In theory, the users in the &amp;ldquo;strong link&amp;rdquo; treatment group might have missed the weak links that could have brought their next job.&lt;/p>
&lt;p>However, all groups had some degree of job mobility – some just a bit more than others. Moreover, since the researchers were observing an engineering experiment, the study itself seems to raise few ethical concerns.&lt;/p>
&lt;p>Nonetheless, it is a reminder to ask how much our most intimate professional decisions – such as selecting a new career or workplace – are determined by black-box artificial intelligence algorithms whose workings we cannot see.&lt;/p></description></item><item><title>Doing research online (by SAGE Research Methods): A Mixed-Method to Explain How Extreme Opinions Infiltrate Online Discussions</title><link>https://www.behavioral-ds.science/theme2_content/sage-research-methods-online-problematic-content/</link><pubDate>Wed, 27 Jul 2022 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme2_content/sage-research-methods-online-problematic-content/</guid><description>&lt;iframe scrolling="no" webkitAllowFullScreen="true" mozallowfullscreen="true" allowFullScreen="true" width="640" height="360" src="https://methods.sagepub.com/video/embed/srmpromo/21fyoz/mapping-online-problematic-content-mixing-approaches">Your browser does not support iFrames.&lt;/iframe>
&lt;p>&lt;a href="https://www.behavioral-ds.science/authors/ma-rizoiu/">Andrei&lt;/a> was interviewed by SAGE Research Methods for the &lt;a href="https://uk.sagepub.com/en-gb/eur/sage-research-methods-doing-research-online">Doing Online Research&lt;/a> case study collection.
He discusses a case study using qualitative approaches and machine learning to map online problematic content, including blending digital ethnography and advanced machine learning, data collection, dataset augmentation, results, lessons learned, and recommendations.&lt;/p>
&lt;p>There is a strong focus on the interdisciplinarity of the work &amp;ndash; a collaboration with digital communication scientists &lt;a href="https://profiles.uts.edu.au/Amelia.Johns">Amelia Johns&lt;/a> and &lt;a href="https://profiles.uts.edu.au/Francesco.Bailo">Francesco Bailo&lt;/a>, literary scientist &lt;a href="https://profiles.uts.edu.au/Emily.Booth">Emily Booth&lt;/a>, and computer scientists &lt;a href="https://www.behavioral-ds.science/authors/quyu-kong/">Quyu Kong&lt;/a> and &lt;a href="https://www.behavioral-ds.science/authors/ma-rizoiu/">Marian-Andrei Rizoiu&lt;/a>.&lt;/p>
&lt;p>The interview is based on our &lt;a href="https://arxiv.org/pdf/2109.00302.pdf">recent paper&lt;/a> published in &lt;a href="https://www.icwsm.org/2022/index.html/">ICWSM 2022&lt;/a>, where we propose a complete solution to accelerate the qualitative analysis of problematic online speech — with a specific focus on opinions emerging from online communities — by leveraging machine learning algorithms.&lt;/p>
&lt;p>&lt;strong>Paper citation:&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Quyu Kong, Emily Booth, Francesco Bailo, Amelia Johns, and Marian-Andrei
Rizoiu. Slipping to the Extreme: A Mixed Method to Explain How Extreme
Opinions Infiltrate Online Discussions. In AAAI International Conference
on Web and Social Media (Vol. 16, pp. 524–535), 2022.
&lt;/code>&lt;/pre>
&lt;p>(see full paper here: &lt;a href="https://arxiv.org/pdf/2109.00302.pdf">https://arxiv.org/pdf/2109.00302.pdf&lt;/a>, and a full description of the research in &lt;a href="https://www.behavioral-ds.science/theme2_content/icwsm2022/">this blogpost&lt;/a>)&lt;/p>
&lt;p>&lt;strong>Acknowledgements:&lt;/strong>&lt;br>
This research was partially funded by the University of Technology of Sydney through a cross-faculty grant, Facebook Research under the Content Policy Research Initiative, and the Commonwealth of Australia (represented by the Defence Science and Technology Group) through a Defence Science Partnerships Agreement.&lt;/p></description></item><item><title>Slipping to the Extreme: A Mixed-Method to Explain How Extreme Opinions Infiltrate Online Discussions</title><link>https://www.behavioral-ds.science/theme2_content/icwsm2022/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme2_content/icwsm2022/</guid><description>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/HwFq3ywanp4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;p>In our &lt;a href="https://arxiv.org/pdf/2109.00302.pdf">recent paper&lt;/a> accepted at &lt;a href="https://www.icwsm.org/2022/index.html/">ICWSM 2022&lt;/a>, we propose a complete solution to accelerate the qualitative analysis of problematic online speech — with a specific focus on opinions emerging from online communities — by leveraging machine learning algorithms.&lt;/p>
&lt;p>&lt;strong>Paper citation:&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Quyu Kong, Emily Booth, Francesco Bailo, Amelia Johns, and Marian-Andrei
Rizoiu. Slipping to the Extreme: A Mixed-Method to Explain How Extreme
Opinions Infiltrate Online Discussions. In: Proceedings of the 16TH AAAI
International Conference on Web and Social Media, 2022.
&lt;/code>&lt;/pre>
&lt;p>(see full paper here: &lt;a href="https://arxiv.org/pdf/2109.00302.pdf">https://arxiv.org/pdf/2109.00302.pdf&lt;/a>)&lt;/p>
&lt;h3 id="problematic-speech-a-modern-plague">Problematic Speech: A Modern Plague&lt;/h3>
&lt;p>Problematic speech is online interactions, speech, and artifacts that are inaccurate, misleading, inappropriately attributed, or altogether fabricated [1].
In 2020, the COVID-19 pandemic alerted the world to complex issues that arise from social media platforms circulating user-generated misinformation, hate speech, and conspiracy theories [2].
There are several primary types of quantitative methods for addressing problematic information, including large-scale monitoring of social media datasets [3], understanding platforms, users, and networks contributing to the &amp;ldquo;infodemic&amp;rdquo; [4], and predicting future pathways of information spreading [5].
These studies provide valuable insights into understanding how problematic information spreads and detecting which sources are reshared frequently and by which accounts.
However, these approaches often have less to say about why certain opinions and views gain traction with vulnerable groups and online communities.&lt;/p>
&lt;p>Qualitative research methods are well placed to address this gap.
They provide rich, contextual insights into online communities&amp;rsquo; social beliefs, values, and practices, which shape how information is shared and how opinions are formed [6].
Nevertheless, a common criticism of qualitative research is that the in-depth knowledge comes at the expense of generating insights of limited representativeness and weak robustness of the findings.
Therefore, there is a gap between the depth of insight gained from ethnographic and qualitative approaches and the breadth of knowledge gained from computational methods from data science.&lt;/p>
&lt;p>Our work fills this gap by proposing a mixed-method approach that combines qualitative insights, large-scale data collection, and human-in-the-loop machine learning approaches.
We apply our method to map in-depth and in-breadth the problematic information around four topics:
&lt;em>2019-20 Australian bushfire season&lt;/em>,
&lt;em>Climate change&lt;/em>,
&lt;em>COVID-19&lt;/em>, and
&lt;em>Vaccination&lt;/em>
on three social media platforms (Facebook, Twitter, and YouTube).&lt;/p>
&lt;h2 id="our-solution-mixing-digital-ethnography-with-advanced-machine-learning">Our Solution: Mixing Digital Ethnography with Advanced Machine Learning&lt;/h2>
&lt;p>&lt;img src="fig1.png" alt="The pipeline of machine learning accelerated qualitative research where the human-in-the-loop machine learning algorithms are employed for dataset augmentation.">&lt;/p>
&lt;p>We present a complete solution that bridges and facilitates qualitative and quantitative analysis to study problematic online speech.
The pipeline consists of three components which are detailed in this section.&lt;/p>
&lt;h3 id="deep-qualitative-study">Deep qualitative study&lt;/h3>
&lt;p>The first component is the qualitative study.
We build a platform based on an open-source tool, &lt;a href="https://wikiba.se/">&lt;em>Wikibase&lt;/em>&lt;/a>, where we conduct qualitative and quantitative analysis.
Through the quantitative study, we build an ontology of problematic online speech.
We label a large number of social media postings using their topics.
Simultaneously, we construct a vocabulary of 71 opinions that we also use to label postings.
Some example opinions include:&lt;/p>
&lt;ul>
&lt;li>Climate change crisis isn't real&lt;/li>
&lt;li>United Nations is corrupt&lt;/li>
&lt;li>Climate change is a UN hoax&lt;/li>
&lt;li>United Nations wants to be the global ruling government&lt;/li>
&lt;li>Vaccines cause Autism&lt;/li>
&lt;li>The World Health Organisation is corrupt&lt;/li>
&lt;/ul>
&lt;p>These opinions contain mistrust in the government and supra-national structures (e.g., UN, WHO) and typical misinformation about vaccines.&lt;/p>
&lt;h3 id="unlabeled-data-collection">Unlabeled data collection&lt;/h3>
&lt;p>Qualitative approaches analyze emerging content and construct the vocabulary simultaneously when labeling the data.
However, they lack representativeness as they tend to be overly concentrated on narrow areas of the narrative landscape.
For this reason, the second step in our methodology involves collecting data at scale.
We collect large-scale raw data using the uncovered vocabulary from the deep qualitative study.
We construct keywords (shown in the table) for each topic to crawl social media data from three platforms.
We obtain a total of &lt;strong>13,321,813&lt;/strong> postings — &lt;strong>11,437,009&lt;/strong> Facebook postings, &lt;strong>1,793,927&lt;/strong> tweets and &lt;strong>90,877&lt;/strong> YouTube comments.&lt;/p>
&lt;p>&lt;img src="table.png" alt="keywords">&lt;/p>
&lt;h3 id="dataset-augmentation">Dataset augmentation&lt;/h3>
&lt;p>The next step is to annotate all the postings in our dataset automatically.
We employ machine learning algorithms to augment the data labeling process with a human-in-the-loop setting.&lt;/p>
&lt;p>By adopting the state-of-the-art text classification algorithm, RoBERTa [7,8], we first train the classifiers to identify problematic speech on postings annotated by the qualitative researchers.
Next, we deploy three strategies to select unlabeled data.
The active learning [9] strategy selects the data for which the classifiers are most uncertain.
The top-confidence strategy selects data that classifiers are most certain about.
The third strategy — the random strategy — randomly samples from unlabeled data.
The qualitative researchers then label the sampled data, introduce the newly labeled data in the ontology, and repeat the procedure iteratively until the predictive performance converges.&lt;/p>
&lt;h2 id="humanintheloop-performance">Human-in-the-loop Performance&lt;/h2>
&lt;p>We discuss here the convergence of prediction performance over labeling iterations.&lt;/p>
&lt;p>The following plot depicts the prediction performance on the test set macro-averaged over topics (accuracy in the left panel and F1 score on the right panel) over iterations.
The solid lines show the performance indicators, together with the cross-validation generalization error.&lt;/p>
&lt;p>The cross-validation performance is stable across iterations.
This is expected as the classifiers learn from the same data on which the generalization is estimated — i.e., the classifiers are representative of the data they were trained on.
However, the difference between the test set performance and cross-validation performance is indicative of the representativity over the entire dataset.
The cross-validation accuracy is consistently lower than the test set accuracy because the test data is more imbalanced than labeled data.
The cross-validation F1 is more optimistic than the test set F1.
Finally, the difference between the two stabilizes for the later iterations, further suggesting the convergence.
&lt;img src="fig3.png" alt="Convergence of topic classifier performances over seven iterations.">&lt;/p>
&lt;h2 id="applying-the-qualitative-mapping">Applying the Qualitative Mapping&lt;/h2>
&lt;p>We employ the obtained augmented labeled set to analyze the dynamics of problematic opinions at scale.
We machine-label the opinions in a large set of postings spanning over a long time, allowing us to apply the qualitative-defined coding schema to a significantly larger sample of postings.
This reduces the unavoidable selection bias of the deep qualitative study.
It also offers a critical tool for analyzing co-occurring opinions, which helps identify central opinions.
It is common for postings to express multiple opinions.&lt;/p>
&lt;p>We explore central opinions by building an opinion co-occurrence network in the online conversation of the topic &lt;strong>2019-20 Australian bushfire season&lt;/strong>.
In the network, nodes are the opinions captured during the bushfire conversation, while edges are present when both opinions are detected in the same postings.
The node degree of a given opinion node represents the number of opinions that co-occurred with it.
The edges are weighted by the number of postings in which their connected node opinions co-occurred.&lt;/p>
&lt;p>The following plot presents each edge's daily proportions of weights among all edges between September 2019 and January 2020.
We show six edges (i.e., opinion pairs) to represent three types of temporal dynamics:&lt;/p>
&lt;ul>
&lt;li>A continuous and relatively strong association between prevalent opinions — &amp;ldquo;Climate change crisis isn't real&amp;rdquo; and &amp;ldquo;Climate change is a UN hoax,&amp;rdquo; which not notably is a conspiracy theory.&lt;/li>
&lt;li>Associations with declining relative frequencies — &amp;ldquo;Greta Thunberg should not have a platform or influence as a climate&amp;hellip;&amp;rdquo; and &amp;ldquo;Women and girls don't deserve a voice in the public sphere&amp;rdquo;.&lt;/li>
&lt;li>Rising associations such as &amp;ldquo;bushfires and climate change not related&amp;rdquo; and &amp;ldquo;bushfires were caused by random arsonists&amp;rdquo;; and also the conspiracy theory associations between &amp;ldquo;United Nations is corrupt&amp;rdquo; and &amp;ldquo;United Nations wants to be the global ruling government&amp;rdquo;.
&lt;img src="fig2.png" alt="Daily proportions of edge weights of six selected co-occurred opinions pairs.">&lt;/li>
&lt;/ul>
&lt;p>In the following plot, we map the co-occurrence network from posts published over 14 days in late September 2019, i.e., the period when the betweenness for conspiracy opinions is at peak.
This figure explains the ambivalent network role that conspiracy opinions can play: we first note a conspiracy opinion with relatively high degree and frequency — &amp;ldquo;Climate change is a UN hoax&amp;rdquo; —, while we also observe the presence of low degree but high betweenness conspiracy opinions at the periphery of the network — &amp;ldquo;Bushfires linked to secret elites&amp;rsquo; secret technology (chemtrails, HAARP, HSRN, geoengineering)&amp;quot;, &amp;ldquo;bushfires deliberately lit to promote a climate change agenda&amp;rdquo; and &amp;ldquo;Australia should not be a member of the United Nations&amp;rdquo;.&lt;/p>
&lt;p>&lt;img src="featured.png" alt="A visualization of the co-occurrence network in late September 2020 — node sizes and colors indicate the degrees and betweenness values">&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;p>[1] Jack, C. 2017. Lexicon of lies: Terms for problematic information. Data &amp;amp; Society.&lt;br>
[2] Posetti, J.; and Bontcheva, K. 2020. Disinfodemic: deciphering COVID-19 disinformation. Policy brief 1.&lt;br>
[3] Ram, R.; Kong, Q.; and Rizoiu, M.-A. 2021. Birdspotter: A Tool for Analyzing and Labeling Twitter Users. In WSDM. ACM.&lt;br>
[4] Smith, N.; and Graham, T. 2019. Mapping the anti-vaccination movement on Facebook. Information, Communication &amp;amp; Society.&lt;br>
[5] Molina, M. D.; Sundar, S. S.; Le, T.; and Lee, D. 2019. “Fake news” is not simply false information: a concept explication and taxonomy of online content. American behavioral scientist&lt;br>
[6] Glaeser, E. L.; and Sunstein, C. R. 2009. Extremism and social learning. Journal of Legal Analysis.&lt;br>
[7] Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; and Polosukhin, I. 2017. Attention is all you need. In NeurIPS.&lt;br>
[8] Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.; Levy, O.; Lewis, M.; Zettlemoyer, L.; and Stoyanov, V. 2019. Roberta: A robustly optimized BERT pretraining approach. arXiv.&lt;br>
[9] Settles, B. 2012. Active learning. Synthesis lectures on artificial intelligence and machine learning.&lt;/p></description></item><item><title>Running Jupyter notebooks on iHPC</title><link>https://www.behavioral-ds.science/extra/ihpc_guide/</link><pubDate>Wed, 13 Oct 2021 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/extra/ihpc_guide/</guid><description>&lt;p>This is a reference guide for accessing the iHPC system for UTS, with a focus on running Python and Jupyter notebooks on iHPC and accessing them from the desktop browser on your local machine.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="some-helpful-references">Some Helpful References&lt;/h2>
&lt;p>&lt;a href="https://ihpc.research.uts.edu.au/pages/documentation_rhel77/access_and_connectivity/ssh">This&lt;/a> is the reference for the website for remote access to the HPC at UTS.&lt;/p>
&lt;p>&lt;a href="https://www.blopig.com/blog/2018/03/running-jupyter-notebook-on-a-remote-server-via-ssh/">This&lt;/a> is an excellent blog on using Jupyter Notebooks remotely.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="step-1--open-the-tunnel-to-ihpc">Step 1 - Open the Tunnel to iHPC&lt;/h2>
&lt;p>Navigate to &lt;a href="https://vpn.uts.edu.au/vdesk/webtop.eui?webtop=/Common/webtop_vpn&amp;amp;webtop_type=webtop_full">this link&lt;/a>
and open &lt;strong>Student VPN Tunnel&lt;/strong>. The F5 VPN App should open up in a new window - accept (yes) and the tunnel will open up.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="step-2--access-the-ihpc-command-line">Step 2 - Access the iHPC (command line)&lt;/h2>
&lt;p>At the command line using use the following command to access the&lt;/p>
&lt;pre>&lt;code class="language-.bash"># Generic command
ssh username@...
# Example command for my access
ssh jwmurray@ihpc.eng.uts.edu.au
&lt;/code>&lt;/pre>
&lt;p>From here you will be asked for your password - input it as normal.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="step-3--connect-to-a-node-in-ihpc">Step 3 - Connect to a Node in iHPC&lt;/h2>
&lt;p>Now you will be effectively working in a remote computing environment. Use the command &lt;code>cnode&lt;/code> to get a list of the nodes within iHPC.&lt;/p>
&lt;p>Once you have a list of the nodes on the system you can see who is working in which node and what the usage rates are. To access a specific node you will need to have been granted access previously by the iHPC administrator. This is approved through a supervisor. The two nodes available for us to use are:&lt;/p>
&lt;ul>
&lt;li>hephaestos1&lt;/li>
&lt;li>hephaestos2&lt;/li>
&lt;/ul>
&lt;p>To connect to one of the nodes the following code is used:&lt;/p>
&lt;pre>&lt;code class="language-.bash">cnode hephaestos2 # this will give the detail of only this node
ssh hephaestos2 # this will actually connect to the node
&lt;/code>&lt;/pre>
&lt;p>You now have access to the server environment and can establish a VENV based on this remote server.&lt;/p>
&lt;p>There are two commands that will help navigation on the system&lt;/p>
&lt;pre>&lt;code class="language-.bash">cd ~ # This will get you to your own folder (Data and Templates)
cd / # This will take you to the root directory where all Data is stored.
&lt;/code>&lt;/pre>
&lt;p>The datasets for use are in the Behavioural DS project - the following command will take you there:&lt;/p>
&lt;pre>&lt;code class="language-.bash">cd /projects/BehavioralDS # Data sets is the folder of interest in this one
&lt;/code>&lt;/pre>
&lt;p>You have now opened a ssh tunnel to IHPC, connected to a node and accessed the Data sets in the Behavioural DS project folder on the system.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="step-4--create-venv-for-python">Step 4 - Create VENV for Python&lt;/h2>
&lt;p>Best practice is to create a VENV for Python for each project you run. This will enable a requirements file to be created easily for tracking the packages used in the analysis thereby making it easier for others to reproduce your work.&lt;/p>
&lt;p>Create this VENV in your personal folder for ease. &lt;a href="https://python.land/virtual-environments/virtualenv">This link&lt;/a> has details on how to do this.&lt;/p>
&lt;p>An example is below:&lt;/p>
&lt;pre>&lt;code class="language-.bash">python3 -m venv my_env # make sure to use python3 as python2 doesn't have the venv command baked into it. my_env can be whatever you want to call it. Use something unique as it will be referenced when working in jupyter notebooks.
&lt;/code>&lt;/pre>
&lt;p>&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="step-5--create-a-jupyter-notebook-host">Step 5 - Create a Jupyter Notebook host&lt;/h2>
&lt;p>Now the VENV is created (using python 3.6.8 on iHPC) we can start the Jupyter notebook host we will access remotely. Before we can do this we need to install ipython and jupyter into the VENV we jsut created. &lt;a href="https://deeplearning.lipingyang.org/2017/10/14/intall-ipython-and-jupyter-in-a-virtualenv/">This blog&lt;/a> is a good reference for how to do it.&lt;/p>
&lt;p>Once the VENV is established activate it with &lt;code>source myenv/bin/activate&lt;/code>. Once it is active we need to install iPython and Jupyter via &lt;code>pip3 install ...&lt;/code> into the environment we have created.&lt;/p>
&lt;p>Once we have done this any new packages we need to use as part of the analysis can be loaded with &lt;code>pip3 install (package name)&lt;/code>. Ideally keep two terminal windows open, one for updated packages as required in the remote environment and one for your local machine.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="step-6--set-up-remote-jupyter-notebooks">Step 6 - Set up Remote Jupyter notebooks&lt;/h2>
&lt;p>You'll need to set up the notebook environment on the remote server then establish the ssh environment then start it up on your local machine. Anything you save will be on the remote server, consider where notebooks are held and how to access them in the future.&lt;/p>
&lt;p>&lt;a href="https://www.blopig.com/blog/2018/03/running-jupyter-notebook-on-a-remote-server-via-ssh/">This blog&lt;/a> has the details required to make this work.&lt;/p>
&lt;p>Example code is below:&lt;/p>
&lt;pre>&lt;code class="language-.bash">jupyter notebook --port=9000 --no-browser
&lt;/code>&lt;/pre>
&lt;p>If the port is already in use it cycles through increasing by one on the port number until it serves the notebooks. This is OK as others may have used port number.&lt;/p>
&lt;p>We now have established a virtual environment for python on a remote system and are serving jupyter notebooks. We now need to access them from the desktop on our local machine.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="step-7--access-jupyter-notebooks-being-served-on-the-server">Step 7 - Access Jupyter Notebooks being served on the server&lt;/h2>
&lt;p>Now we need to open up another terminal on our machine, one that will be for use in the local environment. The following command is an example of how this can be done.&lt;/p>
&lt;pre>&lt;code class="language-.bash">ssh -N -f -L yyyy:localhost:xxxx jwmurray@ihpc.eng.uts.edu.au
# yyyy is the number you will use on your local machine
# xxxx is the port used to serve the notebooks remotely
&lt;/code>&lt;/pre>
&lt;p>&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="step-8--open-the-notebooks-and-weave-magic">Step 8 - Open the notebooks and weave magic&lt;/h2>
&lt;p>If everything has worked to this point you now have jupyter notebooks in a virtual environment being served from the powerful computers of iHPC. We just need to open up a browser and access jupyter from the local desktop. This is done in the usual manner with &lt;code>localhost:yyyy&lt;/code> in the browser of your web browser.&lt;/p>
&lt;p>From here any work you do in the notebooks will be saved on the remote server in the folder from where you served the notebooks from.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="step-9--terminate-the-session">Step 9 - Terminate the session&lt;/h2>
&lt;p>Consult &lt;a href="https://ihpc.research.uts.edu.au/pages/documentation_rhel77/access_and_connectivity/terminating">this link&lt;/a> for details on how to terminate the current session.&lt;/p></description></item><item><title>Discovering coordinated disinformation via Hawkes processes</title><link>https://www.behavioral-ds.science/theme2_content/coordinated_disinfo_hawkes/</link><pubDate>Mon, 27 Sep 2021 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme2_content/coordinated_disinfo_hawkes/</guid><description>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/kzGkvZRjnoI?start=70" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;p>Recording of the presentation &amp;ldquo;Discovering the Strategies and Promotion Schedules of Coordinated Disinformation via Hawkes Intensity Processes&amp;rdquo; (Tim Graham, &lt;strong>Marian-Andrei Rizoiu&lt;/strong>, Axel Bruns, Dan Angus), presented at the &lt;a href="https://www.ecrea2021.eu/">European Communication Conference (ECREA) 2021&lt;/a>, 8 Sep. 2021.&lt;/p>
&lt;h1 id="discovering-the-strategies-and-promotion-schedules-of-coordinated-disinformation-via-hawkes-intensity-processes">Discovering the Strategies and Promotion Schedules of Coordinated Disinformation via Hawkes Intensity Processes&lt;/h1>
&lt;p>&lt;a href="https://www.qut.edu.au/about/our-people/academic-profiles/timothy.graham">Tim Graham&lt;/a>, Digital Media Research Centre, Queensland University of Technology&lt;br>
&lt;a href="https://www.behavioral-ds.science/authors/ma-rizoiu/">Marian-Andrei Rizoiu&lt;/a>, Data Science Institute, University of Technology Sydney&lt;br>
&lt;a href="https://www.qut.edu.au/about/our-people/academic-profiles/a.bruns">Axel Bruns&lt;/a>, Digital Media Research Centre, Queensland University of Technology&lt;br>
&lt;a href="https://www.qut.edu.au/about/our-people/academic-profiles/daniel.angus">Dan Angus&lt;/a>, Digital Media Research Centre, Queensland University of Technology&lt;/p>
&lt;p>‘Fake news’ and broader ‘information disorders’ [6] such as mis- and disinformation have emerged as global issues that threaten to undermine democracy and authentic political communication on social media [1]. Increasingly sophisticated coordination strategies have intensified the scale and scope of the impact that disinformation has on public opinion and democratic trust. Howard et al. [3] found that coordinated disinformation operations are now occurring in 48 countries, and in 2019 the European External Action Service detected and exposed over 1,000 cases of disinformation within the European Union [2]. Whilst disinformation has attracted much scholarly attention, most studies to date have focussed on the diffusion and impact of individual content (e.g. ‘fake news’ articles) and the activity of individual accounts (e.g. bots and trolls).&lt;/p>
&lt;p>An emerging problem is to understand message coordination strategies, where content authored and distributed by agents (e.g. Twitter trolls) is governed and scheduled by some unknown principal actor [4]. We know that coordinated promotion (e.g. sharing, liking, retweeting) of ‘fake news’ articles by trolls and social bots can greatly increase and amplify the negative effects of these attempts to sow discord and manipulate public conversations about election candidates and partisan issues such as immigration and climate change. Likewise, it is evident that disinformation campaigns unfold via ‘collaborative work’ that co-opts and cultivates organic systems in order to produce desired effects such as increased polarisation, distrust in news media and confusion of the audience [7]. This makes identifying ‘inauthentic’ versus ‘organic’ activity ever more difficult, as they are intricately enmeshed in real-world disinformation campaigns.&lt;/p>
&lt;p>In this paper, we tackle the problem of inferring the coordinated promotion schedules of ‘fake news’ articles using a novel approach known as Hawkes Intensity Processes (HIP; see [5]). We analyse the diffusion of articles from ten major sources of hyperpartisan information and ‘fake news’ within over 16.5 million tweets that linked to content from these sites during July to September 2019. Using HIP, we uncover not only coordination strategies but also the promotion schedules of ‘fake news’ content, where agents (in this case Twitter accounts) are being centrally managed by principals (e.g. state operatives, government officials, etc.) in order to strategically promote ‘fake news’ content and maximise its virality and longevity in the social memory. This paper provides preliminary results from this ongoing research, highlighting the current challenges as well as open problems and gaps for future work.&lt;/p>
&lt;h3 id="references">References&lt;/h3>
&lt;p>[1] Benkler, Y., Faris, R., &amp;amp; Roberts, H. (2018). Network propaganda: Manipulation, disinformation, and radicalization in American politics. Oxford University Press.&lt;br>
[2] European Commission. (2019). Action plan against disinformation: Report in progress. Retrieved 20 November 2019 from: &lt;a href="https://ec.europa.eu/commission/sites/beta-political/files/factsheet_disinfo_elex_140619_final.pdf">https://ec.europa.eu/commission/sites/beta-political/files/factsheet_disinfo_elex_140619_final.pdf&lt;/a>.&lt;br>
[3] Howard, P. N., &amp;amp; Kollanyi, B. (2016). Bots, #StrongerIn, and #Brexit: Computational Propaganda during the UK-EU Referendum. SSRN Electronic Journal. doi:10.2139/ssrn.2798311&lt;br>
[4] Keller, F. B., Schoch, D., Stier, S., &amp;amp; Yang, J. (2019). Political Astroturfing on Twitter: How to Coordinate a Disinformation Campaign. Political Communication, 1-25.&lt;br>
[5] Rizoiu, M. A., Xie, L., Sanner, S., Cebrian, M., Yu, H., &amp;amp; Van Hentenryck, P. (2017, April). Expecting to be hip: Hawkes intensity processes for social media popularity. In Proceedings of the 26th International Conference on World Wide Web (pp. 735-744). International World Wide Web Conferences Steering Committee.&lt;br>
[6] Wardle, C., &amp;amp; Derakhshan, H. (2017). Information disorder: Toward an interdisciplinary framework for research and policymaking. Council of Europe Report DGI (2017) 09.&lt;br>
[7] Wilson, T., Zhou, K., &amp;amp; Starbird, K. (2018). Assembling Strategic Narratives: Information Operations as Collaborative Work within an Online Community. Proceedings of the ACM on Human-Computer Interaction, 2(CSCW), 183.&lt;/p>
&lt;h2 id="the-panel-coordinated-inauthentic-behaviour-in-social-media-new-methods-and-findings">The panel: &amp;ldquo;Coordinated Inauthentic Behaviour in Social Media: New Methods and Findings&amp;rdquo;&lt;/h2>
&lt;h3 id="panel-rationale">Panel Rationale&lt;/h3>
&lt;p>Social media platforms are increasingly forced to address what Facebook now describes as ‘coordinated inauthentic behaviour’ (Gleicher 2018): online influence operations that seek to trick platform algorithms into promoting and recommending ‘problematic information’ (Jack 2017), to mislead the human users of such platforms into accepting and sharing such content, and thereby also to affect broader issue frames and news agendas in mainstream media coverage. Concerns about such coordinated inauthentic behaviour extend earlier fears about the influence of malignant social bots, but also transcend them: drawing on social bots as well as human labour, coordinated inauthentic behaviour is likely to involve a combination of manual and automated activity. This additional human factor also complicates the detection of such coordinated activities, and their distinction from genuine, organic, authentic coordinated actions.&lt;/p>
&lt;p>This cross-national and interdisciplinary panel approaches the study of coordinated inauthentic behaviour from a number of directions. It outlines novel and innovative detection and analysis approaches for a number of leading social media platforms, and presents their results in the context of domestic and international political debates across several national contexts. Further, it also considers how mainstream journalism might report on and respond to such activities in order to protect news audiences from being affected by coordinated inauthentic behaviours.&lt;/p>
&lt;p>The first two papers in this panel focus especially on coordinated inauthentic link-sharing practices. Paper 1 introduces Hawkes Intensity Processes (HIP), a novel technique for inferring the coordinated content promotion schedules of automated social media accounts, and applies this to a major dataset of 16.5 million tweets containing links to ten major sites identified as sources of hyperpartisan content and ‘fake news’. In doing so, it uncovers new networks of inauthentic Twitter actors. Paper 2 investigates similar coordinated link-sharing activity on Facebook in Italy during the 2018 Italian and 2019 European elections. It uncovers evidence for the involvement of dozens of pages, groups, and public profiles in such media manipulation attempts. Paper 3 complements this work by focussing especially on the temporal posting patterns in such coordinated activity. It employs the recurrence plotting technique to identify traces of inauthentic actors’ use of automated scheduling tools in systematically posting content to a network of apparently unrelated pages, focussing here especially on a group of far-right pages on Facebook. Paper 4 examines ten coordinated disinformation campaigns across the globe (e.g., Hong Kong, Russia, USA, Spain and Germany) and identifies important traits that help distinguish between those participating in the disinformation campaign and the regular users they try to imitate. Paper 5, finally, shifts our attention to a core target of such coordinated inauthentic behaviour: the journalists and editors whose perception of current political moods such influence operations often aim to affect. Drawing on a series of in-depth interviews with Danish news workers and related stakeholders, it examines their understanding of and responses to coordinated mis- and disinformation campaigns.&lt;/p>
&lt;p>Collectively, these studies contribute substantially to advancing the methodological toolkit and extending the empirical evidence base for the study of coordinated inauthentic behaviour, while also not losing sight of the stakeholders that such work seeks to support. They offer an independent assessment of the nature and extent of the problem across several leading social media platforms, complementing the platform providers’ own investigations into such activities and identifying possible responses to such concerns for both social and mainstream media actors.&lt;/p>
&lt;h3 id="the-papers-presented-are-presenters-bolded">The papers presented are (presenters bolded):&lt;/h3>
&lt;ul>
&lt;li>Discovering the Strategies and Promotion Schedules of Coordinated Disinformation via Hawkes Intensity Processes (Tim Graham, &lt;strong>Marian-Andrei Rizoiu&lt;/strong>, Axel Bruns, Dan Angus)&lt;/li>
&lt;li>It Takes a Village to Manipulate the Media: Coordinated Link Sharing Behaviour during 2018 and 2019 Italian Elections (&lt;strong>Fabio Giglietto&lt;/strong>, Nicola Righetti, Luca Rossi, Giada Marino)&lt;/li>
&lt;li>Recurrence Plotting for Detecting Duplicate Online Posting Activities (&lt;strong>Dan Angus&lt;/strong>, Tim Graham, Tobias Keller, Brenda Moon, Axel Bruns)&lt;/li>
&lt;li>Astroturfing in Hong Kong and Elsewhere: Patterns of Coordination in Hidden Twitter Campaigns (&lt;strong>Franziska B. Keller&lt;/strong>, Sebastian Stier, David Schoch, JungHwan Yang)&lt;/li>
&lt;/ul></description></item><item><title>Compute and storage resources</title><link>https://www.behavioral-ds.science/extra/compute_resources/</link><pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/extra/compute_resources/</guid><description>&lt;p>Our group has access to considerable computation and storage resources. This document describes these and how to access them. Each resource has its own use scenario, and some may be more adapted to specific problems than others (for example, if you want to set up a Twitter crawler, use a Nectar Virtual Machine for better uptime and to avoid security issues on the compute servers).
We have four compute resources and each has attached a storage resource.&lt;/p>
&lt;h2 id="compute-servers-and-frameworks">Compute servers and frameworks&lt;/h2>
&lt;h3 id="ihpc-servers">iHPC servers&lt;/h3>
&lt;p>&lt;strong>Link to resource&lt;/strong>: &lt;a href="https://ihpc.research.uts.edu.au/">ihpc.research.uts.edu.au&lt;/a> (requires &lt;a href="https://vpn.uts.edu.au/">UTS VPN&lt;/a>)&lt;/p>
&lt;p>&lt;strong>Quick description&lt;/strong>: iHPC stands for Interactive High-Performance Computing. In a nutshell, these are very large machines (around 60 cores, and terabytes of memory). The machines are hosted in UTS and require both a UTS affiliation and special access. The servers are grouped into clusters, some of which require special access.&lt;/p>
&lt;p>Our group has a private cluster called &lt;em>hephaestos&lt;/em> which currently contains three machines (see print screen below). Our private cluster is accessible to BDS members only.&lt;/p>
&lt;p>&lt;img src="https://www.behavioral-ds.science/extra/onboarding_content/compute.png" width="100%" />&lt;/p>
&lt;p>&lt;strong>Getting access&lt;/strong>: Request an iHPC account (see &lt;a href="https://ihpc.research.uts.edu.au/">ihpc.research.uts.edu.au&lt;/a> for instructions). Mention the Behavioral Data Science group and Andrei in your request to be automatically added to the hephaestos access lists. &lt;strong>Make sure you read the documentation!&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Use case&lt;/strong>: the iHPC is designed for prototyping that requires large machines (Jupyter Notebook or RStudio), or for intermediary-size compute (for larger size see &lt;a href="#HPCC">UTS HPC&lt;/a> and &lt;a href="#NCI">NCI&lt;/a>). You can use iHPC using its Graphical User Interface (GUI) via NoMachine. You can also connect via console using:&lt;/p>
&lt;p>&lt;code>ssh &amp;lt;user&amp;gt;@hephaestos1.ihpc.uts.edu.au&lt;/code>&lt;/p>
&lt;p>For use with &lt;em>Jupyter Notebook&lt;/em> or &lt;em>RStudio Server&lt;/em>, you can redirect ports via SSH tunneling. Assuming the Jupyter Notebook/RStudio Server listens on port 8282, you can redirect that port by connecting to hephaestos1 using:&lt;/p>
&lt;p>&lt;code>ssh -L 8282:localhost:8282 &amp;lt;user&amp;gt;@hephaestos1.ihpc.uts.edu.au&lt;/code>&lt;/p>
&lt;p>after which you can connect the browser to your local machine to &lt;code>https://localhost:8282&lt;/code> and access the kernel on the distant machines. See &lt;a href="https://www.ssh.com/academy/ssh/tunneling/example">here for more details and examples&lt;/a>.&lt;/p>
&lt;p>&lt;strong>More details&lt;/strong>: For detailed instructions on setting up remote Jupyter notebooks on iHPC, check out &lt;a href="https://www.behavioral-ds.science/extra/ihpc_guide">this guide&lt;/a>.
&lt;br/>&lt;br/>&lt;/p>
&lt;h3 id="nectar-virtual-machines">NeCTAR Virtual Machines&lt;/h3>
&lt;p>&lt;strong>Link to resource&lt;/strong>: &lt;a href="https://dashboard.rc.nectar.org.au/">https://dashboard.rc.nectar.org.au/&lt;/a>&lt;/p>
&lt;p>&lt;strong>Quick description&lt;/strong>: NeCTAR is an infrastructure for virtual machines (i.e. machines that can be spawned for a particular purpose), similar to Amazon Web Services. This is quite useful for crawling data with no downtime, hosting visualizers, and even computing. More details here: &lt;a href="https://ardc.edu.au/services/nectar-research-cloud/">https://ardc.edu.au/services/nectar-research-cloud/&lt;/a>&lt;/p>
&lt;p>Our group has an allocation of 25 instances, 120 vCPUs, and 480 GB of RAM.&lt;/p>
&lt;p>&lt;strong>Getting access&lt;/strong>: First activate your UTS/ANU/Data61 account here: &lt;a href="https://dashboard.rc.nectar.org.au/">https://dashboard.rc.nectar.org.au/&lt;/a>. Then flip Andrei the email address associated with the account, and I'll add you to the project. Note: once you have access, you need to switch projects using the project selector in the top-left corner to access the behavioral-ds allocation.&lt;/p>
&lt;p>&lt;strong>Use case&lt;/strong>: You can easily spawn virtual machines, install stuff on them, play and destroy them. Each virtual machine acts as a computer, therefore you can install web interfaces, use it for compute (the larger flavors), and connect via SSH. The port forwarding trick described for iHPC also works for NeCTAR VMs.
&lt;a name="HPCC">&lt;/a>&lt;br/>&lt;br/>&lt;/p>
&lt;h3 id="uts-highperformance-computing-cluster-hpcc">UTS High-Performance Computing Cluster (HPCC)&lt;/h3>
&lt;p>&lt;strong>Link to resource&lt;/strong>: &lt;a href="https://hpc.research.uts.edu.au/">https://hpc.research.uts.edu.au/&lt;/a>&lt;/p>
&lt;p>&lt;strong>Usage status&lt;/strong>: &lt;a href="https://hpc.research.uts.edu.au/status/">https://hpc.research.uts.edu.au/status/&lt;/a>&lt;/p>
&lt;p>&lt;strong>Quick description&lt;/strong>: HPCC is a typical high-performance computing cluster (a.k.a. super-computers), in which jobs run non-interactively. See &lt;a href="https://docs.hpc.qmul.ac.uk/intro/">here a schema of HPC clusters&lt;/a>. UTS HPCC uses PBS as the scheduler, and it is designed to be fully compatible with NCI. Its mission is to be a training or development site for larger HPC projects destined for NCI.&lt;/p>
&lt;p>&lt;strong>Getting access&lt;/strong>: You need to request access to the HPCC. Email &lt;a href="mailto:eResearch-IT@uts.edu.au">&lt;a href="mailto:eResearch-IT@uts.edu.au">eResearch-IT@uts.edu.au&lt;/a>&lt;/a> to introduce yourself and your requirements. Make sure you mention Andrei and that you are part of the Behavioral DS group. Once you have access read the &lt;a href="https://hpc.research.uts.edu.au/getting_started/">HPC Getting Started&lt;/a> pages.&lt;/p>
&lt;p>&lt;strong>Use case&lt;/strong>: As HPC systems stand, UTS HPCC is a small system, but very useful for mid- to largish-scale computations. You can access 600 cores and up to 6TB of memory. Usage-wise, UTS HPCC stands in between iHPC and the NCI. That is, once your compute grows too large for iHPC, you use HPCC to scale it up and prepare your scripts for NCI.
&lt;a name="NCI">&lt;/a>&lt;br/>&lt;br/>&lt;/p>
&lt;h3 id="national-computation-infrastructure-nci-supercomputer--gadi">National Computation Infrastructure (NCI) supercomputer &amp;ndash; Gadi&lt;/h3>
&lt;p>&lt;strong>Link to resource&lt;/strong>: &lt;a href="https://nci.org.au/">https://nci.org.au/&lt;/a>&lt;/p>
&lt;p>&lt;strong>Usage status&lt;/strong>: &lt;a href="https://nci.org.au/our-systems/status">https://nci.org.au/our-systems/status&lt;/a>&lt;/p>
&lt;p>&lt;strong>Quick description&lt;/strong>: NCI’s Gadi is Australia’s supercomputer. Gadi has 3,200 compute nodes, 155,000 CPU cores, 567 Terabytes of memory, and 640 GPUs (as of 07/09/2021). It has a peak performance of 9 petaflops (by comparison, the largest supercomputer, Fugaku in Japan, has a &lt;a href="https://en.wikipedia.org/wiki/TOP500">peak performance of 442 petaflops&lt;/a>).&lt;/p>
&lt;p>Gadi is a cross-institutional shared resource, and its usage requires credit (in NCI terms &lt;em>service units&lt;/em> (SU)). Our group has a varying allocation of SUs to be used for computing, which can be dynamically increased. Speak to Andrei if you believe you may require more than we have or even if you may use up all the exiting allocation (not leaving enough for the others).&lt;/p>
&lt;p>&lt;strong>Getting access&lt;/strong>: You will need to &lt;a href="https://opus.nci.org.au/display/Help/How+to+create+an+NCI+user+account">request an NCI account&lt;/a> using your UTS/ANU/Data61 email address. Use our project code &lt;code>gh47: Tracking disinformation campaigns across social media (Marian-Andrei Rizoiu)&lt;/code> during the joining process. If you already have an account, simply request to join the project. You will subsequently use this project code for all computing. Make sure you have a read of the &lt;a href="https://opus.nci.org.au/display/Help/Gadi+User+Guide">Gadi User guide&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Use case&lt;/strong>: Use Gadi for the largest scale computes, which require years of sequential compute time. Ideally, you designed already your scripts using the &lt;a href="#HPCC">UTS HPCC&lt;/a>. Note that Gadi is less responsive than HPCC (and less forgiving with not respecting the limits and instructions).&lt;/p>
&lt;p>There are several queues available for Gadi, depending on your usage requirements. These include &lt;em>normal&lt;/em> (day-to-day compute), &lt;em>express&lt;/em> (small batches that can be executed fast), &lt;em>hugemem&lt;/em> and &lt;em>megamem&lt;/em> (large memory requirement), and &lt;em>gpuvolta&lt;/em> (for deep learning).
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="storage">Storage&lt;/h2>
&lt;h3 id="ihpc-data-folder-1tb">iHPC data folder (1TB)&lt;/h3>
&lt;p>iHPC home folders are limited to 32 GB. However, each iHPC user has a data folder of 1TB accessible at &lt;code>/data/&amp;lt;username&amp;gt;&lt;/code>. Put here all large files, including your anaconda and datasets. This data folder is on Network File System (NFS) and accessible from any iHPC machine.&lt;/p>
&lt;h3 id="ihpc-project-mount-20tb">iHPC project mount (20TB)&lt;/h3>
&lt;p>For shared files and datasets, our group has a project allocation of 20TB, accessible at &lt;code>/projects/BehavioralDS/&lt;/code>. All files in this folder are accessible by all group members.&lt;/p>
&lt;h3 id="nectar-storage-12tb">Nectar storage (12TB)&lt;/h3>
&lt;p>NeCTAR VMs have very little storage space (~30GB of disk). You can also create external volumes that can be attached to the VMs (each 50GB). For larger storage, our group has a 12TB NFS volume that needs to be attached using the following procedure.&lt;/p>
&lt;ol start="0">
&lt;li>
&lt;p>&lt;strong>Send the IP address or hostname of the machine&lt;/strong> that you want to mount the Space storage to Intersect Operations (&lt;a href="mailto:help@intersect.org.au">&lt;a href="mailto:help@intersect.org.au">help@intersect.org.au&lt;/a>&lt;/a>). &lt;strong>Copy Andrei to the email!&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Install NFS and automount related packages (for Ubuntu)&lt;/strong>:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;code>apt-get install nfs-common autofs rpcbind&lt;/code>&lt;/p>
&lt;p>&lt;code>systemctl enable rpcbind&lt;/code>&lt;/p>
&lt;p>&lt;code>systemctl start rpcbind&lt;/code>&lt;/p>
&lt;p>&lt;code>systemctl enable autofs&lt;/code>&lt;/p>
&lt;p>&lt;code>systemctl start autofs&lt;/code>&lt;/p>
&lt;ol start="2">
&lt;li>&lt;strong>Create Directories&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;code>mkdir -p /data/mounts&lt;/code>&lt;/p>
&lt;ol start="3">
&lt;li>&lt;strong>Create /etc/auto.data&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>&lt;code>echo &amp;quot;Q3530 -fstype=nfs,nfsvers=3 10.255.122.28:/gpfs/general00/pool9000/Q3530/Q3530&amp;quot; &amp;gt;&amp;gt; /etc/auto.data&lt;/code>&lt;/p>
&lt;ol start="4">
&lt;li>&lt;strong>Modify /etc/auto.master&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>Run the following command to insert mount point to /etc/auto.master file&lt;/p>
&lt;p>&lt;code>echo &amp;quot;/data/mounts /etc/auto.data&amp;quot; &amp;gt;&amp;gt; /etc/auto.master&lt;/code>&lt;/p>
&lt;ol start="5">
&lt;li>&lt;strong>Restart autofs and create symlink&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>Restart autofs service to apply the above changes&lt;/p>
&lt;p>&lt;code>systemctl restart autofs&lt;/code>&lt;/p>
&lt;p>&lt;code>ln -s /data/mounts/Q3530 /data/Q3530&lt;/code>
&lt;br/>&lt;br/>&lt;/p>
&lt;h3 id="nci-storage-4tb">NCI storage (4TB)&lt;/h3>
&lt;p>Our group has a storage allocation of 4TB on NCI. It can be accessed at &lt;code>/g/data/gh47/&lt;/code>. If you want to use this allocation in your PBS jobs, you need to explicitly ask for it in the submission script. For example, to indicate that credit should be used from gh47 and to access both the &lt;code>scratch&lt;/code> and the &lt;code>/g/data&lt;/code> allocation, one would add the following lines in the submission script:&lt;/p>
&lt;p>&lt;code>#PBS -P gh47&lt;/code>&lt;/p>
&lt;p>&lt;code>#PBS -l storage=scratch/gh47+g/data/gh47&lt;/code>&lt;/p></description></item><item><title>Onboarding</title><link>https://www.behavioral-ds.science/extra/onboarding/</link><pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/extra/onboarding/</guid><description>&lt;p>(this document is shamelessly adapted from &lt;a href="https://dlab.epfl.ch/onboarding/">Robert West’s excellent dlab onboarding page&lt;/a>)&lt;/p>
&lt;p>If you’re new to the &lt;a href="https://www.behavioral-ds.science/">Behavioral Data Science lab&lt;/a> (BDS), first of all: welcome! This page will help you get started by providing useful information on how to get set up and ready to roll. If you’re new not only to BDS but to UTS as a whole, see the bottom of this page for some additional useful pointers.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="compute-resources">Compute resources&lt;/h2>
&lt;p>As a very first step, carefully read &lt;a href="https://www.behavioral-ds.science/extra/compute_resources">this introduction&lt;/a> to our computing and storage resources: iHPC, UTS HPCC, Nectar, and NCI. It will tell you everything that’s necessary to get cracking and crunching with that exciting data!
&lt;br/>&lt;br/>&lt;/p>
&lt;p>&lt;a name="Group">&lt;/a>&lt;/p>
&lt;h2 id="communication">Communication&lt;/h2>
&lt;h3 id="groups-webpage">Group’s webpage&lt;/h3>
&lt;p>Our group’s webpage is https://www.behavioral-ds.science/. It lists the members, our news, our publications, and blog entries. We also use it to keep track of &lt;a href="#abcde">our reading group schedule&lt;/a>. Our website is collaborative, and every member needs to update it (for example to add their personal profile, or to fill in the reading details). The webpage is hosted on Github pages, and we update it by committing to the repository.&lt;/p>
&lt;p>To add your profile to the &lt;a href="https://www.behavioral-ds.science/people">lab's people page&lt;/a>, you need to fork the &lt;a href="https://github.com/behavioral-ds/behavioral-ds.github.io">lab's repository on GitHub&lt;/a>, edit it is to add your profile, and create a pull request. More instructions are in the repository’s README.
&lt;br/>&lt;br/>&lt;/p>
&lt;h3 id="slack">Slack&lt;/h3>
&lt;p>Join the &lt;a href="https://behavioral-ds.slack.com/">BDS team on Slack&lt;/a> by asking Andrei to send you an invite. We use Slack for all communications. The group’s philosophy is that we all are aware of the work of others, and we pitch in when we feel like it. The workspace is organized in public channels, one for each project.&lt;/p>
&lt;p>Each BDS member is part of the channels they work on (usually one project). All research-oriented discussions go in the project channel (please keep the DM for only admin and personal issues). Feel free to roam around and peek at any public channel.&lt;/p>
&lt;p>There are several public channels that you might want to peak at:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://behavioral-ds.slack.com/archives/CC1UMTHS7">#general&lt;/a> &amp;ndash; general announcements, usually admin- and social group-related&lt;/li>
&lt;li>&lt;a href="https://behavioral-ds.slack.com/archives/C019G01GFE2">#o-data&lt;/a> &amp;ndash; datasets&lt;/li>
&lt;li>&lt;a href="https://behavioral-ds.slack.com/archives/CNBBFBHHV">#compute-power&lt;/a> &amp;ndash; computation resources and issues&lt;/li>
&lt;li>&lt;a href="https://behavioral-ds.slack.com/archives/CMZJRKSKS">#reading&lt;/a> &amp;ndash; what to read, and announcements about the reading group&lt;/li>
&lt;li>&lt;a href="https://behavioral-ds.slack.com/archives/CC1G91JQZ">#random&lt;/a> &amp;ndash; non-work banter and water cooler conversation
&lt;br/>&lt;br/>&lt;/li>
&lt;/ul>
&lt;h3 id="meetings">Meetings&lt;/h3>
&lt;p>&lt;a href="https://medium.com/@jurgens_24580/reflections-on-strategies-for-successful-meetings-with-undergraduate-researchers-ae22306ecd8d">Here&lt;/a> is some good advice on how to make meetings with your advisor as effective and successful as possible. Please read it.&lt;/p>
&lt;p>Where possible, in-person (offline) meetings are preferred. For online and mixed-mode meetings we use Zoom. When online, we will use Zoom’s Shared Whiteboard to take collective notes. If you have a Zoom-compatible tablet with a pen, it is recommended to install Zoom as drawing with a pen is considerably easier than with a mouse. Alternative environments (like Miro or Google Jamboard) can also be used.
&lt;br/>&lt;br/>&lt;/p>
&lt;h3 id="reading-group">Reading group&lt;/h3>
&lt;p>We have a reading group that runs for one hour each week. The meeting runs mixed-mode, on Zoom and in-person in Sydney. During the meeting, we read papers and run group-oriented activities (such as three-minute thesis presentations and conference dry-runs). The meeting is run each week by a different member (see the &lt;a href="https://www.behavioral-ds.science/reading/">online roster&lt;/a>). When it is your turn, you can populate the meeting details as described above (see &lt;a href="#Group">group’s webpage&lt;/a>).
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="documenting-your-research">Documenting your research&lt;/h2>
&lt;h3 id="keeping-notes">Keeping notes&lt;/h3>
&lt;p>It is important that you keep thorough notes of your research. This will make it easier to remember the things you’ve done, the things you still need to do, important references you’ve come across, etc. It will also let you share your thoughts with the rest of the group, and it will make you a better, more disciplined researcher.&lt;/p>
&lt;p>We recommend two ways of keeping notes, you will need to choose one. The first is a rolling dated Overleaf document, where each week is a section and under which you note your work and progress, including figures and interpretations. Keep the most recent on top (i.e. you add at the beginning of the document, not at the end). The second way is the app &lt;a href="https://www.notion.so/">Notion&lt;/a>, which has free academic plans with your UTS student number email address. Create a master page that you will share with Andrei. On the Master page link your reading list, meeting notes etc. (see an example print-screen). Note that we suggest using a dedicated tool for managing your reading and related work (such as Mendeley or Zotero).&lt;/p>
&lt;p>&lt;img src="https://www.behavioral-ds.science/extra/onboarding_content/onboarding_1.png" width="50%" />
&lt;img src="https://www.behavioral-ds.science/extra/onboarding_content/onboarding_2.png" width="75%" />&lt;/p>
&lt;h3 id="writing-papers">Writing papers&lt;/h3>
&lt;p>You can find some tips and tools for writing papers in LaTeX on &lt;a href="https://dlab.epfl.ch/onboarding/paper-writing">dlab’s tips for writing&lt;/a>.
&lt;br/>&lt;br/>&lt;/p>
&lt;h3 id="blog-posts">Blog posts&lt;/h3>
&lt;p>Blog posts are a great way of publicizing your research results beyond good old (and slooow…) papers. They are also a channel for making what you’re doing accessible to the general public, rather than just to other academics.&lt;/p>
&lt;p>Therefore, every paper published at BDS is expected to be accompanied by a blog post that is written in non-technical terms and easily accessible to non-experts, to be published on &lt;a href="https://www.behavioral-ds.science/research">BDS’s research page&lt;/a>. You will need to select a category or shout if none is adequate.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="new-to-uts">New to UTS?&lt;/h2>
&lt;p>The following pointers might help you get started if you’ve just arrived at UTS.
&lt;br/>&lt;br/>&lt;/p>
&lt;h3 id="wifi">Wifi&lt;/h3>
&lt;p>On campus, the best wireless network to use is &lt;strong>UTS-Wifi&lt;/strong>. You can use it with your UTS student username and password. For Linux, check the below screen for configuration.&lt;/p>
&lt;p>&lt;img src="https://www.behavioral-ds.science/extra/onboarding_content/onboarding_3.png" width="75%" />&lt;/p>
&lt;h3 id="vpn">VPN&lt;/h3>
&lt;p>To access UTS resources, such as the iHPC compute servers, from outside of the UTS network, you need to use the &lt;a href="https://vpn.uts.edu.au/">UTS VPN&lt;/a>.
&lt;br/>&lt;br/>&lt;/p>
&lt;h3 id="uts-studentstaff-card">UTS student/staff card&lt;/h3>
&lt;p>During your first days at UTS, you’ll get your &lt;a href="https://www.uts.edu.au/current-students/managing-your-course/your-student-info/student-id-cards">UTS student card&lt;/a>, which will serve to access the library and the UTS buildings. Once you have the card, you need to finalize your Safety and Wellbeing Essentials (via Rapid Global, use &lt;a href="https://login.uts.edu.au">login.uts.edu.au&lt;/a> to access this application) after which you will automatically get access to DSI HDR dedicated spaces (room CB02.11.141) and all the space of DSI (Bulding 2, levels 11 and 12) and School of Computer Science (Building 11, levels 6 and 7).&lt;/p>
&lt;!--make sure you let the [Data Science admins](mailto:dsadmin@uts.edu.au) know so that -->
&lt;p>&lt;br/>&lt;br/>&lt;/p>
&lt;h3 id="uts-honorary-appointments">UTS Honorary appointments&lt;/h3>
&lt;p>Group members who are not UTS staff nor students need to obtain honorary UTS appointments. An honorary staff has a UTS online account and can access internal systems, including the compute resources (note: not all compute resources require a UTS affiliation, check details above).&lt;/p>
&lt;p>To get an Honorary appointment, Andrei needs to initiate the process with UTS admins, after which you will receive email instructions by email. Please make sure you fill in the online form ASAP, as the downstream admin process can take weeks. UTS Honorary members are considered staff in UTS systems.&lt;/p></description></item><item><title>PhD Opportunity</title><link>https://www.behavioral-ds.science/extra/phdopportunity/</link><pubDate>Tue, 03 Aug 2021 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/extra/phdopportunity/</guid><description>&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>Rare PhD opportunity for research on the Future of Work and Labour Markets applying Data Science and Machine Learning techniques&lt;/li>
&lt;li>Mentored by leading researchers and industrials in this space&lt;/li>
&lt;li>Access to datasets, strong industry partnerships, and international collaborations with top universities
&lt;br/>&lt;br/>&lt;/li>
&lt;/ul>
&lt;h2 id="the-research-topic">The Research Topic&lt;/h2>
&lt;p>Advances in automation technologies and labour market shocks, such as COVID-19, have elevated the importance of labour mobility issues. Therefore, identifying viable and desirable job transition pathways for individuals has been a growing area of interest. The current state of the art methods [Moro, Frank et al, Nat.Comm.’21] [Dawson et al, PLOS ONE ‘21] take a global view to estimate the dynamics of labour markets using factors such as skill similarity, location, education, experience, and industry labour flows. While these have been shown as important features for explaining job transition pathways, they implicitly assume that the changes in the occupation of an individual depend solely on their current occupation. Other works [Kern et al, PNAS’19] have shown that worker psychometric profiles (measured using Big5 feature) closely relate to their occupations. In other words, people have predispositions towards certain occupations. This project aims to build personalised recommender systems for occupation transitions that account for worker personality, previous experience and education.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="the-opportunity">The Opportunity&lt;/h2>
&lt;p>The Behavioral Data Science lab at UTS has several openings for PhD students to research the Future of Work and labour market networks. The topics of interest are job transitions, skills analysis, and the impacts of technology on labour markets. However, we’re open to other related areas, such as impacts of personality profiles on job choice, quantifying cultural differences between labour markets, and competitive dynamics of occupations and industries. The research will apply data science and machine learning techniques to labour market data, such as job ads and employment statistics.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="what-we-offer">What We Offer&lt;/h2>
&lt;p>This project is part of a wider collaboration with US-based universities and companies. This can open unique opportunities to research internships in both overseas academia and industry. Furthermore, you will be supported throughout your doctorate to become a first rate researcher. This will include:&lt;/p>
&lt;ul>
&lt;li>access to rich datasets to derive insights and real-world problems and know-how;&lt;/li>
&lt;li>exposure to industry networks to apply your work, and possible career paths upon graduation;&lt;/li>
&lt;li>collaboration with top international universities from our networks; and&lt;/li>
&lt;li>a supportive peer-group of doctoral researchers with regular events and reading groups.&lt;/li>
&lt;li>weekly meetings with supervisors to advance your research;&lt;/li>
&lt;/ul>
&lt;p>Once you graduate, you will have developed in-demand skills, published peer-review papers, broadened your professional network, and established yourself as an expert in the Future of Work.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="about-you">About You&lt;/h2>
&lt;p>To be successful in this role, you will either have:&lt;/p>
&lt;ul>
&lt;li>a strong background in data science and applied machine learning;&lt;/li>
&lt;li>an interest labour markets;&lt;/li>
&lt;li>knowledge of at least one programming language, such as Python and R;&lt;/li>
&lt;/ul>
&lt;p>AND/OR&lt;/p>
&lt;ul>
&lt;li>A strong background in economics and are willing to develop your technical skills;&lt;/li>
&lt;/ul>
&lt;p>You will also likely have an Honours or Masters degree. However, equivalent experience coupled with a relevant Bachelor’s Degree could also be sufficient.&lt;/p>
&lt;p>Most importantly, you will show a great deal of initiative, thrive under autonomy, and have a passion for applying rigorous research to help people understand real problems.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="funding">Funding&lt;/h2>
&lt;p>Scholarships are available but will be awarded through a competitive process. Stipend top-ups and paid research work might be available throughout your thesis.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="how-to-apply">How to Apply&lt;/h2>
&lt;p>If you are interested, please send your CV and a cover letter to &lt;a href="mailto:Marian-Andrei.Rizoiu@uts.edu.au">Marian-Andrei.Rizoiu@uts.edu.au&lt;/a>. The cover letter should detail your academic track record, why you are interested in this topic and why you are a good match for the subject.
&lt;br/>&lt;br/>&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;p>[Moro et al, Nat.Comm.’21] Moro, E., Frank, M. R., Pentland, A., Rutherford, A., Cebrian, M., &amp;amp; Rahwan, I. (2021). Universal resilience patterns in labor markets. Nature Communications, 12(1), 1972. &lt;a href="https://doi.org/10.1038/s41467-021-22086-3">https://doi.org/10.1038/s41467-021-22086-3&lt;/a>
&lt;br/>&lt;br/>
[Dawson et al, PLOS ONE ‘21] Dawson, N., Williams, M.-A., &amp;amp; Rizoiu, M.-A. (2021). Skill-driven Recommendations for Job Transition Pathways. PLOS ONE. Retrieved from &lt;a href="http://arxiv.org/abs/2011.11801">http://arxiv.org/abs/2011.11801&lt;/a>
&lt;br/>&lt;br/>
[Kern et al, PNAS’19] Kern, M. L., McCarthy, P. X., Chakrabarty, D., &amp;amp; Rizoiu, M.-A. (2019). Social media-predicted personality traits and values can help match people to their ideal jobs. Proceedings of the National Academy of Sciences, 116(52), 26459–26464. &lt;a href="https://doi.org/10.1073/pnas.1917942116">https://doi.org/10.1073/pnas.1917942116&lt;/a>&lt;/p></description></item><item><title>We spent six years scouring billions of links, and found the web is both expanding and shrinking</title><link>https://www.behavioral-ds.science/theme1_content/online_diversity/</link><pubDate>Fri, 02 Jul 2021 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme1_content/online_diversity/</guid><description>&lt;p>The online world is continuously expanding — always aggregating more services, more users and more activity. Last year, the number of websites registered on the &amp;ldquo;.com&amp;rdquo; domain &lt;a href="https://www.verisign.com/en_US/channel-resources/domain-registry-products/zone-file/index.xhtml">surpassed 150,000,000&lt;/a>.&lt;/p>
&lt;p>However, more than a quarter of a century since its first commercial use, the growth of the online world is now slowing down in some key categories.&lt;/p>
&lt;p>We conducted a multi-year research project analysing global trends in online diversity and dominance. &lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0249993">Our research&lt;/a>, published in Public Library of Science, is the first to reveal some long-term trends in how businesses compete in the age of the web.&lt;/p>
&lt;p>We saw a dramatic consolidation of attention towards a shrinking (but increasingly dominant) group of online organisations. So, while there is still growth in the functions, features and applications offered on the web, the number of entities providing these functions is shrinking.&lt;/p>
&lt;h2 id="web-diversity-nosedives">Web diversity nosedives&lt;/h2>
&lt;p>We analysed more than six billion user comments from the social media website Reddit dating back to 2006, as well as 11.8 billion Twitter posts from as far back as 2011. In total, our research used a massive 5.6Tb trove of data from more than a decade of global activity.&lt;/p>
&lt;p>This dataset was more than four times the size of the original data from the Hubble Space Telescope, which helped Brian Schmidt and colleagues do their &lt;a href="https://theconversation.com/nobel-prize-win-tells-us-the-universe-is-accelerating-what-does-that-mean-3753">Nobel-prize winning work&lt;/a> in 1998 to prove &lt;a href="https://iopscience.iop.org/article/10.1086/300499/meta">the universe's expansion is accelerating&lt;/a>.&lt;/p>
&lt;p>With the Reddit posts, we analysed all the links to other sites and online services — more than one billion in total — to understand the dynamics of link growth, dominance and diversity through the decade.&lt;/p>
&lt;p>We used a measure of link &amp;ldquo;uniqueness&amp;rdquo;. On this scale, 1 represents maximum diversity (all links have their own domain) and 0 is minimum diversity (all links are on one domain, such as &amp;ldquo;youtube.com&amp;rdquo;).&lt;/p>
&lt;p>A decade ago, there was a much greater variety of domains within links posted by users of Reddit, with more than 20 different domains for every 100 random links users posted. Now there are only about five different domains for every 100 links posted.&lt;/p>
&lt;p>&lt;img src="featured.png" alt="Our Reddit analysis showed the pool of top-performing sources online is shrinking.">&lt;/p>
&lt;p>In fact, between 60-70% of all attention on key social media platforms is focused towards just ten popular domains.&lt;/p>
&lt;p>Beyond social media platforms, we also studied linkage patterns across the web, looking at almost 20 billion links over three years. These results reinforced the &amp;ldquo;rich are getting richer&amp;rdquo; online.&lt;/p>
&lt;p>The authority, influence and visibility of the top 1,000 global websites (as measured by network centrality or PageRank) is growing every month, at the expense of all other sites.&lt;/p>
&lt;h2 id="app-diversity-is-on-the-rise">App diversity is on the rise&lt;/h2>
&lt;p>The web started as a source of innovation, new ideas and inspiration — a technology that opened up the playing field. It's now also becoming a medium that actually stifles competition and promotes monopolies and the dominance of a few players.&lt;/p>
&lt;p>Our findings resolve a long-running paradox about the nature of the web: does it help grow businesses, jobs and investment? Or does it make it harder to get ahead by letting anyone and everyone join the game? The answer, it turns out, is it does both.&lt;/p>
&lt;p>While the diversity of sources is in decline, there is a countervailing force of continually increasing functionality with new services, products and applications — such as music streaming services (Spotify), file sharing programs (Dropbox) and messaging platforms (Messenger, Whatsapp and Snapchat).&lt;/p>
&lt;p>&lt;img src="fig2.png" alt="Functional diversity grows continuously online.">&lt;/p>
&lt;h2 id="website-infant-mortality">Website ‘infant mortality&amp;rsquo;&lt;/h2>
&lt;p>Another major finding was the dramatic increase in the &amp;ldquo;infant mortality&amp;rdquo; rate of websites — with the big kids on the block guarding their turf more staunchly than ever.&lt;/p>
&lt;p>We examined new domains that were continually referenced or linked-to in social media after their first appearance. We found that while almost 40% of the domains created 2006 were active five years on, only a little more than 3% of those created in 2015 remain active today.&lt;/p>
&lt;p>The dynamics of online competition are becoming clearer and clearer. And the loss of diversity is concerning. Unlike the natural world, there are no sanctuaries; competition is part of both nature and business.&lt;/p>
&lt;p>Our study has profound implications for business leaders, investors and governments everywhere. It shows the network effects of the web don't just apply to online businesses. They have permeated the entire economy and are rewriting many previously accepted rules of economics.&lt;/p>
&lt;p>For example, the idea that businesses can maintain a competitive advantage based on where they are physically located is increasingly tenuous. Meanwhile, there's new opportunities for companies to set up shop from anywhere in the world and serve a global customer base that's both mainstream and niche.&lt;/p>
&lt;p>&lt;img src="fig3.png" alt="Functional diversity grows continuously online.">&lt;/p>
&lt;p>The best way to encourage diversity is to have more global online businesses focused on providing diverse services, by addressing consumers&amp;rsquo; increasingly niche needs.&lt;/p>
&lt;p>In Australia, we're starting to see this through homegrown companies such as &lt;a href="https://www.canva.com/">Canva&lt;/a>, &lt;a href="https://safetyculture.com/">SafetyCulture&lt;/a> and &lt;a href="https://iwonder.com/">iWonder&lt;/a>. Hopefully many more will appear in the decade ahead.&lt;/p>
&lt;p>&lt;em>This article was first published by the authors on &lt;a href="https://theconversation.com/we-spent-six-years-scouring-billions-of-links-and-found-the-web-is-both-expanding-and-shrinking-159215">The Conversation&lt;/a>.&lt;/em>&lt;/p></description></item><item><title>birdspotter: A toolkit for analyzing and labelling Twitter users</title><link>https://www.behavioral-ds.science/theme2_content/birdspotter/</link><pubDate>Tue, 09 Mar 2021 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme2_content/birdspotter/</guid><description>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/52HwHAiK1rs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;!-- &lt;img src="https://www.behavioral-ds.science/img/birdspotter_logo.png" alt="Birdspotter Logo" width="200"/> -->
&lt;!-- Motivation -->
&lt;!-- Framing: Problem -> Solution -->
&lt;!-- Context -->
&lt;p>Social media platforms, although relatively new, host millions of users and billions of interactions daily. As tied as we are to these platforms, they profoundly impact our social institutions through phenomena such as disinformation, political polarization, and social bots.&lt;/p>
&lt;!-- Problem -->
&lt;p>Researchers are increasingly interested in trying to form an understanding of phenomena and their implications. Social scientists, political scientists, and data practitioners alike curate expansive datasets to combat these potentially adverse effects on our society; however, they lack the appropriate tooling.&lt;/p>
&lt;!-- Solution -->
&lt;p>&lt;code>birdspotter&lt;/code> is an &lt;strong>easy-to-use&lt;/strong> tool that models Twitter users&amp;rsquo; attributes and labels them. It comes prepackaged with a &lt;strong>state-of-the-art bot detector&lt;/strong> and an &lt;strong>influence quantification&lt;/strong> system based on tweet dynamics. &lt;code>birdspotter&lt;/code> features a generalized user labeler, which can be retrained easily with the engineered features to address a variety of use cases. Also, &lt;a href="http://birdspotter.ml/">birdspotter.ml&lt;/a> is a web application that can be utilized to explore datasets and derive a narrative around a dataset.&lt;/p>
&lt;p>In this post, I'll showcase the basic usage of &lt;code>birdspotter&lt;/code> and &lt;a href="http://birdspotter.ml/">birdspotter.ml&lt;/a>.&lt;/p>
&lt;h2 id="installation">Installation&lt;/h2>
&lt;p>The package can be installed in the canonical python way:&lt;/p>
&lt;pre>&lt;code class="language-{bash}">pip install birdspotter
&lt;/code>&lt;/pre>
&lt;h2 id="getting-a-dataset">Getting a dataset&lt;/h2>
&lt;p>The Twitter T&amp;amp;Cs restrict the sharing of tweet data directly online; however, they do allow the sharing of tweet-ids, which can be converted to full tweet data through a process called &lt;em>hydration&lt;/em>. Tools like &lt;a href="https://github.com/DocNow/twarc">twarc&lt;/a> can be used to hydrate a Tweet ID dataset. The resulting dataset will be in &lt;code>jsonl&lt;/code> (line delimited &lt;code>json&lt;/code>) format, which &lt;code>birdspotter&lt;/code> accepts directly.&lt;/p>
&lt;p>In the below examples, we use two datasets; a collection of COVID-19 related tweets from January 31st, 2020 [1], and a collection of tweets about politicians on Twitter [2].&lt;/p>
&lt;p>The politicians&amp;rsquo; dataset was acquired through the following process (and a similar process was taken for the COVID-19 dataset):&lt;/p>
&lt;pre>&lt;code class="language-{bash}">pip install twarc
wget http://twitterpoliticians.org./downloads/base/all_tweet_ids.csv
twarc hydrate all_tweet_ids.csv &amp;gt; tweets.jsonl
&lt;/code>&lt;/pre>
&lt;h2 id="basic-usage">Basic Usage&lt;/h2>
&lt;p>The code below imports the main class &lt;code>Birdspotter&lt;/code>, extracts the tweets from their standard format, labels the users with the default bot detector and influence, and reformats the retweet cascades into a tidier format.&lt;/p>
&lt;pre>&lt;code class="language-{python}">## Import birdspotter
from birdspotter import BirdSpotter
## Extracts the tweets from the raw jsonl [https://github.com/echen102/COVID-19-TweetIDs]
bs = BirdSpotter('covid19.jsonl')
## Uses the default bot labeller and influence quantification systems
bs.getLabeledUsers()
## Formats the retweet cascades, such that expected retweet structures can extracted
bs.getCascadesDataFrame()
## Access the botness labels and influence scores
bs.featureDataframe[['botness', 'influence']]
&lt;/code>&lt;/pre>
&lt;p>From here, the dataset is readily profile-able:&lt;/p>
&lt;pre>&lt;code class="language-{python}">botness_dist = sns.histplot(data=bs.featureDataframe, x=&amp;quot;botness&amp;quot;)
influence_eccdf = sns.ecdfplot(data=bs.featureDataframe, x=&amp;quot;influence&amp;quot;, complementary=True).set(xscale=&amp;quot;log&amp;quot;, yscale=&amp;quot;log&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://www.behavioral-ds.science/img/covid_profile.png" alt="COVID Dataset Profile: (Left) The distribution of bot scores of users; (Right) The ECCDF of influence scores of users, showing a long-tailed (rich-gets-richer) paradigm">&lt;/p>
&lt;h2 id="the-visualizer">The visualizer&lt;/h2>
&lt;p>An alternative way to profile a dataset is the use &lt;a href="http://birdspotter.ml">&lt;code>birdspotter.ml&lt;/code>&lt;/a>, which facilitates dataset exploration and narrative construction.&lt;/p>
&lt;p>&lt;img src="https://www.behavioral-ds.science/img/auspol_teaser.png" alt="birdspotter.ml visualizer: The various components shown include the scatterplot panel (Left), the user information panel (Top Right), and the retweet cascades panel (Bottom Right)">&lt;/p>
&lt;p>The visualizer features a scatterplot (on the left) of influence and botness for a sample of users and the population density. The colors represent the hashtags (a proxy for the topic) that the users most tweet about in the dataset. Users within the scatterplot are hoverable and selectable, and their information populates in the components on the right.&lt;/p>
&lt;p>The top right component shows information and metrics about the selected user and links the user's profile.&lt;/p>
&lt;p>The bottom right component shows the retweet cascades where a user has participated and highlights their participation. The points represent the follower counts (social capital) of users and their retweets/tweets&amp;rsquo; timing. The points are also hoverable and selectable.&lt;/p>
&lt;h2 id="customising-the-labeller">Customising the labeller&lt;/h2>
&lt;p>By default, the labeler is trained as a bot detection system, comparable to the state-of-the-art &lt;a href="https://botometer.osome.iu.edu/">&lt;code>botometer&lt;/code>&lt;/a>. Notable, &lt;code>birdspotter&lt;/code> is provided in an offline package and can be applied at scale, while &lt;code>botometer&lt;/code> is accessible only via an online API, which is often prohibitively rate-limited.&lt;/p>
&lt;p>&lt;code>birdspotter&lt;/code> is a versatile tool and can be utilized by practitioners for a variety of use-cases. For example, we could train the labeler to identify political leaning. This process is a bit involved, so we summarise it below;&lt;/p>
&lt;ol>
&lt;li>We hydrate some tweets from the Twitter Parlimentarian Database&lt;/li>
&lt;li>We filter the tweets to include only &lt;strong>Australian Politicians&lt;/strong>.&lt;/li>
&lt;li>We &lt;strong>label right-wing partied politicians positively&lt;/strong>, and others negatively (with &lt;code>bs_pol.getBotAnnotationTemplate&lt;/code> for example)&lt;/li>
&lt;li>We &lt;strong>retrain &lt;code>birdspotter&lt;/code>&lt;/strong> with these new labels and label all users (i.e., including users the politicians retweeted) using the new model&lt;/li>
&lt;/ol>
&lt;!-- ```{python class.source = 'fold-hide'} -->
&lt;!-- # This is the guts of the code; it does what is described above -->
&lt;!-- politicians = pd.read_csv('./full_member_info.csv', encoding='utf16') -->
&lt;!-- politicians_aus = politicians[politicians['country'] == 'Australia'] -->
&lt;!-- politicians_aus_available = politicians_aus[~politicians_aus['uid'].isnull()] -->
&lt;!-- def classify_party(party_id): -->
&lt;!-- mapping = { -->
&lt;!-- 464 : 1, # Liberal Party of Australia -->
&lt;!-- 465 : -1, # Australian Labor Party -->
&lt;!-- 467 : 1, # The Nationals -->
&lt;!-- 468 : 0, # Nick Xenophon Team -->
&lt;!-- 469 : -1, # Australian Greens -->
&lt;!-- 471 : np.nan, -->
&lt;!-- 475 : 1, # Katter's Australian Party -->
&lt;!-- } -->
&lt;!-- return mapping[party_id] -->
&lt;!-- politicians_aus_available['isright'] = politicians_aus_available['party_id'].apply(classify_party) -->
&lt;!-- politicians_aus_available['user_id'] = politicians_aus_available['uid'].astype(int).astype(str) -->
&lt;!-- politicians_aus_available = politicians_aus_available.set_index('user_id') -->
&lt;!-- with open('./tweets.jsonl', 'r') as rf, open('./aus_tweets.jsonl', 'w') as wf: -->
&lt;!-- for line in tqdm(rf): -->
&lt;!-- try: -->
&lt;!-- j = json.loads(line) -->
&lt;!-- if j['user']['id_str'] in politicians_aus_available['uid'].astype(int).astype(str).values: -->
&lt;!-- wf.write(json.dumps(j) + '\n') -->
&lt;!-- except Exception as e: -->
&lt;!-- print(j) -->
&lt;!-- print(e) -->
&lt;!-- break -->
&lt;!-- bs = BirdSpotter('aus_tweets.jsonl') -->
&lt;!-- bs.getLabeledUsers() -->
&lt;!-- bs.getCascadesDataFrame() -->
&lt;!-- with open('bs_aus_module.pk', 'wb') as wf: -->
&lt;!-- pk.dump(bs,wf, protocol=4) -->
&lt;!-- bs.featureDataframe['isright'] = politicians_aus_available['isright'] -->
&lt;!-- ground_truth = bs.featureDataframe[~bs.featureDataframe['isright'].isnull()][['isright']] -->
&lt;!-- ground_truth['isbot'] = ground_truth['isright'] == 1 -->
&lt;!-- ground_truth = ground_truth[~ground_truth.index.duplicated()] -->
&lt;!-- data = bs.featureDataframe.copy()[bs.featureDataframe.index.isin(ground_truth.index)] -->
&lt;!-- data = data[~data.index.duplicated()] -->
&lt;!-- del data['isright'] -->
&lt;!-- del data['botness'] -->
&lt;!-- del data['influence'] -->
&lt;!-- del data['cascade_membership'] -->
&lt;!-- data = data[list(data.columns[data.dtypes != 'object'])] -->
&lt;!-- data['isbot'] = ground_truth['isbot'].loc[data.index] -->
&lt;!-- with open('pol_training_data.pickle', 'wb') as wf: -->
&lt;!-- pk.dump(data,wf, protocol=4) -->
&lt;!-- from birdspotter import BirdSpotter -->
&lt;!-- import pickle as pk -->
&lt;!-- # bs_pol = BirdSpotter('aus_tweets.jsonl') -->
&lt;!-- with open('bs_aus_module.pk', 'rb') as rf: -->
&lt;!-- bs_pol = pk.load(rf) -->
&lt;!-- print("Loaded module") -->
&lt;!-- bs_pol.trainClassifierModel('pol_training_data.pickle') -->
&lt;!-- print("finished training") -->
&lt;!-- del bs_pol.featureDataframe['botness'] -->
&lt;!-- print("removed botness column") -->
&lt;!-- bs_pol.getBotness() -->
&lt;!-- bs_pol.getLabeledUsers() -->
&lt;!-- print("got labels") -->
&lt;!-- with open('pol_booster.pickle', 'wb') as wf: -->
&lt;!-- pk.dump(bs_pol.booster, wf, protocol=4) -->
&lt;!-- print("pickled booster") -->
&lt;!-- with open('aus_pol_bs_module.pickle', 'wb') as wf: -->
&lt;!-- pk.dump(bs_pol, wf, protocol=4) -->
&lt;!-- with open('pol_booster.pickle', 'wb') as wf: -->
&lt;!-- pk.dump(bs.booster, wf, protocol=4) -->
&lt;!-- ``` -->
&lt;!-- This is context: -->
&lt;!-- I want to start with the opportunity namely the analysis of large amounts of population data tranparently showing the interactions and discourse of people, allowing practictioners to model important applications in society. I also want to highlight the research issues which require investigation, namely social bots, misinformation, polarization, etc. -->
&lt;!-- This is content -->
&lt;!-- I then want to move into the problem, namely that there is a lack of tooling to analyse these huge swaths of data -->
&lt;pre>&lt;code class="language-{python}">bs_pol = BirdSpotter('aus_tweets.jsonl')
bs_pol.trainClassifierModel('pol_training_data.pickle')
bs_pol.getLabeledUsers()
&lt;/code>&lt;/pre>
&lt;p>On this limited of Australian politicians dataset, a 10-fold CV of &lt;code>birdspotter&lt;/code> garners an average AUC (Area under ROC) of 0.986.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>&lt;code>birdspotter&lt;/code> aims to democratize social analyzes that were once the domain of machine learning experts, generating insights and understanding of online phenomena and mitigating their potentially adverse effects on our society. This post shows how &lt;code>birdspotter&lt;/code> can be used in both a simple and advanced way to recover such insights.&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;p>[1] Chen, E. et al. 2020. Tracking social media discourse about the covid-19 pandemic: Development of a public coronavirus twitter data set. JMIR Public Health and Surveillance. 6, 2 (2020), e19273.&lt;/p>
&lt;p>[2] Vliet, L. van et al. 2020. The twitter parliamentarian database: Analyzing twitter politics across 26 countries. PloS one. 15, 9 (2020), e0237073.&lt;/p></description></item><item><title>Job Transitions in a Time of Automation and Labour Market Crises</title><link>https://www.behavioral-ds.science/theme3_content/job_transitions/</link><pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme3_content/job_transitions/</guid><description>&lt;p>&lt;strong>Summary:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>We build a machine learning-based &lt;em>Job Transitions Recommender System&lt;/em> that can accurately predict the probability of transitioning between occupations. We showcase the system for workers forced to transition between jobs.&lt;/li>
&lt;li>The system is based on a novel data-driven method to measure the similarity between occupations based on their underlying skill profiles and real-time job ads.&lt;/li>
&lt;li>We also build a leading indicator of Artificial Intelligence adoption in Australian industries, outlining gaps, opportunities, and trends.&lt;/li>
&lt;li>For full technical details, please read the &lt;a href="https://arxiv.org/abs/2011.11801">pre-print&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>People are forced to change jobs as new technologies automate labour, production is moved abroad, and economic crises unfold. Successfully transitioning between jobs, however, requires leveraging current skills and acquiring others, which can falter if the skills gap is too large.&lt;/p>
&lt;p>In our latest research, &lt;a href="authors/nik-dawson/">Nik Dawson&lt;/a> and &lt;a href="authors/ma-rizoiu/">Marian-Andrei Rizoiu&lt;/a> (together with collaborator &lt;a href="https://research.unsw.edu.au/people/professor-mary-anne-williams">Mary-Anne Williams&lt;/a>) and I developed a novel method to measure the &amp;lsquo;distance&amp;rsquo; between &lt;em>sets of skills&lt;/em> using real-time job ads data. We then use these measures to build a recommender system that accurately predicts the probability of transitioning from one occupation to every other possible occupation. Intuitively, two occupations have a high probability of successfully transitioning when their skill sets are highly similar (i.e. the distance is small). For example, an Accountant has a high probability of transitioning to become a Financial Analyst because their skill sets are similar; whereas a Speech Therapist has a low transition probability to becoming a Financial Analyst as their skill sets are very different. This isn't to say that it's not possible. Rather, the skills gap is large, so the probability of successfully transitioning is diminished.&lt;/p>
&lt;h2 id="the-skill-space-method">The SKILL SPACE Method&lt;/h2>
&lt;p>&lt;strong>Distance between skills&lt;/strong>&lt;/p>
&lt;p>In order to measure the distance between occupations from their underlying skill sets, we first measure the distance between individual skills in job ads for each calendar year from 2012-2020. To achieve this bottom-up approach, we first use a method from Trade Economics, called ‘Revealed Comparative Advantage&amp;rsquo; (RCA), to identify how important an individual skill is to a job ad (i.e. comparative advantage). Then, after some normalisation, we calculate the pairwise similarity between every skill for each year. The image below shows the skill distance embeddings for the top 500 skills by posting frequency in 2018.&lt;/p>
&lt;p>&lt;img src="img/fig1A.png" alt="Figure 1A.">&lt;/p>
&lt;p>Here, each marker represents an individual skill that is coloured according to one of 13 clusters of highly similar skills. As seen in the Software Development cluster (see inset), highly similar skills cluster closely together, such as ‘Python&amp;rsquo; and ‘C++&amp;rsquo;. The skills map also provides useful insights, highlighting that specialised skills (such as ‘Software Development&amp;rsquo; and ‘Healthcare&amp;rsquo;) tend to lay toward the edges of the embedding, whereas more general and transferable skills lay toward the middle, acting as a ‘bridge&amp;rsquo; to specialist skills.&lt;/p>
&lt;p>&lt;strong>Distance between occupations&lt;/strong>&lt;/p>
&lt;p>Next, we use the pairwise skill distances to measure the distance between &lt;em>sets of skills&lt;/em>. In this example, we define sets of skills by their occupational groupings. But they can just as easily be defined by other groupings, such as companies, industries, or personalised skill sets. We calculate the distance between skill sets as the weighted average similarity between the individual skills in each set, where the weights correspond to the skill importance in their respective sets. The figure below visualises the distance between Australian occupations in 2018.&lt;/p>
&lt;p>&lt;img src="img/fig1B.png" alt="Figure 1B.">&lt;/p>
&lt;p>Each occupation is represented by a marker and coloured on a scale according to their automation susceptibility, as calculated by &lt;a href="https://www.sciencedirect.com/science/article/abs/pii/S0040162516302244">Frey and Osborne&lt;/a> - dark blue represents low-risk probability and dark red shows high risk probability over the coming two decades. As seen in the magnified inset, similar occupations lie close together on the map. Further, occupations in low risk of automation tend to be characterised by non-routine, interpersonal, and/or high cognitive labour tasks; whereas occupations in high risk of automation tend to require routine, manual, and/or low cognitive labour tasks. For example, in the inset of the Figure above, a ‘Sheetmetal Trades Worker&amp;rsquo; is deemed to be at high risk of labour automation (82% probability) due to high levels of routine and manual labour tasks required by the occupation. However, the skill set demands of a ‘Sheetmetal Trades Worker&amp;rsquo; are highly similar to an ‘Industrial Designer&amp;rsquo;, which is considered at low risk of labour automation over the coming two decades (4% probability). Therefore, an ‘Industrial Designer&amp;rsquo; represents a transition opportunity for a ‘Sheetmetal Trades Worker&amp;rsquo; that leverages existing skills and protects against potential risks of technological labour automation.&lt;/p>
&lt;h2 id="constructing-a-job-transitions-recommender-system">Constructing a Job Transitions Recommender System&lt;/h2>
&lt;p>The SKILL SPACE Method described above achieves high levels of accuracy in predicting job transitions. However, these are symmetric measures and we know that &lt;strong>job transitions are &lt;em>asymmetric&lt;/em>&lt;/strong> - it is more difficult to transition between jobs in one direction than the other. Therefore, transitions are determined by more than the symmetric distance between skill sets; other factors, such as educational requirements and experience demands, contribute to these asymmetries.&lt;/p>
&lt;p>We account for the asymmetries between job transitions by training a machine learning classifier model that combines the SKILL SPACE distance measures with other labour market variables from job ads data and employment statistics (see the &lt;a href="https://arxiv.org/abs/2011.11801">pre-print&lt;/a> for full details). Our machine learning model is trained against a dataset of ‘actual&amp;rsquo; (i.e. real life) job transitions from an Australian longitudinal household survey. We then apply the trained model to predict the probability for every possible occupational transition in the dataset - described as the transition probability between a ‘source&amp;rsquo; and a ‘target&amp;rsquo; occupation. This creates the &lt;em>Transitions Map&lt;/em>, for which a subset of 20 occupations can be seen in the figure below.&lt;/p>
&lt;p>&lt;img src="img/fig2.png" alt="Figure 2.">&lt;/p>
&lt;p>The coloured heatmap shows the transition probabilities (‘source&amp;rsquo; occupations are in columns and ‘targets&amp;rsquo; are in rows). Dark blue represents higher transition probabilities and lighter blue shows lower probabilities, where the asymmetries between occupation pairs are clearly observed. For example, a ‘Finance Manager&amp;rsquo; has a higher probability of transitioning to become an ‘Accounting Clerk&amp;rsquo; than the reverse direction. Moreover, transitioning to some occupations is generally easier (for example, ‘Bar Attendants and Baristas&amp;rsquo;) than others (‘Life Scientists&amp;rsquo;). The dendrogram (the lines on the left and top of the chart) illustrates the hierarchical clusters of occupations where there is a clear divide between service-oriented professions and manual labour occupations.&lt;/p>
&lt;p>Our model achieves high levels of performance, &lt;strong>accurately predicting 76% of occupational transitions&lt;/strong>.&lt;/p>
&lt;h2 id="recommending-jobs-and-skills">Recommending Jobs and Skills&lt;/h2>
&lt;p>The &lt;em>Transitions Map&lt;/em> provides the basis for making qualified job transition recommendations. We call this the &lt;em>Job Transitions Recommender System&lt;/em>. In the figure below, we highlight the example of `Domestic Cleaners&amp;rsquo;, an occupation that has experienced significant declines in labour demand and employment levels during COVID-19 in Australia.&lt;/p>
&lt;p>&lt;img src="img/fig4.png" alt="Figure 4.">&lt;/p>
&lt;p>First, we use the &lt;em>Transitions Map&lt;/em> to recommend the occupations with the highest transition probabilities; these are the named occupations on the right side of the flow diagram, ordered in descending order of transition probability. Segment widths show the labour demand for each of the recommended occupations during the beginning of the COVID-19 period (measured by posting frequency). The segment colours represent the percentage change of posting frequency during March and April 2019 compared to the same months in 2020; dark red indicates a big decrease in job ad posts and dark blue indicates a big increase. The first six transition recommendations for ‘Domestic Cleaners&amp;rsquo; all experienced negative demand, which is unsurprising given that ‘non-essential&amp;rsquo; services were restricted in Australia during this period. However, the seventh recommendation, ‘Aged and Disabled Carers&amp;rsquo;, had significantly grown in demand during the beginning of the COVID-19 period and there was a high number of jobs advertised. Given that it is generally favorable to transition to high demand jobs, we selected ‘Aged and Disabled Carers&amp;rsquo; as the target occupation for this example.&lt;/p>
&lt;p>&lt;strong>Skill recommendations for target occupations&lt;/strong>&lt;/p>
&lt;p>We then take the &lt;em>Job Transitions Recommender System&lt;/em> a step further by incorporating skill recommendations. Transitioning to a new occupation generally requires developing new skills under time and resource constraints. Therefore, workers must prioritise which skills to develop. We argue that a worker should invest in developing a skill when (1) the &lt;strong>skill is important to the target occupation&lt;/strong> &lt;em>and&lt;/em> (2) the &lt;strong>distance to acquire the skill is large&lt;/strong> (that is, it is relatively difficult to acquire). In the case of the ‘Domestic Cleaner&amp;rsquo; in the figure above, the top recommended skills to assist in the transition to the ‘Aged and Disabled Carer&amp;rsquo; occupation are specialised patient care skills, such as ‘Patient Hygiene Assistance&amp;rsquo;. Conversely, the reasons &lt;em>not&lt;/em> to develop a skill are when (1) the &lt;strong>skill is not important&lt;/strong> &lt;em>or&lt;/em> (2) the &lt;strong>distance is small to the target occupation&lt;/strong>. The figure shows that while some ‘Aged and Disabled Carer&amp;rsquo; jobs require ‘Business Analysis&amp;rsquo; and ‘Finance&amp;rsquo; skills, these skills are of low importance for the ‘Aged and Disabled Carer&amp;rsquo; occupation, so they should not be prioritised. Similarly, skills such as ‘Ironing&amp;rsquo; and ‘Laundry&amp;rsquo; are required by ‘Aged and Disabled Carer&amp;rsquo; jobs but the distance is small, so it is likely that either a ‘Domestic Cleaner&amp;rsquo; already possesses these skills or they can easily acquire them.&lt;/p>
&lt;h2 id="developing-a-leading-indicator-of-ai-adoption">Developing a Leading Indicator of AI Adoption&lt;/h2>
&lt;p>The SKILL SPACE method can also be flexibly applied to other adjacent problems, such as identifying the extent of specific skill gaps of firms within industries and potential adoption of new technologies. Here, we develop a leading indicator for emerging technology adoption and potential labour market disruptions based on skills data, using Artificial Intelligence (AI) as an example. We select AI because of its potential impacts on transforming labour tasks and accelerating job transitions. By applying SKILL SPACE, we were able to measure the yearly similarities between an adaptive set of AI skills against each of the 19 Australian industries from 2013-2019 (see the &lt;a href="https://arxiv.org/abs/2011.11801">pre-print&lt;/a> for technical details). As industry skill sets become more similar to AI skills, the skills gap is diminished and firms within industries are more likely to possess the skills to make productive use of AI technologies. The growth of AI skill similarity within industries is shown by the coloured areas of the radar chart below.&lt;/p>
&lt;p>&lt;img src="img/fig5.png" alt="Figure 5.">&lt;/p>
&lt;p>All industries have increased their similarity levels to AI skills. This highlights the growing importance of AI skills across the Australian labour market. However, the rates of similarity are unequally distributed. Some industries, such as ‘Finance and Insurance Services&amp;rsquo; and ‘Information Media and Telecommunications&amp;rsquo; command much higher rates of AI skill similarity. This indicates that not only are firms within these industries increasingly demanding AI skills but also that the AI skills gaps within these industries are much smaller. Therefore, it is likely that firms within these industries are adopting AI and making productive use of these technologies.&lt;/p>
&lt;p>Also noteworthy are the differences in growth rates toward AI skill similarity. As the figure above clearly shows, AI skill similarity has rapidly grown for some industries and more modestly for others. For instance, ‘Retail Trade&amp;rsquo; has experienced the highest levels of growth in similarity to AI skills, increasing by 407% from 2013 to 2019. The majority of this growth has occurred recently, which coincides with the launch of Amazon Australia in 2017. Since then, Amazon has swiftly hired thousands in Australia. This indicator can assist policy-makers and businesses to robustly monitor the growth of AI skills (or other emerging technologies), which acts as a proxy for AI adoption within industries.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>While the future of work remains unclear, change is inevitable. New technologies, economic crises, and other factors will continue to shift labour demands causing workers to move between jobs. If labour transitions occur efficiently, significant productivity and equity benefits arise at all levels of the labour market; if transitions are slow, or fail, significant costs are borne to both the State and the individual. Therefore, it's in the interests of workers, firms, and governments that labour transitions are efficient and effective. The methods and systems we put forward here could significantly improve the achievement of these goals.&lt;/p>
&lt;p>For the full technical details, please read the &lt;a href="https://arxiv.org/abs/2011.11801">pre-print&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Acknowledgements&lt;/strong>&lt;/p>
&lt;p>We thank &lt;a href="https://www.linkedin.com/in/bleditaska?lipi=urn%3Ali%3Apage%3Ad_flagship3_pulse_read%3Bvr7rCfoNTVGsSR9hhmd%2FhQ%3D%3D">Bledi Taska&lt;/a> and &lt;a href="https://ca.linkedin.com/in/dmiskulin">Davor Miskulin&lt;/a> from Burning Glass Technologies for generously providing the job advertisements data for this research and for their valuable feedback. We also thank &lt;a href="https://fr.linkedin.com/in/broecke-stijn-36ba2048">Stijn Broecke&lt;/a> and other colleagues from the OECD for their ongoing input and guidance in the development of this work.&lt;/p></description></item><item><title>User Analysis on reshare cascades about COVID-19</title><link>https://www.behavioral-ds.science/theme2_content/user_analysis/</link><pubDate>Thu, 03 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme2_content/user_analysis/</guid><description>&lt;p>We demonstrate in this blog post a tutorial on applying the tools for analyzing online information diffusions about Twitter users, &lt;a href="https://github.com/behavioral-ds/BirdSpotter">&lt;code>birdspotter&lt;/code>&lt;/a> and &lt;a href="https://github.com/behavioral-ds/evently">&lt;code>evently&lt;/code>&lt;/a>.&lt;/p>
&lt;h2 id="dataset">Dataset&lt;/h2>
&lt;p>In this tutorial, we apply two tools for analyzing Twitter users, on a COVID-19 retweet dataset. The dataset
is curated by Chen, et al. One can obtain a copy of the tweet IDs from
their &lt;a href="https://github.com/echen102/COVID-19-TweetIDs">project&lt;/a>. We
only use the 31st of Janury sample of the whole dataset for
demonstration purpose. The tweets can be recovered by &lt;code>hydration&lt;/code>
from their IDs. We note that some tweets might have been deleted and in
the end we manage to get 69.2% (1,489,877) of the original tweets.&lt;/p>
&lt;h2 id="tools">Tools&lt;/h2>
&lt;p>While &lt;code>BirdSpotter&lt;/code> captures the social influence and botness of Twitter
users, &lt;code>evently&lt;/code> specifically models the temporal dynamics of online
information diffusion. We leverage information provided by the tools to
study the users in the COVID19 dataset.&lt;/p>
&lt;pre>&lt;code class="language-r">library(evently)
library(reticulate)
birdspotter &amp;lt;- import('birdspotter')
&lt;/code>&lt;/pre>
&lt;h2 id="preprocessing-tweets">Preprocessing tweets&lt;/h2>
&lt;p>At this step, we seek to extract diffusion cascades from the &lt;code>COVID-19&lt;/code>
dataset for analyzing user influence and botness. A diffusion cascade
consist of an initial tweet posted by a Twitter user and followed then
by a sereis of retweets. A function provided by &lt;code>evently&lt;/code> allows one to
obtain cascades from JSON formatted raw tweets. On the other hand, we
initialize a &lt;code>BirdSpotter&lt;/code> instance and compute the influence and
botness scores for all users in the
dataset.&lt;/p>
&lt;pre>&lt;code class="language-r">cascades &amp;lt;- parse_raw_tweets_to_cascades('corona_2020_01_31.jsonl', keep_user = T, keep_absolute_time = T)
bs &amp;lt;- birdspotter$BirdSpotter('corona_2020_01_31.jsonl')
labeled_users &amp;lt;- bs$getLabeledUsers()[, c('user_id', 'botness', 'influence')]
&lt;/code>&lt;/pre>
&lt;p>As we cannot publish &lt;code>corona_2020_01_31.jsonl&lt;/code> due to Twitter TOC, we
have stored the results and load them below&lt;/p>
&lt;pre>&lt;code class="language-r">load('corona_2020_01_31.rda')
labeled_users &amp;lt;- read.csv('corona_31_botness_influence.csv', stringsAsFactors = F,
colClasses=c(&amp;quot;character&amp;quot;,rep(&amp;quot;numeric&amp;quot;,3)))
&lt;/code>&lt;/pre>
&lt;p>We note that all user IDs have been encrypted. After obtaining the
results, let’s first conduct some simple measurements on users and
cascades.&lt;/p>
&lt;pre>&lt;code class="language-r">library(ggplot2)
# check the density of these two values
mean_bot &amp;lt;- mean(labeled_users$botness, na.rm = T)
ggplot(labeled_users, aes(botness)) +
stat_density(geom = 'line') +
geom_vline(xintercept = mean_bot, linetype=2, color = 'red') +
geom_text(data=data.frame(), aes(x = mean_bot, y = 2, label= sprintf('mean: %s', round(mean_bot, 2))), color= 'red', angle=90, vjust=-0.11)
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="README_files/figure-gfm/unnamed-chunk-4-1.png" alt="">&lt;!-- -->&lt;/p>
&lt;pre>&lt;code class="language-r">mean_inf &amp;lt;- mean(labeled_users$influence)
ggplot(labeled_users) +
stat_ecdf(aes(influence, 1 - ..y..)) +
scale_x_log10() +
scale_y_log10() +
ylab('CCDF') +
geom_vline(xintercept = mean_inf, linetype=2, color = 'red') +geom_text(data=data.frame(), aes(x = mean_inf, y = 1e-3, label= sprintf('mean: %s', round(mean_inf, 2))), color= 'red', angle=90, vjust=-0.11)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Warning: Transformation introduced infinite values in continuous y-axis
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="README_files/figure-gfm/unnamed-chunk-4-2.png" alt="">&lt;!-- -->&lt;/p>
&lt;pre>&lt;code class="language-r">mean_value &amp;lt;- mean(sapply(cascades, nrow))
ggplot(data.frame(size = sapply(cascades, nrow))) +
stat_ecdf(aes(size, 1 - ..y..)) +
scale_x_log10() + scale_y_log10() +
geom_vline(xintercept = mean_value, linetype=2, color = 'red') +
geom_text(data=data.frame(), aes(x = mean_value, y = 1e-3, label= sprintf('mean: %s', round(mean_value, 2))), color= 'red', angle=90, vjust=-0.11) +
xlab('cascade size') +
ylab('CCDF')
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Warning: Transformation introduced infinite values in continuous y-axis
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="README_files/figure-gfm/unnamed-chunk-4-3.png" alt="">&lt;!-- -->&lt;/p>
&lt;pre>&lt;code class="language-r">mean_value2 &amp;lt;- mean(sapply(cascades, function(c) c$time[nrow(c)]))
ggplot(data.frame(time = sapply(cascades, function(c) c$time[nrow(c)]))) +
stat_ecdf(aes(time, 1 - ..y..)) +
scale_x_continuous(trans = 'log1p', breaks = c(0, 100, 10000, 1000000), labels = c('0', '1e2', '1e4', '1e6')) +
scale_y_log10() +
geom_vline(xintercept = mean_value2, linetype=2, color = 'red') +
geom_text(data=data.frame(), aes(x = mean_value2, y = 1e-3, label= sprintf('mean: %s', round(mean_value2, 2))), color= 'red', angle=90, vjust=-0.11) +
xlab('cascade final event time')+
ylab('CCDF')
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Warning: Transformation introduced infinite values in continuous y-axis
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="README_files/figure-gfm/unnamed-chunk-4-4.png" alt="">&lt;!-- -->&lt;/p>
&lt;pre>&lt;code class="language-r">mean_value &amp;lt;- mean(labeled_users$activity)
ggplot(data.frame(size = labeled_users$activity)) +
stat_ecdf(aes(size, 1 - ..y..)) +
scale_x_log10() +
scale_y_log10() +
geom_vline(xintercept = mean_value, linetype=2, color = 'red') +
geom_text(data=data.frame(), aes(x = mean_value, y = 1e-3, label= sprintf('mean: %s', round(mean_value, 2))), color= 'red', angle=90, vjust=-0.11) + xlab('user activity')+ ylab('CCDF')
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Warning: Transformation introduced infinite values in continuous y-axis
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="README_files/figure-gfm/unnamed-chunk-4-5.png" alt="">&lt;!-- -->&lt;/p>
&lt;h2 id="retrain-the-bot-detector">Retrain the bot detector&lt;/h2>
&lt;p>If one find the botness scores are not accurate, &lt;code>birdspotter&lt;/code> provides
a relabeling tool and a retrain API to learn from the given relabeled
dataset&lt;/p>
&lt;pre>&lt;code class="language-r"># output a file for mannual labeling
bs$getBotAnnotationTemplate('users_to_label.csv')
# Once annotated the botness detector can be trained with
bs$trainClassifierModel('users_to_label.csv')
&lt;/code>&lt;/pre>
&lt;h2 id="fit-user-posted-cacsades-with-evently">Fit user posted cacsades with &lt;code>evently&lt;/code>&lt;/h2>
&lt;p>We model a group of cascades initiated by a particular user jointly and
treat the fitted model as a characterization of the user. In this
example, we select two users for comparison.&lt;/p>
&lt;pre>&lt;code class="language-r">selected_users &amp;lt;- c('369686755237813560', '174266868073402929')
# fit Hawkes process on cascades initiated by the selected users
user_cascades_fitted &amp;lt;- lapply(selected_users, function(user) {
# select cascades that are initiated by the &amp;quot;selected_user&amp;quot;
selected_cascades &amp;lt;- Filter(function(cascade) cascade$user[[1]] == user, cascades)
# obtain the observation times;
# note 1580515200 is 1st Feb when the observation stopped
# as we only observed until the end of 31st Jan
times &amp;lt;- 1580515200 - sapply(selected_cascades, function(cas) cas$absolute_time[1])
# fit a model on the selected cascades;
fit_series(data = selected_cascades, model_type = 'mPL', observation_time = times, cores = 10)
})
user_cascades_SEISMIC_fitted &amp;lt;- lapply(selected_users, function(user) {
selected_cascades &amp;lt;- Filter(function(cascade) cascade$user[[1]] == user, cascades)
times &amp;lt;- 1580515200 - sapply(selected_cascades, function(cas) cas$absolute_time[1])
fit_series(data = selected_cascades, model_type = 'SEISMIC',
observation_time = times)
})
# check the fitted kernel functions
plot_kernel_function(user_cascades_fitted) +
scale_color_discrete(labels = c(&amp;quot;@BobOngHugots&amp;quot;, &amp;quot;@Jaefans_Global&amp;quot;))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="README_files/figure-gfm/unnamed-chunk-6-1.png" alt="">&lt;!-- -->&lt;/p>
&lt;p>The plot shows the fitted kernel functions of these two users which
reflect their time-decaying influence of attracting followers to reshare
their posts. We then demonstrate how to simulate new cascades&lt;/p>
&lt;pre>&lt;code class="language-r">set.seed(134841)
user_magnitude &amp;lt;- Filter(function(cascade) cascade$user[[1]] == selected_users[[1]], cascades)[[1]]$magnitude[1]
# simulate a new cascade from @BobOngHugots
sim_cascade &amp;lt;- generate_series(user_cascades_fitted[[1]], M = user_magnitude)
plot_event_series(cascade = sim_cascade, model = user_cascades_fitted[[1]])
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="README_files/figure-gfm/unnamed-chunk-7-1.png" alt="">&lt;!-- -->&lt;/p>
&lt;pre>&lt;code class="language-r">selected_cascade &amp;lt;- Filter(function(cascade) cascade$user[1] == selected_users[[1]], cascades)[[1]]
selected_time &amp;lt;- user_cascades_fitted[[1]]$observation_time[1]
# simulate a cascade with a &amp;quot;selected_cascade&amp;quot; from @BobOngHugots
sim_cascade &amp;lt;- generate_series(user_cascades_fitted[[1]], M = user_magnitude,
init_history = selected_cascade)
sprintf('%s new events simulated after cascade',
nrow(sim_cascade[[1]]) - nrow(selected_cascade))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] &amp;quot;25 new events simulated after cascade&amp;quot;
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">predict_final_popularity(user_cascades_fitted[[1]],
selected_cascade, selected_time)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 458.303
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># predict with SEISMIC model, assume we have fitted the SEISMIC model
predict_final_popularity(user_cascades_SEISMIC_fitted[[1]],
selected_cascade, selected_time)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 729.923
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">get_branching_factor(user_cascades_fitted[[1]])
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 0.7681281
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">get_viral_score(user_cascades_fitted[[1]])
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 7.407763
&lt;/code>&lt;/pre>
&lt;h2 id="visualize-users-in-a-latent-space">Visualize users in a latent space&lt;/h2>
&lt;p>We show a visualization of top 300 users posted most tweets using the
features returned by &lt;code>evently&lt;/code> along with the botness and influence
scores from &lt;code>birdspotter&lt;/code>.&lt;/p>
&lt;pre>&lt;code class="language-r"># obtain observation times here again
times &amp;lt;- 1580515200 - sapply(cascades, function(cas) cas$absolute_time[1])
# indicate the grouping of each cascade with the user who started the cascade
names(cascades) &amp;lt;- sapply(cascades, function(cas) cas$user[1])
# fit Hawkes processes on all cascades first
fitted_corona &amp;lt;- group_fit_series(cascades, model_type = 'mPL', observation_time = times)
&lt;/code>&lt;/pre>
&lt;p>The fitting procedure takes quite long so we again load the pre-fitted
models here&lt;/p>
&lt;pre>&lt;code class="language-r">load('fitted_models.rda')
# choose the top 300 users who started most cacsades
selected_users &amp;lt;- labeled_users$user_id[labeled_users$user_id %in%
names(sort(sapply(fitted_corona, length), decreasing = T)[seq(300)])]
# gather the stats for these users
user_influences &amp;lt;- labeled_users$influence[labeled_users$user_id %in% selected_users]
user_botness &amp;lt;- labeled_users$botness[labeled_users$user_id %in% selected_users]
fitted_corona_selected &amp;lt;- fitted_corona[selected_users]
# get the features
features &amp;lt;- generate_features(fitted_corona_selected)
# compute distances between users using manhattan distance
features &amp;lt;- features[, -1] # remove the user id column
distances &amp;lt;- dist(features, method = 'manhattan')
library(tsne)
positions &amp;lt;- tsne(distances, k = 2)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## sigma summary: Min. : 0.34223375605395 |1st Qu. : 0.457223801885988 |Median : 0.489891425900637 |Mean : 0.500483006369232 |3rd Qu. : 0.538593613780411 |Max. : 0.676779919259545 |
## Epoch: Iteration #100 error is: 14.1961110881254
## Epoch: Iteration #200 error is: 0.490122133064818
## Epoch: Iteration #300 error is: 0.474257867010761
## Epoch: Iteration #400 error is: 0.472067779170087
## Epoch: Iteration #500 error is: 0.471844181155159
## Epoch: Iteration #600 error is: 0.471798834134577
## Epoch: Iteration #700 error is: 0.471783207059971
## Epoch: Iteration #800 error is: 0.471632929621924
## Epoch: Iteration #900 error is: 0.47087861882558
## Epoch: Iteration #1000 error is: 0.470873765976829
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">df &amp;lt;- data.frame(x = positions[,1], y = positions[,2],
influence = user_influences, botness = user_botness)
df &amp;lt;- cbind(df, data.frame(botornot = ifelse(df$botness &amp;gt; 0.6, 'Bot', 'Not Bot')))
ggplot(df, aes(x, y, color = influence, shape = botornot, size = botornot)) +
geom_point() +
scale_shape_manual(values = c(15,1)) +
scale_size_manual(values = c(1.5, 1.2)) +
scale_color_gradient(low = '#56B1F7', high = '#132B43', trans = 'log10') +
theme_void() + labs(size = NULL, shape = NULL) +
theme(legend.direction = 'horizontal', legend.position = c(0.8, 0.2),
legend.key.size = unit(.3, 'cm'), legend.text = element_text(size = 6),
legend.title = element_text(size = 6), legend.spacing = unit(.05, 'cm'))
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="README_files/figure-gfm/unnamed-chunk-10-1.png" alt="">&lt;!-- -->&lt;/p></description></item><item><title>Causal Inference: A basic taster</title><link>https://www.behavioral-ds.science/theme1_content/causal_inference_taster/</link><pubDate>Thu, 12 Nov 2020 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme1_content/causal_inference_taster/</guid><description>
&lt;script src="index_files/header-attrs/header-attrs.js">&lt;/script>
&lt;link href="index_files/anchor-sections/anchor-sections.css" rel="stylesheet" />
&lt;script src="index_files/anchor-sections/anchor-sections.js">&lt;/script>
&lt;link rel="stylesheet" href="tufte.css" type="text/css" />
&lt;p>Most statistics students will be familiar with the phrase “correlation isn’t causation,” however, this doesn’t feature strongly in the remainder of their educations. To overcome this hurdle, the researchers’ best practice in experimental design is the randomized controlled trial. However, there are only specific experiments that we can perform. For example, to test the whether smoking causes cancer, we can’t force subjects to smoke. &lt;label for="tufte-mn-" class="margin-toggle">⊕&lt;/label>&lt;input type="checkbox" id="tufte-mn-" class="margin-toggle">&lt;span class="marginnote">In the 1950s the tobacco companies argued that there could be some confounding factor (a gene) which smokers and lung cancer patients shared.&lt;/span> In general, restricting ourselves to experimental studies to determine causation is incredibly limiting (especially for data scientists). We want to make the same causal conclusions from observational studies and those from experimental studies. We can do that by studying causal inference.&lt;/p>
&lt;div id="simpsons" class="section level2">
&lt;h2>Simpson’s Paradox&lt;/h2>
An example of the importance of understanding causal relationships is given by Simpson’s Paradox &lt;span class="citation">(&lt;a href="#ref-simpson1951interpretation" role="doc-biblioref">Simpson 1951&lt;/a>)&lt;/span>, which describes a peculiar phenomenon that can present in data sets, where a correlation between two variables is present in one direction but reverses in each stratum of the data. The paradox expressed best through an example:
&lt;label for="tufte-mn-" class="margin-toggle">⊕&lt;/label>&lt;input type="checkbox" id="tufte-mn-" class="margin-toggle">&lt;span class="marginnote">This appears to suggest that the more someone exercises, the higher their cholesterol is! This is absurd!&lt;/span>
&lt;div class="figure">&lt;span id="fig:simpsons-before">&lt;/span>
&lt;img src="./index_files/figure-html/simpsons-before-1.png" alt="The results of an experiment, where x-axis represents how much exercise an individual does in hours, and y-axis represents cholestral measurment for the same individual." width="672" />
&lt;p class="caption">
Figure 1: The results of an experiment, where x-axis represents how much exercise an individual does in hours, and y-axis represents cholestral measurment for the same individual.
&lt;/p>
&lt;/div>
Figure &lt;a href="#fig:simpsons-before">1&lt;/a> shows a positive correlation in an experiment that measures individuals’ exercise per week and cholesterol. At first glance, this seems absurd, but when we partition the data by another causal variable, this seems reasonable:
&lt;div class="figure">&lt;span id="fig:simpsons-after">&lt;/span>
&lt;img src="index_files/figure-html/simpsons-after-1.png" alt="The same results as the experiment above, partioned by age" width="672" />
&lt;p class="caption">
Figure 2: The same results as the experiment above, partioned by age
&lt;/p>
&lt;/div>
&lt;p>&lt;label for="tufte-mn-" class="margin-toggle">⊕&lt;/label>&lt;input type="checkbox" id="tufte-mn-" class="margin-toggle">&lt;span class="marginnote">(Also note, we have fabricated the data, although these relationships are quite plausible)&lt;/span>
Understanding the full causal story is essential. Without an entire causal narrative, we might recommend inappropriate interventions; for example, a doctor might prescribe less exercise to reduce cholesterol in the case above.&lt;/p>
&lt;p>To deduce such causal stories, we need to apply the methodology of causal inference.&lt;/p>
&lt;/div>
&lt;div id="structural-equation-models-and-causal-graphs" class="section level2">
&lt;h2>Structural Equation Models and Causal Graphs&lt;/h2>
&lt;p>A structural equation model (SEM) is a set of equations representing the relationship between variables. For example, the equations which generated the data from &lt;a href="#simpsons">the Simpson’s paradox example&lt;/a>, are given as:
&lt;span class="math display">\[
\begin{align*}
age &amp;amp;= U_1 \\
exercise &amp;amp;= \frac{1}{13}*age + U_2 \\
cholesteral &amp;amp;= -4*exercise + age + U_3
\end{align*}
\]&lt;/span>
We can think of &lt;span class="math inline">\(U_1\)&lt;/span>, &lt;span class="math inline">\(U_2\)&lt;/span>, and &lt;span class="math inline">\(U_3\)&lt;/span> as specific unobserved exogenous variables of an individual, which generate their endogenous variables (something like error terms).&lt;/p>
&lt;p>A causal graph is a DAG which describes the existence of relationships between variables in a model. An edge &lt;code>x -&amp;gt; y&lt;/code> represents the relationship &lt;code>x&lt;/code> directly causes &lt;code>y&lt;/code>. Consequently, causal graphs can represent SEMs:
&lt;img src="index_files/figure-html/unnamed-chunk-1-1.png" width="672" />&lt;/p>
&lt;p>Indeed this graph shows how age confounds the effect of exercise on cholesterol.&lt;/p>
&lt;/div>
&lt;div id="do-calculus" class="section level2">
&lt;h2>Do-calculus&lt;/h2>
&lt;p>&lt;span class="citation">&lt;a href="#ref-pearl1995causal" role="doc-biblioref">Pearl&lt;/a> (&lt;a href="#ref-pearl1995causal" role="doc-biblioref">1995&lt;/a>)&lt;/span> outline a method to remove this confounding (and other similar scenarios) using do-calculus. Outlining the specifics of do-calculus is beyond the scope of this blog post (but for interested readers, we suggest &lt;span class="citation">(&lt;a href="#ref-pearl2016causal" role="doc-biblioref">Pearl, Glymour, and Jewell 2016&lt;/a>)&lt;/span>). In brief, do-calculus introduces the &lt;span class="math inline">\(do()\)&lt;/span> operator, which acts as an intervention and fixes a variable to a particular constant. For example, consider a similar binary situation to &lt;a href="#simpsons">the Simpson’s paradox example&lt;/a>, where &lt;em>exer&lt;/em> is a binary variable true if the individual is active, &lt;em>chol&lt;/em> is a binary variable true if the individual has high cholesterol, and &lt;em>age&lt;/em> is a binary variable true if the individual is over 60.&lt;/p>
&lt;pre class="r">&lt;code>bin_simpsons_data &amp;lt;- simpsons_data %&amp;gt;%
mutate(age = age &amp;gt; 60) %&amp;gt;% # Binarize the age, so those over 60 are True, and under 60 are False
mutate(exer = exercise&amp;gt;mean(exercise)) %&amp;gt;% # Binarize the exercise level, so those above the average are True, and under are False
mutate(chol = cholesteral&amp;gt;mean(cholesteral)) # Binarize the cholesteral level, so those above the average are True, and under are False&lt;/code>&lt;/pre>
&lt;p>We ask the same experimental question; does exercise reduce cholesterol. A naive approach would be to compute the effect as &lt;span class="math inline">\(P(chol | exer = 1) - P(chol | exer = 0)=\)&lt;/span> 0.168, where &lt;span class="math inline">\(P(chol | exer)\)&lt;/span> is computed by filtering the data according to &lt;em>exer&lt;/em>. Taking this approach, we would erroneously observe that the effect was positive since those who exercise more are also old and more likely to have high cholesterol.&lt;/p>
&lt;p>The experimental best practice approach would be to perform a randomized controlled trial (RCT). A random selection of individuals are assigned to &lt;em>do&lt;/em> a high exercise regiment and the others &lt;em>do&lt;/em> a low exercise regiment (regardless of age). The RCT implicitly removes the natural tendency of exercise to vary with age and allows researchers to observe the causal effect of exercise on cholesterol. When using data generated in such a fashion, increases/decreases in the probability of having high cholesterol caused by exercise are given by &lt;span class="math inline">\(P_{RCT}(chol | exer = 1) - P_{RCT}(chol | exer = 0)\)&lt;/span>. This metric is known as the Average Causal Effect (ACE), sometimes called the Average Treatment Effect. Note that by conditioning on &lt;span class="math inline">\(exer=x\)&lt;/span>, with data generated by an RCT, researchers are essentially limiting the data used to estimate &lt;span class="math inline">\(P_{RCT}(chol | exer = x)\)&lt;/span>, to individuals who were &lt;strong>forced&lt;/strong> to &lt;em>do&lt;/em> an exercise regiment &lt;span class="math inline">\(x\)&lt;/span>. The &lt;em>do&lt;/em> here represents forcing individuals to take an intervention value, regardless of their natural tendency, and this is captured by the &lt;span class="math inline">\(do()\)&lt;/span> operator. In this case, &lt;span class="math inline">\(P(chol | do(exer = x)) = P_{RCT}(chol | exer = x)\)&lt;/span>, since the data was generated with an RCT. However, RCTs can be prohibitively expensive (both in time and money) and might not be necessary to tease out a causal effect.&lt;/p>
&lt;p>We would still like to estimate the ACE, &lt;span class="math inline">\(P(chol | do(exer = 1)) - P(chol | do(exer = 0))\)&lt;/span>, by using data that wasn’t generated from an RCT. By using the &lt;span class="math inline">\(do()\)&lt;/span> operator here, we aim to disassociate &lt;em>exer&lt;/em> from its natural tendency with &lt;em>age&lt;/em> and effectively perform a graph surgery:&lt;/p>
&lt;p>&lt;img src="index_files/figure-html/unnamed-chunk-4-1.png" width="672" />&lt;/p>
&lt;p>&lt;span class="citation">&lt;a href="#ref-pearl2016causal" role="doc-biblioref">Pearl, Glymour, and Jewell&lt;/a> (&lt;a href="#ref-pearl2016causal" role="doc-biblioref">2016&lt;/a>)&lt;/span> provide an adjustment formula for just this scenario:
&lt;span class="math display">\[
P(y|do(x)) = \sum_z \frac{P(X=x, Y=y, PA=z)}{P(X=x| PA=z)}
\]&lt;/span>
where &lt;span class="math inline">\(X\)&lt;/span> represents the variable we are acting on, &lt;span class="math inline">\(Y\)&lt;/span> the variable we measure results from, and &lt;span class="math inline">\(PA\)&lt;/span> the parents of &lt;span class="math inline">\(X\)&lt;/span> and &lt;span class="math inline">\(Y\)&lt;/span> or more generally any nodes that satisfy the back-door criterion (which we will introduce later). Note this allows us to derive the causal effect, as if we had generated data with an RCT, using only probabilities estimated from data not generated by an RCT.&lt;/p>
&lt;p>As such we compute our ACE for the binary scenario:&lt;/p>
&lt;pre class="r">&lt;code># The Joint Distribution P(age, exer, chol) i.e. P(x,y,z)
p_aec &amp;lt;- bin_simpsons_data %&amp;gt;%
count(age, exer, chol) %&amp;gt;%
mutate(freq = n/sum(n))
# The Marginal Distribution P(age) i.e. P(z)
p_a &amp;lt;- bin_simpsons_data %&amp;gt;%
count(age) %&amp;gt;%
mutate(freq = n/sum(n))
# The Marginal Distribution P(age, exer) i.e. P(x, z)
p_ea &amp;lt;- bin_simpsons_data %&amp;gt;%
count(age, exer) %&amp;gt;%
mutate(freq = n/sum(n))
# The Conditional Mariginal Distribution P(exer | age) i.e. P(x | z)
p_e_a &amp;lt;- p_a %&amp;gt;%
right_join(p_ea, by=&amp;quot;age&amp;quot;) %&amp;gt;%
mutate(freq = freq.y/freq.x) %&amp;gt;%
select(age, exer, freq)
# The Intervention Distribution P(chol | do(exer)) i.e. P(y | do(x))
probabilities &amp;lt;- data.table(p_aec %&amp;gt;%
left_join(p_e_a, by=c(&amp;quot;age&amp;quot;, &amp;quot;exer&amp;quot;)) %&amp;gt;%
mutate(freq = freq.x/freq.y) %&amp;gt;%
select(age, exer, chol, freq) %&amp;gt;%
filter(chol) # We are only concerned with what cause high cholestral
)
# The average causal effect of exer on chol
ACE &amp;lt;- sum(probabilities[exer==T, freq]) - sum(probabilities[exer==F, freq]) &lt;/code>&lt;/pre>
&lt;p>This procedure leads to a negative ACE of -0.175, which shows the causal effect of going from high to low exercise on the probability of getting high cholesterol.&lt;/p>
&lt;p>A natural question that follows from this example is, under what conditions can we use such adjustments to achieve an identifiable causal effect.&lt;/p>
&lt;/div>
&lt;div id="d-seperation" class="section level2">
&lt;h2>d-seperation&lt;/h2>
&lt;p>To understand common scenarios where the effect of variable &lt;span class="math inline">\(X\)&lt;/span> on &lt;span class="math inline">\(Y\)&lt;/span> is identifiable within a causal graph, we must first introduce the concept of d-separation, also known as blocking. A pair of variable &lt;span class="math inline">\(X\)&lt;/span> and &lt;span class="math inline">\(Y\)&lt;/span> are said to be blocked if they are conditionally independent, given a set of nodes &lt;span class="math inline">\(Z\)&lt;/span>. There are three graph types, which are essential for blocking:&lt;/p>
&lt;p>&lt;img src="index_files/figure-html/unnamed-chunk-7-1.png" width="672" />&lt;/p>
&lt;p>In the chain scenario, &lt;span class="math inline">\(X \sim Y\)&lt;/span> is blocked by conditioning on &lt;span class="math inline">\(Z={M}\)&lt;/span>. This is sometimes refered to as the mediation scenario, which we will address further in &lt;a href="#front-door">the front-door criterion&lt;/a>.&lt;/p>
&lt;p>&lt;img src="index_files/figure-html/unnamed-chunk-8-1.png" width="672" />&lt;/p>
&lt;p>In the fork scenario, &lt;span class="math inline">\(X \sim Y\)&lt;/span> is blocked by conditioning on &lt;span class="math inline">\(Z={Z}\)&lt;/span>. This is sometimes refered to as the confounder scenario, which is the situation in &lt;a href="#simpsons">the simpson’s paradox example&lt;/a>.&lt;/p>
&lt;p>&lt;img src="index_files/figure-html/unnamed-chunk-9-1.png" width="672" />&lt;/p>
&lt;p>Finally, in the collider scenario, &lt;span class="math inline">\(X \sim Y\)&lt;/span> is blocked by &lt;em>not&lt;/em> conditioning on &lt;span class="math inline">\(Z={M}\)&lt;/span>. The idea that &lt;span class="math inline">\(X\)&lt;/span> and &lt;span class="math inline">\(Y\)&lt;/span>, which are independent, to begin with, can become conditionally dependant is unintuitive. One way to think about this is that we are sharing information received from $ Y $ with $ X $ through $ M $ when we condition on $ M $. For a more thorough investigation into this phenomenon, refer to &lt;span class="citation">(&lt;a href="#ref-pearl2016causal" role="doc-biblioref">Pearl, Glymour, and Jewell 2016&lt;/a>)&lt;/span>.&lt;/p>
&lt;p>A path is said to be blocked by &lt;span class="math inline">\(Z\)&lt;/span> if it contains a chain or fork with its middle node in &lt;span class="math inline">\(Z\)&lt;/span> or a collider with its middle node not in &lt;span class="math inline">\(Z\)&lt;/span>.&lt;/p>
&lt;p>We are now ready to introduce the main criteria for which we can perform adjustments.&lt;/p>
&lt;/div>
&lt;div id="the-backdoor" class="section level2">
&lt;h2>The Backdoor&lt;/h2>
&lt;div class="definition">
&lt;span id="def:unnamed-chunk-10" class="definition">&lt;strong>Definition 1 (The Backdoor Criterion) &lt;/strong>&lt;/span>A set of nodes &lt;span class="math inline">\(Z\)&lt;/span>, given a DAG &lt;span class="math inline">\(G\)&lt;/span> and a pair of nodes &lt;span class="math inline">\((X,Y)\)&lt;/span>, is said to satisfy the backdoor criterion if no node in &lt;span class="math inline">\(Z\)&lt;/span> is a descendant of &lt;span class="math inline">\(X\)&lt;/span>, and &lt;span class="math inline">\(Z\)&lt;/span> blocks all paths between &lt;span class="math inline">\(X\)&lt;/span> and &lt;span class="math inline">\(Y\)&lt;/span>, which contain arrows into &lt;span class="math inline">\(X\)&lt;/span>.
&lt;/div>
&lt;p>If there exists are set of nodes why satisfy the backdoor criterion, then the effect of &lt;span class="math inline">\(X\)&lt;/span> on &lt;span class="math inline">\(Y\)&lt;/span> is identifiable and given by:
&lt;span class="math display">\[
P(y|do(x)) = \sum_z \frac{P(X=x, Y=y, Z=z)}{P(X=x| Z=z)}
\]&lt;/span>&lt;/p>
&lt;p>The backdoor criterion stops undue influence through the &lt;em>backdoor&lt;/em> paths; it leaves direct paths between &lt;span class="math inline">\(X\)&lt;/span> and &lt;span class="math inline">\(Y\)&lt;/span>, and it blocks spurious paths.&lt;/p>
&lt;p>It is clear that { &lt;em>age&lt;/em> } satisfies these conditions to be a backdoor adjustment set in the example above.&lt;/p>
&lt;p>&lt;img src="index_files/figure-html/unnamed-chunk-11-1.png" width="672" />&lt;/p>
&lt;/div>
&lt;div id="front-door" class="section level2">
&lt;h2>The Front-door&lt;/h2>
&lt;p>There are notably common scenarios where this doesn’t work. For example, consider a constructed causal mediation situation, as follows:
&lt;img src="index_files/figure-html/unnamed-chunk-12-1.png" width="672" />&lt;/p>
&lt;p>In this case we cannot use the backdoor criterion, to detect the effect of &lt;em>smoking&lt;/em> on &lt;em>cancer&lt;/em> because &lt;em>tar&lt;/em> is a descendant of &lt;em>smoking&lt;/em>, and there exists no direct link between &lt;em>smoking&lt;/em> and &lt;em>cancer&lt;/em>. We must use instead the frontdoor criterion:&lt;/p>
&lt;div class="definition">
&lt;span id="def:unnamed-chunk-13" class="definition">&lt;strong>Definition 2 (The Frontdoor Criterion) &lt;/strong>&lt;/span>A set of nodes &lt;span class="math inline">\(Z\)&lt;/span>, given a DAG &lt;span class="math inline">\(G\)&lt;/span> and a pair of nodes &lt;span class="math inline">\((X,Y)\)&lt;/span>, is said to satisfy the frontdoor criterion if; &lt;span class="math inline">\(Z\)&lt;/span> intercepts all direct paths from &lt;span class="math inline">\(X\)&lt;/span> to &lt;span class="math inline">\(Y\)&lt;/span>, all paths between &lt;span class="math inline">\(X\)&lt;/span> and &lt;span class="math inline">\(Z\)&lt;/span> are blocked, and all backdoor paths between &lt;span class="math inline">\(Y\)&lt;/span> and &lt;span class="math inline">\(Z\)&lt;/span> are blocked by &lt;span class="math inline">\(X\)&lt;/span>.
&lt;/div>
&lt;p>If there exists are set of nodes &lt;span class="math inline">\(Z\)&lt;/span> which satisfy the frontdoor criterion, and &lt;span class="math inline">\(P(x, z)&amp;gt;0\)&lt;/span>, then the effect of &lt;span class="math inline">\(X\)&lt;/span> on &lt;span class="math inline">\(Y\)&lt;/span> is identifiable and given by:
&lt;span class="math display">\[
P(y|do(x)) = \sum_z P(z|x) \sum_{x^\prime} P(y|x^\prime, z)P(x^\prime)
\]&lt;/span>
In our smoking scenario, we see that by adjusting for &lt;em>tar&lt;/em> , we can observe the effect of &lt;em>smoking&lt;/em> on &lt;em>cancer&lt;/em>.&lt;/p>
&lt;/div>
&lt;div id="conclusion" class="section level2">
&lt;h2>Conclusion&lt;/h2>
&lt;p>The above briefly outlines a core motivation for studying causal inference and causal stories. We summarise some of the underlying theory of causal inference and show practical methodology through the &lt;em>frontdoor&lt;/em> and &lt;em>backdoor&lt;/em> criterion for determining causal effects through entirely observational studies.&lt;/p>
&lt;p>There are notable aspects of causal inference we have omitted from this taster. The most gaping is the lack of an explanation for the powerful tool of counterfactuals. We have only presented binary examples here (aside from our motivating example); however, perhaps the most common and useful causal inference application is to continuous examples using regression with linear models. Ultimately, we decided this was beyond causal inference taster’s scope and were more deserving of their own articles. Again, for the interested reader, we recommend &lt;span class="citation">&lt;a href="#ref-pearl2016causal" role="doc-biblioref">Pearl, Glymour, and Jewell&lt;/a> (&lt;a href="#ref-pearl2016causal" role="doc-biblioref">2016&lt;/a>)&lt;/span>, which adds links to many other resources.&lt;/p>
&lt;div id="refs" class="references csl-bib-body hanging-indent">
&lt;div id="ref-pearl1995causal" class="csl-entry">
Pearl, Judea. 1995. &lt;span>“Causal Diagrams for Empirical Research.”&lt;/span> &lt;em>Biometrika&lt;/em> 82 (4): 669–88.
&lt;/div>
&lt;div id="ref-pearl2016causal" class="csl-entry">
Pearl, Judea, Madelyn Glymour, and Nicholas P Jewell. 2016. &lt;em>Causal Inference in Statistics: A Primer&lt;/em>. John Wiley &amp;amp; Sons.
&lt;/div>
&lt;div id="ref-simpson1951interpretation" class="csl-entry">
Simpson, Edward H. 1951. &lt;span>“The Interpretation of Interaction in Contingency Tables.”&lt;/span> &lt;em>Journal of the Royal Statistical Society: Series B (Methodological)&lt;/em> 13 (2): 238–41.
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Epidemic Hawkes: an example project</title><link>https://www.behavioral-ds.science/researchproject/project1/</link><pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/researchproject/project1/</guid><description>&lt;p>This is an example project description&lt;/p></description></item><item><title>evently: simulation, fitting of Hawkes processes</title><link>https://www.behavioral-ds.science/softwaretool/evently/</link><pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/softwaretool/evently/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>This package is designed for simulating and fitting the Hawkes processes
and the HawkesN processes with several options of kernel functions.
Currently, it assumes univariate processes without background event
rates. Prior knowledge about the models is assumed in the following
tutorial and please refer to [1] and [2] for details about the
models.&lt;/p>
&lt;pre>&lt;code class="language-r">library(evently)
&lt;/code>&lt;/pre>
&lt;h2 id="installation-and-dependencies">Installation and dependencies&lt;/h2>
&lt;p>Several dependencies
(&lt;a href="https://cran.r-project.org/web/packages/poweRlaw/poweRlaw.pdf">poweRlaw&lt;/a>,
&lt;a href="https://ampl.com/">AMPL&lt;/a>,
&lt;a href="https://www.coin-or.org/Ipopt/documentation/">Ipopt&lt;/a>) are required for
running this package. These dependencies will be installed automatically
by R or by following instructions upon package load.&lt;/p>
&lt;p>Install the package by executing&lt;/p>
&lt;pre>&lt;code class="language-r">if (!require('devtools')) install.packages('devtools')
devtools::install_github('behavioral-ds/evently')
&lt;/code>&lt;/pre>
&lt;h2 id="simulating-cascades">Simulating cascades&lt;/h2>
&lt;p>Let’s first simulate 100 event cascades of the &lt;strong>Hawkes process with an
exponential kernel function&lt;/strong> (please refer to the &lt;a href="#available-models">Available
models&lt;/a> for models and their abbreviations in the
package) with a given parameter set, &lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%20%3D%200.9%2C%20%5Ctheta%20%3D%201" alt="\\kappa = 0.9, \\theta= 1" title="\kappa = 0.9, \theta = 1">. For each simulation, we only simulate
until 5 seconds. The resulted cascades are placed in a single &lt;code>list&lt;/code>
where each cascade is a &lt;code>data.frame&lt;/code>.&lt;/p>
&lt;pre>&lt;code class="language-r">set.seed(4)
sim_no &amp;lt;- 100
data &amp;lt;- generate_hawkes_event_series(par = c(K = 0.9, theta = 1), model_type = 'EXP', Tmax = 5, sim_no = sim_no)
# alternatively, `generate_hawkes_event_series` also accepts a model class object
# e.g.
# model &amp;lt;- new_hawkes_model(par = c(K = 0.9, theta = 1), model_type = 'EXP')
# generate_hawkes_event_series(model = model, Tmax = 5, sim_no = sim_no)
head(data[[1]])
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## magnitude time
## 1 1 0.0000000
## 2 1 0.5941959
## 3 1 1.4712411
## 4 1 1.6105430
## 5 1 1.7855535
## 6 1 1.8883869
&lt;/code>&lt;/pre>
&lt;p>A simulated process is represented by a &lt;code>data.frame&lt;/code> where each row is
an event. &lt;code>time&lt;/code> indicates the event happening time, while &lt;code>magnitude&lt;/code>
is the event mark information which is always 1 if &lt;code>model_type&lt;/code> is an
unmarked model. In the context of retweet diffusion cascades, the first
row is the original tweet and all following events are its retweets.
&lt;code>time&lt;/code> records the relative time (in second) of each retweet to the
original tweet and &lt;code>magnitude&lt;/code> is the follows’ count of the user who
retweeted.&lt;/p>
&lt;h2 id="fitting-a-model-on-data">Fitting a model on data&lt;/h2>
&lt;p>We can then fit on the cascades simulated in the previous section. After
providing the &lt;code>data&lt;/code> and &lt;code>model_type&lt;/code>, the fitting procedure will spawn
10 AMPL optimization procedures with different parameter
inistializations due to the non-convexity of some likelihood functions.
Among the 10 fitted model, the one giving the best likelihood value will
be returned. To make the fitting procedure faster, we can specify the
number of &lt;code>cores&lt;/code> to be used for fitting them in
parallel.&lt;/p>
&lt;pre>&lt;code class="language-r">fitted_model &amp;lt;- fit_series(data, model_type = 'EXP', observation_time = 5, cores = 10)
fitted_model
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Model: EXP
## No. of cascades: 100
## init_par
## K 7.92e+00; theta 1.32e+00
## par
## K 8.51e-01; theta 1.06e+00
## Neg Log Likelihood: 285.488
## lower_bound
## K 1.00e-100; theta 1.00e-100
## upper_bound
## K 1.00e+04; theta 3.00e+02
## convergence: 0
&lt;/code>&lt;/pre>
&lt;h2 id="available-models">Available models&lt;/h2>
&lt;p>There are 8 models available so far in this
package:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th align="center">Model&lt;/th>
&lt;th align="center">Abbreviation (model_type)&lt;/th>
&lt;th align="center">Intensity Function&lt;/th>
&lt;th align="center">Parameters&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td align="center">Hawkes process with an exponential kernel function&lt;/td>
&lt;td align="center">EXP&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} \\theta e^{-\\theta (t-t\_i)}" title="\kappa\sum_{t_i &amp;lt; t} \theta e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Hawkes process with a power-law kernel function&lt;/td>
&lt;td align="center">PL&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} (t-t\_i + c)^{-(1+\\theta)}" title="\kappa\sum_{t_i &amp;lt; t} (t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,c,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">HawkesN process with an exponential kernel function&lt;/td>
&lt;td align="center">EXPN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} \\theta e^{-\\theta (t-t\_i)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} \theta e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,theta,N&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">HawkesN process with a power-law kernel function&lt;/td>
&lt;td align="center">PLN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} (t-t\_i + c)^{-(1+\\theta)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} (t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,c,theta,N&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked Hawkes process with an exponential kernel function&lt;/td>
&lt;td align="center">mEXP&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20m_i%5E%7B%5Cbeta%7D%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} \\theta m\_i^{\\beta} e^{-\\theta (t-t\_i)}" title="\kappa\sum_{t_i &amp;lt; t} \theta m_i^{\beta} e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,beta,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked Hawkes process with a power-law kernel function&lt;/td>
&lt;td align="center">mPL&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20m_i%5E%7B%5Cbeta%7D%20%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} m\_i^{\\beta} (t-t\_i + c)^{-(1+\\theta)}" title="\kappa\sum_{t_i &amp;lt; t} m_i^{\beta} (t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,beta,c,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked HawkesN process with an exponential kernel function&lt;/td>
&lt;td align="center">mEXPN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20m_i%5E%7B%5Cbeta%7D%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} \\theta m\_i^{\\beta} e^{-\\theta (t-t\_i)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} \theta m_i^{\beta} e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,beta,theta,N&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked HawkesN process with a power-law kernel function&lt;/td>
&lt;td align="center">mPLN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20m_i%5E%7B%5Cbeta%7D%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} m\_i^{\\beta}(t-t\_i + c)^{-(1+\\theta)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} m_i^{\beta}(t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,beta,c,theta,N&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="acknowledgement">Acknowledgement&lt;/h2>
&lt;p>The development of this package is supported by the Green Policy grant
from the National Security College, Crawford School, ANU.&lt;/p>
&lt;h2 id="license">License&lt;/h2>
&lt;p>Both dataset and code are distributed under the &lt;a href="https://creativecommons.org/licenses/by-nc/4.0/">Creative Commons
Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)
license&lt;/a>. If you
require a different license, please contact us at &lt;a href="mailto:Quyu.Kong@anu.edu.au">Quyu.Kong@anu.edu.au&lt;/a>
or &lt;a href="mailto:Marian-Andrei@rizoiu.eu">Marian-Andrei@rizoiu.eu&lt;/a>.&lt;/p>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;p>[1] Rizoiu, M. A., Lee, Y., Mishra, S., &amp;amp; Xie, L. (2017, December). Hawkes processes for events in social media. In Frontiers of Multimedia Research (pp. 191-218). Association for Computing Machinery
and Morgan &amp;amp; Claypool.&lt;br>
[2] Rizoiu, M. A., Mishra, S., Kong, Q., Carman, M., &amp;amp; Xie, L.
(2018, April). SIR-Hawkes: Linking epidemic models and Hawkes processes to model diffusions in finite populations. In Proceedings of the 2018 World Wide Web Conference (pp. 419-428). International World Wide Web Conferences Steering Committee.&lt;br>
[3] Mishra, S., Rizoiu, M. A., &amp;amp; Xie, L. (2016, October). Feature
driven and point process approaches for popularity prediction. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management (pp. 1069-1078). ACM.&lt;br>
[4] Kong, Q., Rizoiu, M. A., &amp;amp; Xie, L. (2019). Modeling Information
Cascades with Self-exciting Processes via Generalized Epidemic Models. arXiv preprint arXiv:1910.05451.&lt;/p></description></item><item><title>evently: simulation, fitting of Hawkes processes</title><link>https://www.behavioral-ds.science/theme1_content/evently/</link><pubDate>Tue, 12 Nov 2019 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/theme1_content/evently/</guid><description>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/zSMHol0qsy4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>This package is designed for simulating and fitting the Hawkes processes
and the HawkesN processes with several options of kernel functions.
Currently, it assumes univariate processes without background event
rates. Prior knowledge about the models is assumed in the following
tutorial and please refer to [1] and [2] for details about the
models.&lt;/p>
&lt;pre>&lt;code class="language-r">library(evently)
&lt;/code>&lt;/pre>
&lt;h2 id="installation-and-dependencies">Installation and dependencies&lt;/h2>
&lt;p>Several dependencies
(&lt;a href="https://cran.r-project.org/web/packages/poweRlaw/poweRlaw.pdf">poweRlaw&lt;/a>,
&lt;a href="https://ampl.com/">AMPL&lt;/a>,
&lt;a href="https://www.coin-or.org/Ipopt/documentation/">Ipopt&lt;/a>) are required for
running this package. These dependencies will be installed automatically
by R or by following instructions upon package load.&lt;/p>
&lt;p>Install the package by executing&lt;/p>
&lt;pre>&lt;code class="language-r">if (!require('devtools')) install.packages('devtools')
devtools::install_github('behavioral-ds/evently')
&lt;/code>&lt;/pre>
&lt;h2 id="simulating-cascades">Simulating cascades&lt;/h2>
&lt;p>Let’s first simulate 100 event cascades of the &lt;strong>Hawkes process with an
exponential kernel function&lt;/strong> (please refer to the &lt;a href="#available-models">Available
models&lt;/a> for models and their abbreviations in the
package) with a given parameter set, &lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%20%3D%200.9%2C%20%5Ctheta%20%3D%201" alt="\\kappa = 0.9, \\theta= 1" title="\kappa = 0.9, \theta = 1">. For each simulation, we only simulate
until 5 seconds. The resulted cascades are placed in a single &lt;code>list&lt;/code>
where each cascade is a &lt;code>data.frame&lt;/code>.&lt;/p>
&lt;pre>&lt;code class="language-r">set.seed(4)
sim_no &amp;lt;- 100
data &amp;lt;- generate_hawkes_event_series(par = c(K = 0.9, theta = 1), model_type = 'EXP', Tmax = 5, sim_no = sim_no)
# alternatively, `generate_hawkes_event_series` also accepts a model class object
# e.g.
# model &amp;lt;- new_hawkes_model(par = c(K = 0.9, theta = 1), model_type = 'EXP')
# generate_hawkes_event_series(model = model, Tmax = 5, sim_no = sim_no)
head(data[[1]])
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## magnitude time
## 1 1 0.0000000
## 2 1 0.5941959
## 3 1 1.4712411
## 4 1 1.6105430
## 5 1 1.7855535
## 6 1 1.8883869
&lt;/code>&lt;/pre>
&lt;p>A simulated process is represented by a &lt;code>data.frame&lt;/code> where each row is
an event. &lt;code>time&lt;/code> indicates the event happening time, while &lt;code>magnitude&lt;/code>
is the event mark information which is always 1 if &lt;code>model_type&lt;/code> is an
unmarked model. In the context of retweet diffusion cascades, the first
row is the original tweet and all following events are its retweets.
&lt;code>time&lt;/code> records the relative time (in second) of each retweet to the
original tweet and &lt;code>magnitude&lt;/code> is the follows’ count of the user who
retweeted.&lt;/p>
&lt;h2 id="fitting-a-model-on-data">Fitting a model on data&lt;/h2>
&lt;p>We can then fit on the cascades simulated in the previous section. After
providing the &lt;code>data&lt;/code> and &lt;code>model_type&lt;/code>, the fitting procedure will spawn
10 AMPL optimization procedures with different parameter
inistializations due to the non-convexity of some likelihood functions.
Among the 10 fitted model, the one giving the best likelihood value will
be returned. To make the fitting procedure faster, we can specify the
number of &lt;code>cores&lt;/code> to be used for fitting them in
parallel.&lt;/p>
&lt;pre>&lt;code class="language-r">fitted_model &amp;lt;- fit_series(data, model_type = 'EXP', observation_time = 5, cores = 10)
fitted_model
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Model: EXP
## No. of cascades: 100
## init_par
## K 7.92e+00; theta 1.32e+00
## par
## K 8.51e-01; theta 1.06e+00
## Neg Log Likelihood: 285.488
## lower_bound
## K 1.00e-100; theta 1.00e-100
## upper_bound
## K 1.00e+04; theta 3.00e+02
## convergence: 0
&lt;/code>&lt;/pre>
&lt;h2 id="available-models">Available models&lt;/h2>
&lt;p>There are 8 models available so far in this
package:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th align="center">Model&lt;/th>
&lt;th align="center">Abbreviation (model_type)&lt;/th>
&lt;th align="center">Intensity Function&lt;/th>
&lt;th align="center">Parameters&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td align="center">Hawkes process with an exponential kernel function&lt;/td>
&lt;td align="center">EXP&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} \\theta e^{-\\theta (t-t\_i)}" title="\kappa\sum_{t_i &amp;lt; t} \theta e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Hawkes process with a power-law kernel function&lt;/td>
&lt;td align="center">PL&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} (t-t\_i + c)^{-(1+\\theta)}" title="\kappa\sum_{t_i &amp;lt; t} (t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,c,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">HawkesN process with an exponential kernel function&lt;/td>
&lt;td align="center">EXPN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} \\theta e^{-\\theta (t-t\_i)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} \theta e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,theta,N&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">HawkesN process with a power-law kernel function&lt;/td>
&lt;td align="center">PLN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} (t-t\_i + c)^{-(1+\\theta)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} (t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,c,theta,N&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked Hawkes process with an exponential kernel function&lt;/td>
&lt;td align="center">mEXP&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20m_i%5E%7B%5Cbeta%7D%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} \\theta m\_i^{\\beta} e^{-\\theta (t-t\_i)}" title="\kappa\sum_{t_i &amp;lt; t} \theta m_i^{\beta} e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,beta,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked Hawkes process with a power-law kernel function&lt;/td>
&lt;td align="center">mPL&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Csum_%7Bt_i%20%3C%20t%7D%20m_i%5E%7B%5Cbeta%7D%20%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\sum\_{t\_i \&lt; t} m\_i^{\\beta} (t-t\_i + c)^{-(1+\\theta)}" title="\kappa\sum_{t_i &amp;lt; t} m_i^{\beta} (t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,beta,c,theta&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked HawkesN process with an exponential kernel function&lt;/td>
&lt;td align="center">mEXPN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20%5Ctheta%20m_i%5E%7B%5Cbeta%7D%20e%5E%7B-%5Ctheta%20%28t-t_i%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} \\theta m\_i^{\\beta} e^{-\\theta (t-t\_i)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} \theta m_i^{\beta} e^{-\theta (t-t_i)}">&lt;/td>
&lt;td align="center">K,beta,theta,N&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td align="center">Marked HawkesN process with a power-law kernel function&lt;/td>
&lt;td align="center">mPLN&lt;/td>
&lt;td align="center">&lt;img src="https://latex.codecogs.com/png.latex?%5Ckappa%5Cfrac%7BN-N_t%7D%7BN%7D%5Csum_%7Bt_i%20%3C%20t%7D%20m_i%5E%7B%5Cbeta%7D%28t-t_i%20%2B%20c%29%5E%7B-%281%2B%5Ctheta%29%7D" alt="\\kappa\\frac{N-N\_t}{N}\\sum\_{t\_i \&lt; t} m\_i^{\\beta}(t-t\_i + c)^{-(1+\\theta)}" title="\kappa\frac{N-N_t}{N}\sum_{t_i &amp;lt; t} m_i^{\beta}(t-t_i + c)^{-(1+\theta)}">&lt;/td>
&lt;td align="center">K,beta,c,theta,N&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="acknowledgement">Acknowledgement&lt;/h2>
&lt;p>The development of this package is supported by the Green Policy grant
from the National Security College, Crawford School, ANU.&lt;/p>
&lt;h2 id="license">License&lt;/h2>
&lt;p>Both dataset and code are distributed under the &lt;a href="https://creativecommons.org/licenses/by-nc/4.0/">Creative Commons
Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)
license&lt;/a>. If you
require a different license, please contact us at &lt;a href="mailto:Quyu.Kong@anu.edu.au">Quyu.Kong@anu.edu.au&lt;/a>
or &lt;a href="mailto:Marian-Andrei@rizoiu.eu">Marian-Andrei@rizoiu.eu&lt;/a>.&lt;/p>
&lt;h2 id="reference">Reference&lt;/h2>
&lt;p>[1] Rizoiu, M. A., Lee, Y., Mishra, S., &amp;amp; Xie, L. (2017, December). Hawkes processes for events in social media. In Frontiers of Multimedia Research (pp. 191-218). Association for Computing Machinery
and Morgan &amp;amp; Claypool.&lt;br>
[2] Rizoiu, M. A., Mishra, S., Kong, Q., Carman, M., &amp;amp; Xie, L.
(2018, April). SIR-Hawkes: Linking epidemic models and Hawkes processes to model diffusions in finite populations. In Proceedings of the 2018 World Wide Web Conference (pp. 419-428). International World Wide Web Conferences Steering Committee.&lt;br>
[3] Mishra, S., Rizoiu, M. A., &amp;amp; Xie, L. (2016, October). Feature
driven and point process approaches for popularity prediction. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management (pp. 1069-1078). ACM.&lt;br>
[4] Kong, Q., Rizoiu, M. A., &amp;amp; Xie, L. (2019). Modeling Information
Cascades with Self-exciting Processes via Generalized Epidemic Models. arXiv preprint arXiv:1910.05451.&lt;/p></description></item><item><title>Contact</title><link>https://www.behavioral-ds.science/contact/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/contact/</guid><description/></item><item><title>News</title><link>https://www.behavioral-ds.science/news/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/news/</guid><description/></item><item><title>People</title><link>https://www.behavioral-ds.science/people/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/people/</guid><description/></item><item><title>Publications</title><link>https://www.behavioral-ds.science/publication/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/publication/</guid><description>&lt;p>
&lt;script src="https://www.behavioral-ds.science/js/bibtex_js.js">&lt;/script>
&lt;bibtex src="publications.bib">&lt;/bibtex>&lt;/p>
&lt;div style="margin-right: 10px; margin-top: -50px; float:right">
&lt;div class="input-group">
&lt;span class="input-group-addon">&lt;i class="fa fa-search" style="padding-left: 5px;">&lt;/i>&lt;/span>
&lt;input type="text" class="bibtex_search" id="searchbar" placeholder="Search publications">
&lt;/div>
&lt;/div>
&lt;div class="row">
&lt;div class="col-sm-12">
&lt;div id="bibtex_display" style="padding: 0 10px;">&lt;/div>
&lt;div class="bibtex_structure">
&lt;div class="group year" extra="DESC number">
&lt;div class="row">
&lt;div id="year-title" class="col-sm-12">
&lt;div class="title">&lt;/div>
&lt;/div>
&lt;div class="col-sm-12">
&lt;div class="templates">&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;/div>
&lt;div class="bibtex_template">
&lt;ul style="list-style-type:none">
&lt;li class="if author" style="font-weight: normal;">
&lt;b>&lt;span class="title">&lt;/span>&lt;/b>,
&lt;span class="author">&lt;/span>,
&lt;span class="if booktitle">
&lt;span class="booktitle">&lt;/span>,
&lt;/span>
&lt;span class="if journal">
&lt;span class="journal">&lt;/span>,
&lt;/span>
&lt;span class="year">&lt;/span>
&lt;span class="if url" style="margin-left: 5px; font-size:16px">
&lt;a class="url" target="_blank">
&lt;i class="fas fa-link" style="color:black;">&lt;/i>&lt;/a>
&lt;/span>
&lt;span class="if url_paper" style="margin-left: 5px; font-size:16px">
&lt;a class="url_paper" target="_blank">
&lt;i class="fas fa-file-alt" style="color:black;">&lt;/i>&lt;/a>
&lt;/span>
&lt;span class="if url_code" style="margin-left: 5px; font-size:16px">
&lt;a class="url_code" target="_blank">
&lt;i class="fab fa-github" style="color:black;">&lt;/i>&lt;/a>
&lt;/span>
&lt;span class="if url_slides" style="margin-left: 5px; font-size:16px">
&lt;a class="url_slides" target="_blank">
&lt;i class="far fa-newspaper" style="color:black;">&lt;/i>&lt;/a>
&lt;/span>
&lt;span class="if url_video" style="margin-left: 5px; font-size:16px">
&lt;a class="url_video" target="_blank">
&lt;i class="fas fa-video" style="color:black;">&lt;/i>&lt;/a>
&lt;/span>
&lt;span class="if abstract" style="margin-left: 5px;">
&lt;div class="morepage" >
&lt;span class="bibtexkey">&lt;/span>
&lt;span class="abstract noread">&lt;/span>
&lt;/div>
&lt;/span>
&lt;/li>
&lt;/ul>
&lt;/div>
&lt;/div>
&lt;/div></description></item><item><title>Reading</title><link>https://www.behavioral-ds.science/reading/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/reading/</guid><description/></item><item><title>Reading</title><link>https://www.behavioral-ds.science/reading2021/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/reading2021/</guid><description/></item><item><title>Reading</title><link>https://www.behavioral-ds.science/reading2022/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/reading2022/</guid><description/></item><item><title>Reading</title><link>https://www.behavioral-ds.science/reading2023/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/reading2023/</guid><description/></item><item><title>Reading</title><link>https://www.behavioral-ds.science/reading2024/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/reading2024/</guid><description/></item><item><title>Research</title><link>https://www.behavioral-ds.science/research/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.behavioral-ds.science/research/</guid><description/></item></channel></rss>